{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-staff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.值范围 2.相似线段形态 3.highlight落在区间内 4.方差大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-activity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "branch = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "for index in range(12):\n",
    "    item = {}\n",
    "    item['alias'] = 'search_branch' + str(branch[index])\n",
    "    item['desc'] = 'Branch ' + str(branch[index]) + ' common use KeyValue and Mark'\n",
    "    item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+').*(txAtt|Pma|linearization fault)'\n",
    "    item['exp_extract'] = [\n",
    "                        \"{}[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "                        \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "                        \"{}[{timestamp}] {}\"\n",
    "                        ]\n",
    "    item['exp_mark'] = [{\"alias\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}]\n",
    "    item['is_case_sensitive'] = True\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    config['search'].append(item)\n",
    "\n",
    "# for index in range(12):\n",
    "#     item = {}\n",
    "#     item['alias'] = 'insight_branch' + str(branch[index])\n",
    "#     item['desc'] = 'Branch Insight' + str(branch[index])\n",
    "#     item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+')'\n",
    "#     item['exp_extract'] = \"{}[{timestamp}]{}, msg = {msg}\"\n",
    "#     item['exp_mark'] = {\"alias\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}\n",
    "#     item['is_case_sensitive'] = True\n",
    "#     item['forward_rows'] = 0\n",
    "#     item['backward_rows'] = 0\n",
    "#     config['insight'].append(item)\n",
    "\n",
    "# for index in range(12):\n",
    "#     item = {}\n",
    "#     item['alias'] = 'statistic_branch' + str(branch[index])\n",
    "#     item['desc'] = 'Branch ' + str(branch[index]) + ' statistic txAtt'\n",
    "#     item['code'] = \"self.result = self.text_file_model.alias_data['\" + 'search_branch' + str(branch[index]) + \"'].res_key_value['txAtt']['global_index']\"\n",
    "#     config['statistic'].append(item)\n",
    "    \n",
    "json_object = json.dumps(config)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\config.txt\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceef613-07b4-47a1-8797-b9955f670ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "\n",
    "item1 = {}\n",
    "item1['alias'] = 'PackageName'\n",
    "item1['desc'] = 'Elog package restart name'\n",
    "item1['exp_search'] = '_R13C193'\n",
    "item1['exp_extract'] = [\n",
    "                    \"[{tmp1}] {}LMC ID: {packname}\\n[{tmp2}] {}\\n[{tmp3}] {}\\n[{tmp4}] {}\\n[{tmp5}] {}\\n[{timestamp}] {}\"\n",
    "                    ]\n",
    "item1['exp_mark'] = []\n",
    "item1['is_case_sensitive'] = True\n",
    "item1['forward_rows'] = 0\n",
    "item1['backward_rows'] = 5\n",
    "config['search'].append(item1)\n",
    "\n",
    "item2 = {}\n",
    "item2['alias'] = 'ErrorName'\n",
    "item2['desc'] = 'ABN: raiseFaultAndRollback'\n",
    "item2['exp_search'] = 'ABN: raiseFaultAndRollback'\n",
    "item2['exp_extract'] = [\n",
    "                    \"[{timestamp}] {}ABN: {errorname} {}\"\n",
    "                    ]\n",
    "item2['exp_mark'] = []\n",
    "item2['is_case_sensitive'] = True\n",
    "item2['forward_rows'] = 0\n",
    "item2['backward_rows'] = 0\n",
    "config['search'].append(item2)\n",
    "\n",
    "json_object = json.dumps(config)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\cooper_config.txt\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-fever",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from parse import parse\n",
    "\n",
    "str1 = 'BXP_3: [2022-11-23 22:04:44.572174570] (+0.000333470) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"txlProcBranchB\", fileAndLine = \"dpdController.cc:1887\", msg = \"txAtt:289, txAttPeak:0, dpGainLoopEnable:true, dpGainCtrlType:DSA_AD_TXFE, torTemperature:495 (0.1C), torGainBackoff:0 (0.01dB), torGainLin:3.49543(0.01dB), torStepBit:6, cc0Ctrl1=0x00000118 , avgIMpa0:1980 [mAmp]\" }'\n",
    "# str2 = 'BXP_3: [2022-12-10 15:55:26.739019220] (+0.000025340) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"TxBranchCtrlB\", fileAndLine = \"txChangeCycleHelper.cc:264\", msg = \"Txl branch J restart due to txL linearization fault!\" }'\n",
    "# str1 = \"BXP_2: [221120 164014] 27: PA measured values for driver name: DpaVddSv:7; value: 26992; branch Id: 7\"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] \\(%{STRING:cost}\\) \"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}Pma:%{FLOAT:Pma0}\\[%{DROP:tmp1}DpdPma:%{FLOAT:DpdPma0}\\[%{DROP:tmp2}Pmb:%{FLOAT:Pmb}, TorPmb:%{FLOAT:TorPmb0}\\[%{FLOAT:TorPmb1} %{FLOAT:TorPmb2}\\] \"\n",
    "exp_search = '(txlProcBranchB|TxBranchCtrlB).*(txAtt|linearization fault)'\n",
    "exp_extract = '{}[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}'\n",
    "r_search = re.findall(exp_search, str1)\n",
    "r_extract = parse(exp_extract, str1)\n",
    "print(r_search)\n",
    "print(r_extract.named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd51e56-d580-4908-97ed-46a77c62e948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from parse import parse\n",
    "# str1 = [\n",
    "#     \"221211-00:51:48 10.69.81.43 22.0n MSRBS_NODE_MODEL_22.Q2_566.28125.116_3317 stopfile=/tmp/21234\\n\",\n",
    "#     \"coli>/fruacc/lhsh BXP_5 ts r\\n\",\n",
    "#     \"Board                     : 45.2 C\\n\",\n",
    "#     \"DcPaVdd:0                 : 57.3 C\\n\",\n",
    "#     \"DcPaVdd:1                 : 57.8 C\\n\",\n",
    "#     \"DcPaVdd:2                 : 50.1 C\\n\",\n",
    "#     \"DcPaVdd:3                 : 50.6 C\\n\",\n",
    "#     \"DcTrxVcc                  : 48.3 C\\n\"\n",
    "# ]\n",
    "\n",
    "st1 = ['221211-00:50:33 10.69.81.43 22.0n MSRBS_NODE_MODEL_22.Q2_566.28125.116_3317 stopfile=/tmp/21234\\n', 'coli>/fruacc/lhsh BXP_5 ts r\\n', 'Board                     : 33.2 C\\n', 'DcPaVdd:0                 : 43.7 C\\n', 'DcPaVdd:1                 : 44.3 C\\n', 'DcPaVdd:2                 : 37.4 C\\n', 'DcPaVdd:3                 : 37.7 C\\n', 'DcTrxVcc                  : 48.9 C\\n']\n",
    "str2 = '\\n'.join(str1)\n",
    "r = parse(\"{timestamp} {}DcPaVdd:0                 : {temp:f} C{}\", str2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79fd9d-3959-41b1-a56d-4b30c31ebf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_clean_special_symbols(text, symbol):\n",
    "    for ch in ['::', '/','{','}','[',']','(',')','#','+','!',';',',','\"','\\'','@','`','$','^','&','|','\\n']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch,symbol)\n",
    "    return re.sub(symbol+\"+\", symbol, text)\n",
    "\n",
    "msg = \"fault state change: TX_FAULT_PROCESS_DONE---TX_FAULT_RECEIVED\"\n",
    "msg = msg[::-1] + ' '\n",
    "\n",
    "regex = '([A-Za-z0-9_.-]+?)[ ]?[:=][ ]?([A-Za-z0-9_.]+?) '\n",
    "msg = self_clean_special_symbols(msg, ' ')\n",
    "for value,key  in re.findall(regex, msg):\n",
    "    print(key[::-1], value[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03f5e8-a83d-4b5a-b9bc-e899d4c15736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_analysis.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-retailer",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # for display purposes\n",
    "import ruptures as rpt  # our package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from text_analysis import TextAnalysisModel\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# import en_core_web_sm\n",
    "# nlp = en_core_web_sm.load()\n",
    "\n",
    "text_analysis = await TextAnalysisModel('parallel', mode = 'test')\n",
    "\n",
    "file_path = ['D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\E55G948878_LE_SARONGGE_BXP_6_telog.log']\n",
    "config_path = 'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\config2.txt'\n",
    "\n",
    "await text_analysis.file_container.on_new_file('', file_path)\n",
    "await text_analysis.file_container.on_load_config('', config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81af8d-38d3-4ab4-8eaf-2d29eb2f7281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(text_analysis_model.file_container_model.text_file_models[namespace].alias_data[alias].res_key_value['txAtt_float'])\n",
    "data.loc[(data['value'] == 2500), :].reset_index(drop=True).loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d031c-0b4c-4774-a7cf-728f16acf7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = ''\n",
    "namespace = list(text_analysis_model.file_container_model.text_file_models.keys())[0]\n",
    "alias = 'insight_branchJ'\n",
    "res_mark = text_analysis_model.file_container_model.text_file_models[namespace].alias_data[alias].res_mark\n",
    "for mark in res_mark.keys():\n",
    "    mark_timestamp = res_mark[mark]['timestamp'][0]\n",
    "    mark_global_index = res_mark[mark]['global_index'][0]\n",
    "    mark_search_index = res_mark[mark]['search_index'][0]\n",
    "mark_timestamp, mark_global_index, mark_search_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1917db1-9fbc-4c24-a093-6079bbc36c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_words = set(['timeout', 'fault', 'error', 'abn', 'shutdown'])\n",
    "filter_words = ['db', 'mamp']\n",
    "\n",
    "def self_clean_special_symbols(text, symbol):\n",
    "    for ch in ['.', '_','-']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch,symbol)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return re.sub(symbol+\"+\", symbol, text)\n",
    "        \n",
    "def string_filter(df):\n",
    "    text = self_clean_special_symbols(df['value'], ' ')\n",
    "    words = []\n",
    "    for w in text.strip().split(' '):\n",
    "        w = w.lower()\n",
    "        if len(w) > 0:\n",
    "            if (not w[0].isdigit()) & (w not in filter_words):\n",
    "                words.append(w)\n",
    "                \n",
    "    if len(set(words).intersection(special_words)) > 0:\n",
    "        return False\n",
    "            \n",
    "    if len(words) < 2:\n",
    "        return True\n",
    "    \n",
    "    doc = nlp(' '.join(words))\n",
    "    pos = [w.pos_ for w in doc]\n",
    "        \n",
    "    if len(set(pos).intersection(set(['VERB', 'AUX']))) > 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "res_residue_marks = pd.DataFrame(text_analysis_model.file_container_model.text_file_models[namespace].alias_data[alias].res_residue_marks)\n",
    "res_residue_marks = res_residue_marks.loc[(res_residue_marks['timestamp'] < mark_timestamp), :]\n",
    "res_residue_marks['is_filter'] = res_residue_marks.apply(string_filter, axis=1)\n",
    "res_residue_marks = res_residue_marks.loc[(res_residue_marks['is_filter'] == False), :].reset_index(drop=True)\n",
    "\n",
    "sentences = list(set(res_residue_marks['value'].values))\n",
    "for s in sentences:\n",
    "    _type = 'Normal'\n",
    "    y = res_residue_marks.loc[(res_residue_marks['value'] == s), :].reset_index(drop=True)\n",
    "    y = list(y['search_index'].values)\n",
    "    indcies = []\n",
    "    for v in y:\n",
    "        indcies.append(True if v > mark_search_index * 0.7 else False)\n",
    "    if (list(set(indcies))[0] == True) & (len(list(set(indcies))) == 1):\n",
    "        _type = 'Mutation'\n",
    "        \n",
    "    if _type == 'Normal':\n",
    "        res_residue_marks.loc[(res_residue_marks['value'] == s), 'is_filter'] = True\n",
    "\n",
    "res_residue_marks = res_residue_marks.loc[(res_residue_marks['is_filter'] == False), :].reset_index(drop=True)\n",
    "res_residue_marks = res_residue_marks.drop(columns=['is_filter'])\n",
    "res_residue_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5d819-02c8-4d31-ab92-e70800958806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_strs = ['name', 'id']\n",
    "\n",
    "res_key_value = text_analysis_model.file_container_model.text_file_models[namespace].alias_data[alias].res_key_value\n",
    "for key in res_key_value.keys():\n",
    "    # if key == 'txAtt_float':\n",
    "    #     print(key)\n",
    "    if res_key_value[key]['type'] == 'str':\n",
    "        flag =  True\n",
    "        for c in filter_strs:\n",
    "            if c in key.lower():\n",
    "                flag = False\n",
    "        if key[0].isdigit():\n",
    "            flag = False\n",
    "\n",
    "        tmp_y = []\n",
    "        tmp_search_indcies = []\n",
    "        for index, t in enumerate(res_key_value[key]['timestamp']):\n",
    "            if t < mark_timestamp:\n",
    "                tmp_y.append(res_key_value[key]['value'][index])\n",
    "                tmp_search_indcies.append(res_key_value[key]['search_index'][index])\n",
    "            else:\n",
    "                break\n",
    "        y = []\n",
    "        search_indcies = []\n",
    "        for index, v in enumerate(tmp_y):\n",
    "            if len(v) >= 2:\n",
    "                if v[0:2] == '0x':\n",
    "                    y.append(v)\n",
    "                    search_indcies.append(tmp_search_indcies[index])\n",
    "                elif v[0].isdigit():\n",
    "                    pass\n",
    "                else:\n",
    "                    y.append(v)\n",
    "                    search_indcies.append(tmp_search_indcies[index])\n",
    "            \n",
    "        if len(y) < 1:\n",
    "            flag = False\n",
    "\n",
    "        if flag:\n",
    "            _type = 'Normal'\n",
    "            for t in set(y):\n",
    "                indcies = []\n",
    "                for index, item in enumerate(y):\n",
    "                    if t == item:\n",
    "                        indcies.append(True if search_indcies[index] > mark_search_index * 0.7 else False)\n",
    "                        \n",
    "                if (list(set(indcies))[0] == True) & (len(list(set(indcies))) == 1):\n",
    "                    _type = 'Mutation'\n",
    "                    break\n",
    "                    \n",
    "            # print(key, indcies, search_indcies, y)\n",
    "            if _type != 'Normal':\n",
    "                print(key, indcies, search_indcies, y)\n",
    "            # data = pd.DataFrame(y, columns=['y'])\n",
    "            # signal = np.array([[i] for i in data['y']])\n",
    "            # algo = rpt.Dynp(model=\"l2\", min_size=1, jump=1).fit(signal)\n",
    "            # result = algo.predict(n_bkps=2)\n",
    "            # print(key, len(y), result, glins[0])\n",
    "            # rpt.display(signal, result, result)\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd843e-cc22-4076-ae3c-4edac2a491d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_strs = ['id', '.cc']\n",
    "\n",
    "res_key_value = text_analysis_model.alias_data['insight_branchJ'].res_key_value\n",
    "for key in res_key_value.keys():\n",
    "    # if key == 'txAtt_float':\n",
    "    #     print(key)\n",
    "    if (res_key_value[key]['type'] == 'float') | (res_key_value[key]['type'] == 'int'):\n",
    "        flag =  True\n",
    "        for c in filter_strs:\n",
    "            if c in key.lower():\n",
    "                flag = False\n",
    "\n",
    "        if key[0].isdigit():\n",
    "            flag = False\n",
    "\n",
    "        y = []\n",
    "        glins = []\n",
    "        for index, t in enumerate(res_key_value[key]['timestamp']):\n",
    "            if t < timestamp:\n",
    "                y.append(res_key_value[key]['value'][index])\n",
    "                glins.append(res_key_value[key]['global_index'][index])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if (len(y) <= 3) | (len(set(y)) <= 1):\n",
    "            flag = False\n",
    "\n",
    "        if flag:\n",
    "            data = pd.DataFrame(y, columns=['y'])\n",
    "            signal = np.array([[i] for i in data['y']])\n",
    "            algo = rpt.Dynp(model=\"l2\", min_size=1, jump=1).fit(signal)\n",
    "            result = algo.predict(n_bkps=2)\n",
    "            print(key, len(y), result, glins[0])\n",
    "            rpt.display(signal, result, result)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419c923-b1f3-4b16-bc5e-40da8feabdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(text_analysis_model.alias_data['insight_branchJ'].res_key_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee0b80-dde3-4d2f-9d97-bf085a7a3e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from text_analysis import TextAnalysisModel\n",
    "\n",
    "text_analysis_model = await TextAnalysisModel('parallel', mode = 'test')\n",
    "\n",
    "file_path = ['D:\\\\projects\\\\ericsson_flow\\\\ELOG_READ_FULL_ENM3\\\\DL_BAYAHBARATCISIIH_GH.log']\n",
    "config_path = 'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\cooper_config1.txt'\n",
    "\n",
    "await text_analysis_model.file_container_model.on_new_file('', file_path)\n",
    "await text_analysis_model.file_container_model.on_load_config('', config_path)\n",
    "\n",
    "for key in text_analysis_model.alias_data.keys():\n",
    "    if 'Name' in key:\n",
    "        print(key, text_analysis_model.alias_data[key].res_key_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde300a5-a983-47b2-bc88-8c117dec9ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960fea0c-3f5e-422a-84be-18e12448caf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = False\n",
    "if ('packname' in text_analysis_model.alias_data['PackageName'].res_key_value) & ('errorname' in text_analysis_model.alias_data['ErrorName'].res_key_value):\n",
    "    for item in text_analysis_model.alias_data['ErrorName'].res_key_value['errorname']['timestamp']:\n",
    "        if text_analysis_model.alias_data['PackageName'].res_key_value['packname']['timestamp'][0] < item:\n",
    "            result = True        \n",
    "else:\n",
    "    result = 'unknow'\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a1b90-9ba8-49a3-9966-10813cea3e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = self.text_analysis_model.batch_statistic_model.table\n",
    "tt = table.loc[(table['BeforeError'] == True) & (table['AfterError'] == False),:]\n",
    "self.result = len(tt) / len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65779300-032d-4b6f-bafd-6c515cb6f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.text_analysis_model.batch_statistic_model.table.to_csv('D:\\\\projects\\\\ericsson_flow\\\\test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ce2f1-dbe8-407d-90e0-33d0f4e6032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.result = False\n",
    "if ('packname' in self.text_analysis_model.alias_data['PackageName'].res_key_value) & ('errorname' in self.text_analysis_model.alias_data['ErrorName'].res_key_value):\n",
    "    for item in self.text_analysis_model.alias_data['ErrorName'].res_key_value['errorname']['timestamp']:\n",
    "        if self.text_analysis_model.alias_data['PackageName'].res_key_value['packname']['timestamp'][0] > item:\n",
    "            self.result = True        \n",
    "else:\n",
    "    self.result = 'unknow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bced4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80519cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_clean_special_symbols(text, symbol):\n",
    "    for ch in ['.', '_','-']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch,symbol)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return re.sub(symbol+\"+\", symbol, text)\n",
    "        \n",
    "def camel_case_split(s):\n",
    "    idx = list(map(str.isupper, s))\n",
    "    # mark change of case\n",
    "    l = [0]\n",
    "    for (i, (x, y)) in enumerate(zip(idx, idx[1:])):\n",
    "        if x and not y:  # \"Ul\"\n",
    "            l.append(i)\n",
    "        elif not x and y:  # \"lU\"\n",
    "            l.append(i+1)\n",
    "    l.append(len(s))\n",
    "    # for \"lUl\", index of \"U\" will pop twice, have to filter that\n",
    "    return [s[x:y].lower() for x, y in zip(l, l[1:]) if x < y]\n",
    "\n",
    "special_words = set(['timeout', 'fault', 'error', 'abn', 'shutdown', 'deactivate' , 'activate'])\n",
    "for index, item in enumerate(text_analysis_model.alias_data['insight_branchI'].outlier):\n",
    "    if item['abnormal_type'] == 'UniquePrint':\n",
    "        t = self_clean_special_symbols(item['value'], ' ')\n",
    "        tmpwords = t.split(' ')\n",
    "        words = []\n",
    "        [words.extend(camel_case_split(word)) for word in tmpwords]\n",
    "        doc = nlp(' '.join(words))\n",
    "        pos = [w.pos_ for w in doc]\n",
    "        flag = True if len(set(pos).intersection(set(['VERB', 'AUX']))) > 0 else False\n",
    "        flag = True if len(set(words).intersection(special_words)) > 0 else flag\n",
    "        if flag == True:\n",
    "            print(index, flag, item['value'], re.findall('msg = \"(.*?)\"', item['origin']), set(pos))\n",
    "#         print(index, item['abnormal_type'], item['value'], re.findall('msg = \"(.*?)\"', item['origin']))\n",
    "        \n",
    "# camel_case_split('IPaddress')\n",
    "# doc = nlp(\"77868817us\")\n",
    "# print([(w.text, w.pos_) for w in doc]) 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b246cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'\\d+', '',\"hello 42 I'm a 32 string 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Training Signal sequence successfully done Activated\")\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from text_analysis import TextAnalysisModel\n",
    "\n",
    "text_analysis_model = await TextAnalysisModel('parallel', mode = 'test')\n",
    "\n",
    "dir_path = 'D:\\\\projects\\\\ericsson_flow\\\\batch_test'\n",
    "config = 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\config2.txt'\n",
    "\n",
    "await text_analysis_model.file_container_model.batch_insight_model.new(dir_path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analysis_model.file_container_model.batch_insight_model.result.loc[1, 'resOutlier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analysis_model.file_container_model.batch_insight_model.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = text_analysis_model.file_container_model.batch_insight_model.result\n",
    "res = tmp.loc[(tmp['fileName'] == 'E55H060478_LE_JLADANSUKAHATI_CBX_PL_BXP_6_telog.log'), :].reset_index(drop=True).loc[0, :]\n",
    "dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53c9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame([[0,22],[0,22],[0,22],[0,255],[0,255],[0,255]])\n",
    "cost =[]\n",
    "for i in range(1, 4):\n",
    "    KM = KMeans(n_clusters = i, max_iter = 500)\n",
    "    KM.fit(X)\n",
    "\n",
    "    # calculates squared error\n",
    "    # for the clustered points\n",
    "    cost.append(KM.inertia_)\n",
    "    \n",
    "# plot the cost against K values\n",
    "plt.plot(range(1, 4), cost, color ='g', linewidth ='3')\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Squared Error (Cost)\")\n",
    "plt.show() # clear the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt   # data visualization\n",
    "import seaborn as sns             # statistical data visualization\n",
    "\n",
    "def splita(df):\n",
    "    return df['Month,#Passengers'].split(',')[0]\n",
    "\n",
    "def splitb(df):\n",
    "    return df['Month,#Passengers'].split(',')[1]\n",
    "    \n",
    "path = 'AirPassengers.csv'\n",
    "df = pd.read_csv(path)\n",
    "df['Month'] = df.apply(splita, axis=1)\n",
    "df['#Passengers'] = df.apply(splitb, axis=1)\n",
    "df = df.drop(columns=['Month,#Passengers'])\n",
    "df.columns = ['Date','Number of Passengers']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-folks",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = [200 if i % 2 == 0 else 150 for i in range(100)]\n",
    "data = pd.DataFrame(data, columns=['y'])\n",
    "# data.loc[0:50, 'y'] = 22\n",
    "# data.loc[51, 'y'] = 255\n",
    "data.loc[52:100, 'y'] = 100\n",
    "data = data.reset_index()\n",
    "data = data.rename(columns={'index':'x'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smapi\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt   # data visualization\n",
    "import seaborn as sns             # statistical data visualization\n",
    "\n",
    "\n",
    "# Multiplicative Decomposition \n",
    "multiplicative_decomposition = seasonal_decompose(data['y'], model='multiplicative', period=30)\n",
    "\n",
    "# Additive Decomposition\n",
    "additive_decomposition = seasonal_decompose(data['y'], model='additive', period=30)\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (16,12)})\n",
    "multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [0 if str(i) == 'nan'  else i for i in additive_decomposition.resid]\n",
    "res = pd.DataFrame(res, columns=['y'])\n",
    "res = res.reset_index()\n",
    "res = res.rename(columns={'index':'x'})\n",
    "\n",
    "regression = smapi.ols(\"data ~ x\", data=dict(data=res['y'], x=res['x'])).fit()\n",
    "test = regression.outlier_test()\n",
    "test[test['bonf(p)'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-scheduling",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketio\n",
    "sio = socketio.AsyncClient(reconnection=False)\n",
    "await sio.connect('http://127.0.0.1:8000', namespaces=['/TextAnalysis/FileContainer'])\n",
    "# standard Python\n",
    "# sio = socketio.Client()\n",
    "# sio.connect('http://127.0.0.1:8000', namespaces=['/TextAnalysis/FileContainer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29b870-a7c5-4b32-a127-ec0fd012d7dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await sio.emit('new_file', ['D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\E55G948878_LE_SARONGGE_BXP_6_telog.log'], namespace='/TextAnalysis/FileContainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ea13b-3d0b-40c8-8acb-dd856b51b62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await sio.emit('load_config', 'D:\\projects\\\\ericsson_flow\\\\new_files\\\\config1.txt', namespace='/TextAnalysis/FileContainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d82bb-a47a-4274-99e9-0f0672ee6c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sio.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54afcd4-e726-484f-8b24-707a8426e24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# await sio.disconnect\n",
    "sio = socketio.AsyncClient(reconnection=False)\n",
    "await sio.connect('http://127.0.0.1:8000', namespaces=['/TextAnalysis/FileContainer', '/TextAnalysis/FileContainer/LE_PELAUKAN_PL.log_BXP_5_telog.log/TextFileFunction/StatisticFunction/statistic_branchA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a60aad-18b2-48d8-a2d4-1c17c5101135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sio.connection_namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77da60-46a0-4565-bc3d-ce0ac0b31c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def printm(model):\n",
    "    print(model)\n",
    "\n",
    "await sio.emit('model', namespace='/TextAnalysis/FileContainer/LE_PELAUKAN_PL.log_BXP_5_telog.log/TextFileFunction/StatisticFunction/statistic_branchA', callback=printm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe069c94-3da8-4586-9c2e-a8aeec395c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efc817-3986-47f3-8529-8189df0b86e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sio.emit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e164340-cbd1-4b4f-b374-e71978d2110a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson_toolsets_env",
   "language": "python",
   "name": "ericsson_toolsets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
