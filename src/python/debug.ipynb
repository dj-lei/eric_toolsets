{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543a9b8-78fc-4d29-aa0d-d2c60de6bb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "str1 = '[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}'\n",
    "re.findall('\\{(.*?)\\}', str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-activity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "branch = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "for index in range(12):\n",
    "    item = {}\n",
    "    item['role_path'] = 'root.' + 'branch' + str(branch[index]) + '.search_branch' + str(branch[index])\n",
    "    item['identifier'] = 'search_branch' + str(branch[index])\n",
    "    item['desc'] = 'Branch ' + str(branch[index]) + ' common use KeyValue and Mark'\n",
    "    item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+').*(txAtt|Pma|linearization fault)'\n",
    "    item['exp_extract'] = [\n",
    "                        \"{}[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "                        # \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "                        \"{}[{timestamp}] {}\"\n",
    "                        ]\n",
    "    item['exp_mark'] = [{\"abbr\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}]\n",
    "    item['is_active'] = False\n",
    "    item['is_case_sensitive'] = True\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    if index == 0:\n",
    "        item['is_active'] = True\n",
    "    config['search'].append(item)\n",
    "\n",
    "keys = ['txAtt', 'torTemperature', 'avgIMpa0', 'LF']\n",
    "for search_config in config['search']:\n",
    "    item = {}\n",
    "    item['role_path'] = search_config['role_path'].replace('search', 'chart')\n",
    "    item['identifier'] = search_config['identifier'].replace('search', 'chart')\n",
    "    item['desc'] = item['identifier'] + ' all KeyValue and Mark'\n",
    "    item['check'] = False\n",
    "    item['key_value_tree'] = {'namespace': 'KeyValue', 'name':'Key Value', 'check':False, 'children':[]}\n",
    "    for search_config2 in config['search']:\n",
    "        search_atom = {}\n",
    "        search_atom['namespace'] = search_config2['identifier']\n",
    "        search_atom['name'] = search_config2['identifier']\n",
    "        search_atom['check'] = False\n",
    "        search_atom['children'] = []\n",
    "        for key in keys:\n",
    "            if search_config['identifier'] == search_config2['identifier']:\n",
    "                search_atom['children'].append({'name': key, 'check': True})\n",
    "            else:\n",
    "                search_atom['children'].append({'name': key, 'check': False})\n",
    "        item['key_value_tree']['children'].append(search_atom)\n",
    "    config['chart'].append(item)\n",
    "\n",
    "# for index in range(12):\n",
    "#     item = {}\n",
    "#     item['name'] = 'insight_branch' + str(branch[index])\n",
    "#     item['desc'] = 'Branch Insight' + str(branch[index])\n",
    "#     item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+')'\n",
    "#     item['exp_extract'] = \"{}[{timestamp}]{}, msg = {msg}\"\n",
    "#     item['exp_mark'] = {\"name\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}\n",
    "#     item['is_case_sensitive'] = True\n",
    "#     item['forward_rows'] = 0\n",
    "#     item['backward_rows'] = 0\n",
    "#     config['insight'].append(item)\n",
    "\n",
    "# for index in range(12):\n",
    "#     item = {}\n",
    "#     item['name'] = 'statistic_branch' + str(branch[index])\n",
    "#     item['desc'] = 'Branch ' + str(branch[index]) + ' statistic txAtt'\n",
    "#     item['code'] = \"self.result = self.text_file_model.data['\" + 'search_branch' + str(branch[index]) + \"'].res_key_value['txAtt']['global_index']\"\n",
    "#     config['statistic'].append(item)\n",
    "    \n",
    "json_object = json.dumps(config)\n",
    "with open(\"E:\\\\projects\\\\ericsson_flow\\\\new_files\\\\config.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04930e7e-18d5-4970-a453-e0b638883997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "def add_search_config(parent, express, processes, keyword, mark):\n",
    "    config = []\n",
    "    \n",
    "    item = {}\n",
    "    item['identifier'] = f'{parent}_ErrorFaultABN'\n",
    "    identifier = item['identifier']\n",
    "    item['role_path'] = f'root.{parent}.EFA.{identifier}'\n",
    "\n",
    "    item['desc'] = parent + ' Error Fault ABN'\n",
    "    item['exp_search'] = parent + '.*(error| fault|ABN)'\n",
    "    item['exp_extract'] = [\n",
    "                            parent + express\n",
    "                        ]\n",
    "    item['exp_mark'] = [\n",
    "                            {\"abbr\":\"ER\",\"exp\":\"error\",\"color\":\"#f00000\"},\n",
    "                            {\"abbr\":\"FA\",\"exp\":\" fault\",\"color\":\"#f00000\"},\n",
    "                            {\"abbr\":\"ABN\",\"exp\":\"ABN\",\"color\":\"#ffff00\"}\n",
    "                        ]\n",
    "    item['is_active'] = True\n",
    "    item['is_case_sensitive'] = False\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    config.append(item)\n",
    "\n",
    "    for index, process in enumerate(processes):\n",
    "        item = {}\n",
    "        name = process.replace(',','_')\n",
    "        item['identifier'] = f'{parent}_{name}'\n",
    "        identifier = item['identifier']\n",
    "        item['role_path'] = f'root.{parent}.{identifier}' if (keyword not in process) else f'root.{parent}.{process}.{identifier}'\n",
    "        item['desc'] =  parent + ' ' + process + ' common use KeyValue and Mark'\n",
    "        item['exp_search'] = f'{parent}.*{process}'\n",
    "        item['exp_extract'] = [\n",
    "                                parent + express\n",
    "                            ]\n",
    "        item['exp_mark'] = mark if (keyword in process) else []\n",
    "        item['is_active'] = False\n",
    "        item['is_case_sensitive'] = True\n",
    "        item['forward_rows'] = 0\n",
    "        item['backward_rows'] = 0\n",
    "        config.append(item)\n",
    "    return config\n",
    "        \n",
    "def add_chart_config(tmp_search):\n",
    "    config = []\n",
    "    for search_config in tmp_search:\n",
    "\n",
    "        if len(search_config['exp_mark']) == 0:\n",
    "            continue\n",
    "\n",
    "        item = {}\n",
    "        item['role_path'] = search_config['role_path'] + '_Chart'\n",
    "        item['identifier'] = search_config['identifier'] + '_Chart'\n",
    "        item['desc'] = item['identifier'] + ' all KeyValue and Mark'\n",
    "        item['check'] = False\n",
    "        item['key_value_tree'] = {'namespace': 'KeyValue', 'name':'Key Value', 'check':False, 'children':[]}\n",
    "        for search_config2 in tmp_search:\n",
    "            search_atom = {}\n",
    "            search_atom['namespace'] = search_config2['identifier']\n",
    "            search_atom['name'] = search_config2['identifier']\n",
    "            search_atom['check'] = False\n",
    "            search_atom['children'] = []\n",
    "            if len(search_config2['exp_mark']) > 0:\n",
    "                keys = []\n",
    "                for mark in search_config2['exp_mark']:\n",
    "                    keys.append(mark['abbr'])\n",
    "                    \n",
    "                for key in keys:\n",
    "                    if search_config['identifier'] == search_config2['identifier']:\n",
    "                        search_atom['children'].append({'name': key, 'check': True})\n",
    "                    else:\n",
    "                        search_atom['children'].append({'name': key, 'check': False})\n",
    "                        \n",
    "            item['key_value_tree']['children'].append(search_atom)\n",
    "        config.append(item)\n",
    "    return config\n",
    "\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "\n",
    "processes = []\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\ErrorLog\\\\DOT TE LOG.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        res = re.findall(' \\((.*?)\\): ', line)\n",
    "        if len(res) > 0:\n",
    "            processes.append(res[0]) \n",
    "processes = list(set(processes))\n",
    "processes.sort()\n",
    "config['search'].extend(add_search_config('DOT_TE_LOG', \":{timestamp} ({}\", processes, 'kkkkkkkkkkkkk', []))\n",
    "\n",
    "processes = []\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\ErrorLog\\\\DU1 TE LOG.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        res = re.findall('procname = \\\"(.*?)\\\"', line)\n",
    "        if len(res) > 0:\n",
    "            processes.append(res[0])\n",
    "processes = list(set(processes))\n",
    "processes.sort()\n",
    "config['search'].extend(add_search_config('DU1_TE_LOG', \":[{timestamp}]{}\", processes, 'kkkkkkkkkkkkk', []))\n",
    "config['search'].extend(add_search_config('DU2_TE_LOG', \":[{timestamp}]{}\", processes, 'kkkkkkkkkkkkk', []))\n",
    "\n",
    "processes = []\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\ErrorLog\\\\RU1 TE LOG.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        res = re.findall(', { \\\"(.*?)\\\"', line)\n",
    "        if len(res) > 0:\n",
    "            processes.append(res[0])\n",
    "processes = list(set(processes))\n",
    "processes.sort()\n",
    "mark = [\n",
    "            {\"abbr\":\"ED\",\"exp\":\"EVENT_DEACTIVATE\",\"color\":\"#759aa0\"},\n",
    "            {\"abbr\":\"ER\",\"exp\":\"EVENT_RELEASE\",\"color\":\"#e69d87\"},\n",
    "            {\"abbr\":\"ES\",\"exp\":\"EVENT_SETUP\",\"color\":\"#8dc1a9\"},\n",
    "            {\"abbr\":\"EA\",\"exp\":\"EVENT_ACTIVATE\",\"color\":\"#ea7e53\"},\n",
    "            {\"abbr\":\"IND\",\"exp\":\"IND_ACTIVATE\",\"color\":\"#eedd78\"}\n",
    "        ]\n",
    "tmp_search = add_search_config('RU1_TE_LOG', '{}[{timestamp}]{}', processes, 'TxBranchCtrl', mark)\n",
    "config['search'].extend(tmp_search)\n",
    "config['chart'].extend(add_chart_config(tmp_search))\n",
    "\n",
    "tmp_search = add_search_config('RU2_TE_LOG', '{}[{timestamp}]{}', processes, 'TxBranchCtrl', mark)\n",
    "config['search'].extend(tmp_search)\n",
    "config['chart'].extend(add_chart_config(tmp_search))\n",
    "\n",
    "json_object = json.dumps(config)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\DotConfigFull.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84793c-8d6e-4a8a-b079-5a1e3368c144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from parse import parse\n",
    "\n",
    "str1 = 'RU2_TE_LOG:BXP_2: [2023-02-23 10:31:25.766459124] com_ericsson_trithread:INFO: { 0 }, { \"TxBranchCtrlC\", \"logManager.cc:37\", \"Branch does not support different power level (txChangeCycleStatePrepare.cc:517)\" }'\n",
    "# str2 = 'BXP_3: [2022-12-10 15:55:26.739019220] (+0.000025340) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"TxBranchCtrlB\", fileAndLine = \"txChangeCycleHelper.cc:264\", msg = \"Txl branch J restart due to txL linearization fault!\" }'\n",
    "str1 = \"\tfru_2051: [230201 120650]  144: PSU enters: DC_AISG_U:0 exceeds the limists. Value(mV): 587, limits[EXCEPTIONAL_HI,NORMAL_HI, NORMAL_LOW, EXCEPTIONAL_LOW](13125,13125,11875,11875)\"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] \\(%{STRING:cost}\\) \"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}Pma:%{FLOAT:Pma0}\\[%{DROP:tmp1}DpdPma:%{FLOAT:DpdPma0}\\[%{DROP:tmp2}Pmb:%{FLOAT:Pmb}, TorPmb:%{FLOAT:TorPmb0}\\[%{FLOAT:TorPmb1} %{FLOAT:TorPmb2}\\] \"\n",
    "exp_extract = '{}[{timestamp}]{}PSU enters{}'\n",
    "r_extract = parse(exp_extract, str1)\n",
    "print(r_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75e39c-8976-42e1-9b52-517eed5c85c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# processes = []\n",
    "# with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\4449\\\\faillog 4449 ULSA.txt\", \"r\") as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         res = re.findall(\"{ \\\"(.*?)\\\",\", line)\n",
    "#         if len(res) > 0:\n",
    "#             # if ('BranchCtrl' not in res[0]) & ('PhaseCtrl' not in res[0]):\n",
    "#             processes.append(res[0])\n",
    "            \n",
    "# with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\4449\\\\passlog 4449 ULSA.txt\", \"r\") as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         res = re.findall(\"{ \\\"(.*?)\\\",\", line)\n",
    "#         if len(res) > 0:\n",
    "#             # if ('BranchCtrl' not in res[0]) & ('PhaseCtrl' not in res[0]):\n",
    "#             processes.append(res[0])\n",
    "            \n",
    "# processes = list(set(processes))\n",
    "# processes.sort()\n",
    "# processes\n",
    "processes = [\n",
    " 'AntennaModule',\n",
    " 'EquipCtrl',\n",
    " 'PaSrvDC',\n",
    " 'PimcTdiHandler',\n",
    " 'RICRAI_SERVER',\n",
    " 'RxBranchCtrlA',\n",
    " 'RxBranchCtrlB',\n",
    " 'RxBranchCtrlC',\n",
    " 'RxBranchCtrlD',\n",
    " 'RxRmcService',\n",
    " 'TorLoSrvCD',\n",
    " 'TxBranchCtrlC',\n",
    " 'TxBranchCtrlD',\n",
    " 'TxCoordinationSrvCD',\n",
    " 'TxLoSrvC',\n",
    " 'TxLoSrvD',\n",
    " 'TxTimingPhaseCtrlC',\n",
    " 'antpServerProc_',\n",
    " 'bcProc',\n",
    " 'brhProc',\n",
    " 'carrierListElogScheduler.cc',\n",
    " 'carrierResourceHandlerImpl.cc',\n",
    " 'child.c',\n",
    " 'cmd_proc',\n",
    " 'cmd_proc(COLI)',\n",
    " 'cpriCtrlProc',\n",
    " 'cprilhmd.c',\n",
    " 'crhCarrierCtrl.cc',\n",
    " 'crhCarrierListHandler.cc',\n",
    " 'crhProxyProc',\n",
    " 'ecp_x11.c',\n",
    " 'faultManagerProc',\n",
    " 'iqIqcSwitchingAlgorithmCpri.cc',\n",
    " 'iqIqcSwitchingResourceHandlerIf.cc',\n",
    " 'iqIqcSwitchingResourceHandlerMs.cc',\n",
    " 'ledProc',\n",
    " 'libecp_x11.c',\n",
    " 'lrciRasCapDbFacadeAbfaas.cc',\n",
    " 'lrciRasCapDbFacadeBase.cc',\n",
    " 'lrciRasCapabilities.cc',\n",
    " 'radioTrDcServer',\n",
    " 'rfPort.cc',\n",
    " 'rftProc',\n",
    " 'rhd-lh.c',\n",
    " 'rmcProc',\n",
    " 'rtsCtrl',\n",
    " 'rtsCtrl_requestProcessor',\n",
    " 'rxBranchTimingInfoReporter.cc',\n",
    " 'stimenotifyd.c',\n",
    " 'tmoSchedulerEqp',\n",
    " 'tmoSchedulerTx',\n",
    " 'trDcProc',\n",
    " 'txBranchReporterCrh.cc',\n",
    " 'txlProcBranchC',\n",
    " 'txlProcBranchD',\n",
    " 'ulh_hdlc.c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df44f1-6796-4d8c-bd7d-4e72bab7f918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "product_name = 'Radio4449'\n",
    "processes = processes\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "\n",
    "item = {}\n",
    "item['role_path'] = f'{product_name}.TimedoutErrorFaultABN'\n",
    "item['identifier'] = 'TimedoutErrorFaultABN'\n",
    "item['desc'] = 'Error Fault ABN Timedout'\n",
    "item['exp_search'] = 'error| fault|ABN|Timed out'\n",
    "item['exp_extract'] = [\n",
    "                    \"[{timestamp}] {}\" \n",
    "                    ]\n",
    "item['exp_mark'] = [\n",
    "                        {\"abbr\":\"TO\",\"exp\":\"Timed out\",\"color\":\"#FFB6C1\"},\n",
    "                        {\"abbr\":\"ER\",\"exp\":\"error\",\"color\":\"#f00000\"},\n",
    "                        {\"abbr\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"},\n",
    "                        {\"abbr\":\"ABN\",\"exp\":\"ABN:\",\"color\":\"#ffff00\"}\n",
    "                    ]\n",
    "item['is_active'] = True\n",
    "item['is_case_sensitive'] = True\n",
    "item['forward_rows'] = 0\n",
    "item['backward_rows'] = 0\n",
    "config['search'].append(item)\n",
    "\n",
    "for index, process in enumerate(processes):\n",
    "    item = {}\n",
    "    item['role_path'] = f'{product_name}.' + process.replace('.','_').replace('(','_').replace(')','_')\n",
    "    item['identifier'] = process\n",
    "    item['desc'] =  process + ' common use KeyValue and Mark'\n",
    "    item['exp_search'] = '\"'+process.replace('(','\\\\(').replace(')','\\\\)')+'\", '\n",
    "    item['exp_extract'] = [\n",
    "                        # \"[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "                        # \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "                        \"[{timestamp}] {}\" \n",
    "                        ]\n",
    "    # item['exp_mark'] = [\n",
    "    #                         {\"abbr\":\"ED\",\"exp\":\"EVENT_DEACTIVATE\",\"color\":\"#e00000\"},\n",
    "    #                         {\"abbr\":\"ER\",\"exp\":\"EVENT_RELEASE\",\"color\":\"#d00000\"},\n",
    "    #                         {\"abbr\":\"ES\",\"exp\":\"EVENT_SETUP\",\"color\":\"#c00000\"},\n",
    "    #                         {\"abbr\":\"EA\",\"exp\":\"EVENT_ACTIVATE\",\"color\":\"#b00000\"},\n",
    "    #                         {\"abbr\":\"IND\",\"exp\":\"IND_ACTIVATE\",\"color\":\"#a00000\"}\n",
    "    #                     ]\n",
    "    item['is_active'] = False\n",
    "    item['is_case_sensitive'] = True\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    config['search'].append(item)\n",
    "\n",
    "# tmp_search = []\n",
    "# processes = range(2)\n",
    "# for index in processes:\n",
    "#     item = {}\n",
    "#     branch_num = str(index)\n",
    "#     item['role_path'] = f'{product_name}.' + 'branch' + branch_num + '.search_branch' + branch_num\n",
    "#     item['identifier'] = 'search_branch' + branch_num\n",
    "#     item['desc'] = 'Branch ' + branch_num + ' common use KeyValue and Mark'\n",
    "#     item['exp_search'] = f'(process = \"txlProcBranch'+branch_num+'\"|process = \"TxBranchCtrl'+branch_num+'\")'\n",
    "#     item['exp_extract'] = [\n",
    "#                         \"[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "#                         # \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "#                         \"[{timestamp}] {}\" \n",
    "#                         ]\n",
    "#     item['exp_mark'] = [\n",
    "#                             {\"abbr\":\"ED\",\"exp\":\"EVENT_DEACTIVATE\",\"color\":\"#759aa0\"},\n",
    "#                             {\"abbr\":\"ER\",\"exp\":\"EVENT_RELEASE\",\"color\":\"#e69d87\"},\n",
    "#                             {\"abbr\":\"ES\",\"exp\":\"EVENT_SETUP\",\"color\":\"#8dc1a9\"},\n",
    "#                             {\"abbr\":\"EA\",\"exp\":\"EVENT_ACTIVATE\",\"color\":\"#ea7e53\"},\n",
    "#                             {\"abbr\":\"IND\",\"exp\":\"IND_ACTIVATE\",\"color\":\"#eedd78\"}\n",
    "#                         ]\n",
    "#     item['is_active'] = False\n",
    "#     item['is_case_sensitive'] = True\n",
    "#     item['forward_rows'] = 0\n",
    "#     item['backward_rows'] = 0\n",
    "#     config['search'].append(item)\n",
    "#     tmp_search.append(item)\n",
    "        \n",
    "# keys = ['txAtt', 'avgIMpa0', 'ED', 'ER', 'ES', 'EA', 'IND']\n",
    "# for search_config in tmp_search:\n",
    "#     item = {}\n",
    "#     item['role_path'] = search_config['role_path'].replace('search', 'chart')\n",
    "#     item['identifier'] = search_config['identifier'].replace('search', 'chart')\n",
    "#     item['desc'] = item['identifier'] + ' all KeyValue and Mark'\n",
    "#     tree = {'namespace': 'KeyValue', 'name':'Key Value', 'check':False, 'children':[]}\n",
    "#     for search_config2 in tmp_search:\n",
    "#         search_atom = {}\n",
    "#         search_atom['namespace'] = search_config2['identifier']\n",
    "#         search_atom['name'] = search_config2['identifier']\n",
    "#         search_atom['check'] = False\n",
    "#         search_atom['children'] = []\n",
    "#         for key in keys:\n",
    "#             if search_config['identifier'] == search_config2['identifier']:\n",
    "#                 search_atom['children'].append({'name': key, 'check': True})\n",
    "#             else:\n",
    "#                 search_atom['children'].append({'name': key, 'check': False})\n",
    "#         tree['children'].append(search_atom)\n",
    "#     item['key_value_tree'] = [{'id': '', 'type': 'TidyTree', 'elements':tree}]\n",
    "#     config['chart'].append(item)\n",
    "    \n",
    "json_object = json.dumps(config)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\4449Config.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f6694-8889-45d0-acee-537eafee47d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################### User Define ###############################\n",
    "# DCGM directory Location\n",
    "dcgm_dir_path = 'D:/projects/ericsson_flow/new_files/Dot4455/'\n",
    "\n",
    "extract_paths = [\n",
    "    '*_logfiles.zip/teread.log',\n",
    "    '*_e2.log.gz/*_dcg_e2.log',\n",
    "    '*_modump.zip/*_dcg_k.log.gz/*_dcg_k.log'\n",
    "]\n",
    "\n",
    "# Save directory Location\n",
    "save_path = 'D:/projects/ericsson_flow/new_dcgm_output/'\n",
    "# Python regular express\n",
    "telog_filters = 'radio6626'\n",
    "# Python regular express\n",
    "elog_filters = 'HW fault'\n",
    "# Whether to integrate into one file.\n",
    "is_into_one_file = False\n",
    "\n",
    "\n",
    "class ZipDecompress(object):\n",
    "    def __init__(self, path, extract_paths):\n",
    "        self.path = path\n",
    "        self.extract_paths = extract_paths\n",
    "        self.result = {}\n",
    "        self.decompress()\n",
    "        \n",
    "    def decompress(self):\n",
    "        for num, package_name in enumerate(iterate_files_in_directory(self.path)):\n",
    "            if '.zip' in package_name:\n",
    "                self.result[package_name] = []\n",
    "                zip_path = self.path + package_name\n",
    "                with zipfile.ZipFile(zip_path, 'r') as file:\n",
    "                    for extract_path in extract_paths:\n",
    "                        file_name, lines = self.decompress_file(file, extract_path)\n",
    "                        self.result[package_name].append([file_name, lines])\n",
    "        \n",
    "    def decompress_file(self, f_refer, extract_path):\n",
    "        path_node = extract_path.split('/')[0].replace('*', '')\n",
    "        tg = ''\n",
    "        for file in f_refer.filelist:\n",
    "            if path_node in file.filename:\n",
    "                tg = file.filename\n",
    "\n",
    "        if '.zip' in tg:\n",
    "            with f_refer.open(tg, 'r') as nest:\n",
    "                zfile = io.BytesIO(nest.read())\n",
    "                with zipfile.ZipFile(zfile) as nested_zip:\n",
    "                    return self.decompress_file(nested_zip, '/'.join(extract_path.split('/')[1:]))\n",
    "        elif '.gz' in tg:\n",
    "            with f_refer.open(tg, 'r') as nest:\n",
    "                zfile = io.BytesIO(nest.read())\n",
    "                lines = gzip.open(zfile, 'r')\n",
    "                return nest.name, [line.decode(\"utf-8\") for line in lines]\n",
    "        else:\n",
    "            with f_refer.open(tg, 'r') as nest:\n",
    "                lines = nest.readlines()\n",
    "                return tg, [line.decode(\"utf-8\") for line in lines]\n",
    "\n",
    "\n",
    "class ContentSearch(object):\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        self.result = {}\n",
    "        \n",
    "    def search_by_range(self, start_exp, end_exp):\n",
    "        self.result = []\n",
    "        \n",
    "        flag = False\n",
    "        lines = []\n",
    "        indices = []\n",
    "        start_exp_parse = ''\n",
    "        end_exp_parse = ''\n",
    "        for index, line in enumerate(self.lines):\n",
    "            if flag:\n",
    "                r = parse(end_exp, line)\n",
    "                if r is not None:\n",
    "                    flag = False\n",
    "                    end_exp_parse = r.named\n",
    "                    self.result.append({'start_exp_parse': start_exp_parse, 'end_exp_parse': end_exp_parse, 'indices': indices, 'lines': lines})\n",
    "                    lines = []\n",
    "                    indices = []\n",
    "                else:\n",
    "                    lines.append(line)\n",
    "                    indices.append(index)\n",
    "                    continue\n",
    "            r = parse(start_exp, line)\n",
    "            if r is not None:\n",
    "                start_exp_parse = r.named\n",
    "                flag = True\n",
    "                lines.append(line)\n",
    "                indices.append(index)\n",
    "        return self.result\n",
    "                    \n",
    "    def search_by_regular(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697de069-294c-45fc-b3fe-cd1cafe52cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "class KeyValueExtract(object):\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        self.result = {}\n",
    "                        \n",
    "    def extract_in_embedded(self, kv_exps):\n",
    "        self.result = {}\n",
    "        for index, line in enumerate(self.lines):\n",
    "            for kv_exp in kv_exps:\n",
    "                r = parse(kv_exp, line)\n",
    "                if r is not None:\n",
    "                    for key in r.named.keys():\n",
    "                        if key not in self.result:\n",
    "                            self.result[key] = []\n",
    "                        self.result[key].append({'index': index, 'value': r.named[key], 'timestamp': convert_datetime_timestamp(r.named['timestamp'])})\n",
    "        return self.result\n",
    "    \n",
    "    def extract_in_batch(self, kv_exps):\n",
    "        timestamp = ''\n",
    "        self.result = {}\n",
    "        for index, line in enumerate(self.lines):\n",
    "            for kv_exp in kv_exps:\n",
    "                r = parse(kv_exp, line)\n",
    "                if r is not None:\n",
    "                    if 'timestamp' in r.named:\n",
    "                        timestamp = convert_datetime_timestamp(r.named['timestamp'])\n",
    "                        break\n",
    "                    for key in r.named.keys():\n",
    "                        if key not in self.result:\n",
    "                            self.result[key] = []\n",
    "                        self.result[key].append({'index': index, 'value': r.named[key], 'timestamp': timestamp})\n",
    "        return self.result\n",
    "    \n",
    "    def extract_in_batch_notime(self, kv_exps):\n",
    "        timestamp = ''\n",
    "        self.result = {}\n",
    "        for index, line in enumerate(self.lines):\n",
    "            for kv_exp in kv_exps:\n",
    "                r = parse(kv_exp, line)\n",
    "                if r is not None:\n",
    "                    for key in r.named.keys():\n",
    "                        if key not in self.result:\n",
    "                            self.result[key] = []\n",
    "                        self.result[key].append({'index': index, 'value': r.named[key], 'timestamp': 0})\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0489f45-bf90-4b4e-8b89-70c2c538a571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################### User Define ###############################\n",
    "# DCGM directory Location\n",
    "dir_path = 'D:/projects/ericsson_flow/new_files/AIR_HC/'\n",
    "origin_data_output = 'D:/projects/ericsson_flow/new_files/RRU4432B28OriginData.csv'\n",
    "product_name = 'RRU4432B28'\n",
    "map_table_start_mark = ['FRU','LNH','BOARD','ST','FAULT','OPER','MAINT']\n",
    "map_table_end_mark = '---------------------------------------------------------------------'\n",
    "map_table_exp = '{} ;{assigned_name} ;{product_name} {}'\n",
    "\n",
    "exps = {\n",
    "    'trx status':{'kv_exps': [\n",
    "                    '{}Date: {timestamp},{}',\n",
    "                    '{}txPma{}: {txPma},{}',\n",
    "                    '{}txDpdPma{}: {txDpdPma},{}',\n",
    "                    '{}txPmb{}: {txPmb},{}',\n",
    "                    '{}txTorPmb{}: {txTorPmb},{}',\n",
    "                    '{}dpd {}: {dpd},{}',\n",
    "                    '{}dpdStateMachine{}: {dpdStateMachine},{}', \n",
    "                    '{}gainStateMachine{}: {gainStateMachine},{}',\n",
    "                    '{}linearizationStateMachine{}: {linearizationStateMachine},{}'\n",
    "                ], 'filter_exps': {\n",
    "                    'txPma': \"row['txPma_abnormal'] = False\",\n",
    "                    'txDpdPma': \"row['txDpdPma_abnormal'] = True if float(row['txPma']['value']) - float(row['txDpdPma']['value']) > 4 else False\",\n",
    "                    'txPmb': \"row['txPmb_abnormal'] = True if float(row['txPma']['value']) - float(row['txPmb']['value']) != 0 else False\",\n",
    "                    'txTorPmb': \"row['txTorPmb_abnormal'] = True if float(row['txPma']['value']) - float(row['txTorPmb']['value']) > 0.1 else False\",\n",
    "                    'dpd': \"row['dpd_abnormal'] = True if row['dpd']['value'] in ['off'] else False\",\n",
    "                    'dpdStateMachine': \"row['dpdStateMachine_abnormal'] = True if row['dpdStateMachine']['value'] in ['OFF'] else False\",\n",
    "                    'gainStateMachine': \"row['gainStateMachine_abnormal'] = True if row['gainStateMachine']['value'] in ['CtrlGainStateIdle:started', 'ns:stopped'] else False\", \n",
    "                    'linearizationStateMachine': \"row['linearizationStateMachine_abnormal'] = True if row['linearizationStateMachine']['value'] in ['ns:stopped'] else False\"\n",
    "                }, 'search_type': 'range', 'extract_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "    'elog read':{'kv_exps': [\n",
    "                    '{}[{timestamp}]{}Lin. fault port{LinFault}',\n",
    "                    '{}[{timestamp}]{}POWER LOST{PowerLost}',\n",
    "                    '{}[{timestamp}]{}PSU enters{PsuEnter}',\n",
    "                    '{}[{timestamp}]{}JESD LINK FAILURE{JesdLinkFailure}',\n",
    "                    '{}[{timestamp}]{}#### DPDCONTROLLER{DpdController}',\n",
    "                ], 'filter_exps': {\n",
    "                    'LinFault': \"\",\n",
    "                    'PowerLost': \"\",\n",
    "                    'PsuEnter': \"\",\n",
    "                    'JesdLinkFailure': \"\",\n",
    "                    'DpdController': \"\",\n",
    "                }, 'search_type': 'range', 'extract_type': 'embedded', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} elog read{}', 'end_exp': '{}End of log{}'},\n",
    "    'ts r':{'kv_exps': [\n",
    "                    '{}Board{}: {Board} {}',\n",
    "                    '{}DcPaVdd:0{}: {DcPaVdd_0} {}',\n",
    "                    '{}DcPaVdd:1{}: {DcPaVdd_1} {}',\n",
    "                    '{}DcTrxVcc{}: {DcTrxVcc} {}',\n",
    "                    '{}Dra:0{}: {Dra_0} {}',\n",
    "                    '{}PaDriver:A{}: {PaDriver_A} {}',\n",
    "                    '{}PaDriver:B{}: {PaDriver_B} {}',\n",
    "                    '{}PaDriver:C{}: {PaDriver_C} {}',\n",
    "                    '{}PaDriver:D{}: {PaDriver_D} {}',\n",
    "                    '{}PaFinal:A{}: {PaFinal_A} {}',\n",
    "                    '{}PaFinal:B{}: {PaFinal_B} {}',\n",
    "                    '{}PaFinal:C{}: {PaFinal_C} {}',\n",
    "                    '{}PaFinal:D{}: {PaFinal_D} {}',\n",
    "                    '{}Rx:A{}: {Rx_A} {}',\n",
    "                    '{}Rx:B{}: {Rx_B} {}',\n",
    "                    '{}Rx:C{}: {Rx_C} {}',\n",
    "                    '{}Rx:D{}: {Rx_D} {}',\n",
    "                    '{}Tor:A{}: {Tor_A} {}',\n",
    "                    '{}Tor:B{}: {Tor_B} {}',\n",
    "                    '{}Tor:C{}: {Tor_C} {}',\n",
    "                    '{}Tor:D{}: {Tor_D} {}',\n",
    "                    '{}Touch: {Touch} {}',\n",
    "                    '{}TrxTemp:0{}: {TrxTemp_0} {}',\n",
    "                    '{}Tx:A{}: {Tx_A} {}',\n",
    "                    '{}Tx:B{}: {Tx_B} {}',\n",
    "                    '{}Tx:C{}: {Tx_C} {}',\n",
    "                    '{}Tx:D{}: {Tx_D} {}',\n",
    "                ], 'filter_exps': {\n",
    "                    'Board': \"row['Board_abnormal'] = True if (float(row['Board']['value']) < 0) | (float(row['Board']['value']) > 50) else False\",\n",
    "                    'DcPaVdd_0': \"row['DcPaVdd_0_abnormal'] = True if (float(row['DcPaVdd_0']['value']) < 0) | (float(row['DcPaVdd_0']['value']) > 60) else False\",\n",
    "                    'DcPaVdd_1': \"row['DcPaVdd_1_abnormal'] = True if (float(row['DcPaVdd_1']['value']) < 0) | (float(row['DcPaVdd_1']['value']) > 60) else False\",\n",
    "                    'DcTrxVcc': \"row['DcTrxVcc_abnormal'] = True if (float(row['DcTrxVcc']['value']) < 0) | (float(row['DcTrxVcc']['value']) > 40) else False\",\n",
    "                    'Dra_0': \"row['Dra_0_abnormal'] = True if (float(row['Dra_0']['value']) < 0) | (float(row['Dra_0']['value']) > 60) else False\",\n",
    "                    'PaDriver_A': \"row['PaDriver_A_abnormal'] = True if (float(row['PaDriver_A']['value']) < 0) | (float(row['PaDriver_A']['value']) > 70) else False\",\n",
    "                    'PaDriver_B': \"row['PaDriver_B_abnormal'] = True if (float(row['PaDriver_B']['value']) < 0) | (float(row['PaDriver_B']['value']) > 70) else False\",\n",
    "                    'PaDriver_C': \"row['PaDriver_C_abnormal'] = True if (float(row['PaDriver_C']['value']) < 0) | (float(row['PaDriver_C']['value']) > 70) else False\",\n",
    "                    'PaDriver_D': \"row['PaDriver_D_abnormal'] = True if (float(row['PaDriver_D']['value']) < 0) | (float(row['PaDriver_D']['value']) > 70) else False\",\n",
    "                    'PaFinal_A': \"row['PaFinal_A_abnormal'] = True if (float(row['PaFinal_A']['value']) < 0) | (float(row['PaFinal_A']['value']) > 80) else False\",\n",
    "                    'PaFinal_B': \"row['PaFinal_B_abnormal'] = True if (float(row['PaFinal_B']['value']) < 0) | (float(row['PaFinal_B']['value']) > 80) else False\",\n",
    "                    'PaFinal_C': \"row['PaFinal_C_abnormal'] = True if (float(row['PaFinal_C']['value']) < 0) | (float(row['PaFinal_C']['value']) > 80) else False\",\n",
    "                    'PaFinal_D': \"row['PaFinal_D_abnormal'] = True if (float(row['PaFinal_D']['value']) < 0) | (float(row['PaFinal_D']['value']) > 80) else False\",\n",
    "                    'Rx_A': \"row['Rx_A_abnormal'] = True if (float(row['Rx_A']['value']) < 0) | (float(row['Rx_A']['value']) > 55) else False\",\n",
    "                    'Rx_B': \"row['Rx_B_abnormal'] = True if (float(row['Rx_B']['value']) < 0) | (float(row['Rx_B']['value']) > 55) else False\",\n",
    "                    'Rx_C': \"row['Rx_C_abnormal'] = True if (float(row['Rx_C']['value']) < 0) | (float(row['Rx_C']['value']) > 55) else False\",\n",
    "                    'Rx_D': \"row['Rx_D_abnormal'] = True if (float(row['Rx_D']['value']) < 0) | (float(row['Rx_D']['value']) > 55) else False\",\n",
    "                    'Tor_A': \"row['Tor_A_abnormal'] = True if (float(row['Tor_A']['value']) < 0) | (float(row['Tor_A']['value']) > 55) else False\",\n",
    "                    'Tor_B': \"row['Tor_B_abnormal'] = True if (float(row['Tor_B']['value']) < 0) | (float(row['Tor_B']['value']) > 55) else False\",\n",
    "                    'Tor_C': \"row['Tor_C_abnormal'] = True if (float(row['Tor_C']['value']) < 0) | (float(row['Tor_C']['value']) > 55) else False\",\n",
    "                    'Tor_D': \"row['Tor_D_abnormal'] = True if (float(row['Tor_D']['value']) < 0) | (float(row['Tor_D']['value']) > 55) else False\",\n",
    "                    'TrxTemp_0': \"row['TrxTemp_0_abnormal'] = True if (float(row['TrxTemp_0']['value']) < 0) | (float(row['TrxTemp_0']['value']) > 75) else False\",\n",
    "                    'Tx_A': \"row['Tx_A_abnormal'] = True if (float(row['Tx_A']['value']) < 0) | (float(row['Tx_A']['value']) > 55) else False\",\n",
    "                    'Tx_B': \"row['Tx_B_abnormal'] = True if (float(row['Tx_B']['value']) < 0) | (float(row['Tx_B']['value']) > 55) else False\",\n",
    "                    'Tx_C': \"row['Tx_C_abnormal'] = True if (float(row['Tx_C']['value']) < 0) | (float(row['Tx_C']['value']) > 55) else False\",\n",
    "                    'Tx_D': \"row['Tx_D_abnormal'] = True if (float(row['Tx_D']['value']) < 0) | (float(row['Tx_D']['value']) > 55) else False\",\n",
    "                }, 'search_type': 'range', 'extract_type': 'batch_notime', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} ts r{}', 'end_exp': '{}================{}'},\n",
    "    'cs r':{'kv_exps': [\n",
    "                    '{}PaDriver0:A{}: {PaDriver0_A} {}',\n",
    "                    '{}PaDriver0:B{}: {PaDriver0_B} {}',\n",
    "                    '{}PaDriver0:C{}: {PaDriver0_C} {}',\n",
    "                    '{}PaDriver0:D{}: {PaDriver0_D} {}',\n",
    "                    '{}PaDriver1:A{}: {PaDriver1_A} {}',\n",
    "                    '{}PaDriver1:B{}: {PaDriver1_B} {}',\n",
    "                    '{}PaDriver1:C{}: {PaDriver1_C} {}',\n",
    "                    '{}PaDriver1:D{}: {PaDriver1_D} {}',\n",
    "                    '{}PaFinal0:A{}: {PaFinal0_A} {}',\n",
    "                    '{}PaFinal0:B{}: {PaFinal0_B} {}',\n",
    "                    '{}PaFinal0:C{}: {PaFinal0_C} {}',\n",
    "                    '{}PaFinal0:D{}: {PaFinal0_D} {}',\n",
    "                    '{}PaFinal1:A{}: {PaFinal1_A} {}',\n",
    "                    '{}PaFinal1:B{}: {PaFinal1_B} {}',\n",
    "                    '{}PaFinal1:C{}: {PaFinal1_C} {}',\n",
    "                    '{}PaFinal1:D{}: {PaFinal1_D} {}',\n",
    "                ], 'filter_exps': {\n",
    "                    'PaDriver0_A': \"row['PaDriver0_A_abnormal'] = True if (float(row['PaDriver0_A']['value']) < 0.15) | (float(row['PaDriver0_A']['value']) > 0.25) else False\",\n",
    "                    'PaDriver0_B': \"row['PaDriver0_B_abnormal'] = True if (float(row['PaDriver0_B']['value']) < 0.15) | (float(row['PaDriver0_B']['value']) > 0.25) else False\",\n",
    "                    'PaDriver0_C': \"row['PaDriver0_C_abnormal'] = True if (float(row['PaDriver0_C']['value']) < 0.15) | (float(row['PaDriver0_C']['value']) > 0.25) else False\",\n",
    "                    'PaDriver0_D': \"row['PaDriver0_D_abnormal'] = True if (float(row['PaDriver0_D']['value']) < 0.15) | (float(row['PaDriver0_D']['value']) > 0.25) else False\",\n",
    "                    'PaDriver1_A': \"row['PaDriver1_A_abnormal'] = True if (float(row['PaDriver1_A']['value']) < 0.15) | (float(row['PaDriver1_A']['value']) > 0.25) else False\",\n",
    "                    'PaDriver1_B': \"row['PaDriver1_B_abnormal'] = True if (float(row['PaDriver1_B']['value']) < 0.15) | (float(row['PaDriver1_B']['value']) > 0.25) else False\",\n",
    "                    'PaDriver1_C': \"row['PaDriver1_C_abnormal'] = True if (float(row['PaDriver1_C']['value']) < 0.15) | (float(row['PaDriver1_C']['value']) > 0.25) else False\",\n",
    "                    'PaDriver1_D': \"row['PaDriver1_D_abnormal'] = True if (float(row['PaDriver1_D']['value']) < 0.15) | (float(row['PaDriver1_D']['value']) > 0.25) else False\",\n",
    "                    'PaFinal0_A': \"row['PaFinal0_A_abnormal'] = True if (float(row['PaFinal0_A']['value']) < 0.2) | (float(row['PaFinal0_A']['value']) > 0.7) else False\",\n",
    "                    'PaFinal0_B': \"row['PaFinal0_B_abnormal'] = True if (float(row['PaFinal0_B']['value']) < 0.2) | (float(row['PaFinal0_B']['value']) > 0.7) else False\",\n",
    "                    'PaFinal0_C': \"row['PaFinal0_C_abnormal'] = True if (float(row['PaFinal0_C']['value']) < 0.2) | (float(row['PaFinal0_C']['value']) > 0.7) else False\",\n",
    "                    'PaFinal0_D': \"row['PaFinal0_D_abnormal'] = True if (float(row['PaFinal0_D']['value']) < 0.2) | (float(row['PaFinal0_D']['value']) > 0.7) else False\",\n",
    "                    'PaFinal1_A': \"row['PaFinal1_A_abnormal'] = True if (float(row['PaFinal1_A']['value']) < 0.2) | (float(row['PaFinal1_A']['value']) > 0.7) else False\",\n",
    "                    'PaFinal1_B': \"row['PaFinal1_B_abnormal'] = True if (float(row['PaFinal1_B']['value']) < 0.2) | (float(row['PaFinal1_B']['value']) > 0.7) else False\",\n",
    "                    'PaFinal1_C': \"row['PaFinal1_C_abnormal'] = True if (float(row['PaFinal1_C']['value']) < 0.2) | (float(row['PaFinal1_C']['value']) > 0.7) else False\",\n",
    "                    'PaFinal1_D': \"row['PaFinal1_D_abnormal'] = True if (float(row['PaFinal1_D']['value']) < 0.2) | (float(row['PaFinal1_D']['value']) > 0.7) else False\",\n",
    "                }, 'search_type': 'range', 'extract_type': 'batch_notime', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} cs r{}', 'end_exp': '{}================{}'},\n",
    "    'vs r':{'kv_exps': [\n",
    "                    '{}Dc1_35{}: {Dc1_35} {}',\n",
    "                    '{}Dc1_8{}: {Dc1_8} {}',\n",
    "                    '{}Dc3_3{}: {Dc3_3} {}',\n",
    "                    '{}Dc3_7{}: {Dc3_7} {}',\n",
    "                    '{}Dc5_11{}: {Dc5_11} {}',\n",
    "                    '{}DcAux{}: {DcAux} {}',\n",
    "                    '{}DcTrxA1_3:0{}: {DcTrxA1_3_0} {}',\n",
    "                    '{}DcTrxA1_8:0{}: {DcTrxA1_8_0} {}',\n",
    "                    '{}DcTrxD1:0{}: {DcTrxD1_0} {}',\n",
    "                    '{}DcTrxVcc{}: {DcTrxVcc} {}',\n",
    "                    '{}DcXenon0_842:0{}: {DcXenon0_842_0} {}',\n",
    "                    '{}DcXenon0_9:0{}: {DcXenon0_9_0} {}',\n",
    "                    '{}DcXenonCore:0{}: {DcXenonCore_0} {}',\n",
    "                    '{}PaDriverVdd:A{}: {PaDriverVdd_A} {}',\n",
    "                    '{}PaDriverVdd:B{}: {PaDriverVdd_B} {}',\n",
    "                    '{}PaDriverVdd:C{}: {PaDriverVdd_C} {}',\n",
    "                    '{}PaDriverVdd:D{}: {PaDriverVdd_D} {}',\n",
    "                    '{}PaFinalVdd:A{}: {PaFinalVdd_A} {}',\n",
    "                    '{}PaFinalVdd:B{}: {PaFinalVdd_B} {}',\n",
    "                    '{}PaFinalVdd:C{}: {PaFinalVdd_C} {}',\n",
    "                    '{}PaFinalVdd:D{}: {PaFinalVdd_D} {}',\n",
    "                    '{}Ret{}: {Ret} {}',\n",
    "                ], 'filter_exps': {\n",
    "                    'Dc1_35': \"row['Dc1_35_abnormal'] = True if (float(row['Dc1_35']['value']) < 1.32) | (float(row['Dc1_35']['value']) > 1.38) else False\",\n",
    "                    'Dc1_8': \"row['Dc1_8_abnormal'] = True if (float(row['Dc1_8']['value']) < 1.75) | (float(row['Dc1_8']['value']) > 1.85) else False\",\n",
    "                    'Dc3_3': \"row['Dc3_3_abnormal'] = True if (float(row['Dc3_3']['value']) < 3.25) | (float(row['Dc3_3']['value']) > 3.35) else False\",\n",
    "                    'Dc3_7': \"row['Dc3_7_abnormal'] = True if (float(row['Dc3_7']['value']) < 3.65) | (float(row['Dc3_7']['value']) > 3.75) else False\",\n",
    "                    'Dc5_11': \"row['Dc5_11_abnormal'] = True if (float(row['Dc5_11']['value']) < 5.05) | (float(row['Dc5_11']['value']) > 5.15) else False\",\n",
    "                    'DcAux': \"row['DcAux_abnormal'] = True if (float(row['DcAux']['value']) < 10.3) | (float(row['DcAux']['value']) > 10.5) else False\",\n",
    "                    'DcTrxA1_3_0': \"row['DcTrxA1_3_0_abnormal'] = True if (float(row['DcTrxA1_3_0']['value']) < 1.27) | (float(row['DcTrxA1_3_0']['value']) > 1.33) else False\",\n",
    "                    'DcTrxA1_8_0': \"row['DcTrxA1_8_0_abnormal'] = True if (float(row['DcTrxA1_8_0']['value']) < 1.77) | (float(row['DcTrxA1_8_0']['value']) > 1.83) else False\",\n",
    "                    'DcTrxD1_0': \"row['DcTrxD1_0_abnormal'] = True if (float(row['DcTrxD1_0']['value']) < 0.99) | (float(row['DcTrxD1_0']['value']) > 1.05) else False\",\n",
    "                    'DcTrxVcc': \"row['DcTrxVcc_abnormal'] = True if (float(row['DcTrxVcc']['value']) < 8.9) | (float(row['DcTrxVcc']['value']) > 9.1) else False\",\n",
    "                    'DcXenon0_842_0': \"row['DcXenon0_842_0_abnormal'] = True if (float(row['DcXenon0_842_0']['value']) < 0.823) | (float(row['DcXenon0_842_0']['value']) > 0.883) else False\",\n",
    "                    'DcXenon0_9_0': \"row['DcXenon0_9_0_abnormal'] = True if (float(row['DcXenon0_9_0']['value']) < 0.87) | (float(row['DcXenon0_9_0']['value']) > 0.93) else False\",\n",
    "                    'DcXenonCore_0': \"row['DcXenonCore_0_abnormal'] = True if (float(row['DcXenonCore_0']['value']) < 0.711) | (float(row['DcXenonCore_0']['value']) > 0.755) else False\",\n",
    "                    'PaDriverVdd_A': \"row['PaDriverVdd_A_abnormal'] = True if (float(row['PaDriverVdd_A']['value']) < 40) | (float(row['PaDriverVdd_A']['value']) > 51) else False\",\n",
    "                    'PaDriverVdd_B': \"row['PaDriverVdd_B_abnormal'] = True if (float(row['PaDriverVdd_B']['value']) < 40) | (float(row['PaDriverVdd_B']['value']) > 51) else False\",\n",
    "                    'PaDriverVdd_C': \"row['PaDriverVdd_C_abnormal'] = True if (float(row['PaDriverVdd_C']['value']) < 40) | (float(row['PaDriverVdd_C']['value']) > 51) else False\",\n",
    "                    'PaDriverVdd_D': \"row['PaDriverVdd_D_abnormal'] = True if (float(row['PaDriverVdd_D']['value']) < 40) | (float(row['PaDriverVdd_D']['value']) > 51) else False\",\n",
    "                    'PaFinalVdd_A': \"row['PaFinalVdd_A_abnormal'] = True if (float(row['PaFinalVdd_A']['value']) < 40) | (float(row['PaFinalVdd_A']['value']) > 51) else False\",\n",
    "                    'PaFinalVdd_B': \"row['PaFinalVdd_B_abnormal'] = True if (float(row['PaFinalVdd_B']['value']) < 40) | (float(row['PaFinalVdd_B']['value']) > 51) else False\",\n",
    "                    'PaFinalVdd_C': \"row['PaFinalVdd_C_abnormal'] = True if (float(row['PaFinalVdd_C']['value']) < 40) | (float(row['PaFinalVdd_C']['value']) > 51) else False\",\n",
    "                    'PaFinalVdd_D': \"row['PaFinalVdd_D_abnormal'] = True if (float(row['PaFinalVdd_D']['value']) < 40) | (float(row['PaFinalVdd_D']['value']) > 51) else False\",\n",
    "                    'Ret': \"row['Ret_abnormal'] = True if (float(row['Ret']['value']) < 29.37) | (float(row['Ret']['value']) > 29.43) else False\",\n",
    "                }, 'search_type': 'range', 'extract_type': 'batch_notime', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} vs r{}', 'end_exp': '{}================{}'},\n",
    "    'rvc r':{'kv_exps': [\n",
    "                    '{}RxRfGain:A{}: {RxRfGain_A}\\n',\n",
    "                    '{}RxRfGain:B{}: {RxRfGain_B}\\n',\n",
    "                    '{}RxRfGain:C{}: {RxRfGain_C}\\n',\n",
    "                    '{}RxRfGain:D{}: {RxRfGain_D}\\n',\n",
    "                    '{}RxRfGain0:A{}: {RxRfGain0_A}\\n',\n",
    "                    '{}RxRfGain0:B{}: {RxRfGain0_B}\\n',\n",
    "                    '{}RxRfGain0:C{}: {RxRfGain0_C}\\n',\n",
    "                    '{}RxRfGain0:D{}: {RxRfGain0_D}\\n',\n",
    "                    '{}TorAttenuator:A{}: {TorAttenuator_A}\\n',\n",
    "                    '{}TorAttenuator:B{}: {TorAttenuator_B}\\n',\n",
    "                    '{}TorAttenuator:C{}: {TorAttenuator_C}\\n',\n",
    "                    '{}TorAttenuator:D{}: {TorAttenuator_D}\\n',\n",
    "                    '{}TxAttenuation:A{}: {TxAttenuation_A}\\n',\n",
    "                    '{}TxAttenuation:B{}: {TxAttenuation_B}\\n',\n",
    "                    '{}TxAttenuation:C{}: {TxAttenuation_C}\\n',\n",
    "                    '{}TxAttenuation:D{}: {TxAttenuation_D}\\n',\n",
    "                    '{}TxAttenuation0:A{}: {TxAttenuation0_A}\\n',\n",
    "                    '{}TxAttenuation0:B{}: {TxAttenuation0_B}\\n',\n",
    "                    '{}TxAttenuation0:C{}: {TxAttenuation0_C}\\n',\n",
    "                    '{}TxAttenuation0:D{}: {TxAttenuation0_D}\\n',\n",
    "                    '{}TxGain:A{}: {TxGain_A}\\n',\n",
    "                    '{}TxGain:B{}: {TxGain_B}\\n',\n",
    "                    '{}TxGain:C{}: {TxGain_C}\\n',\n",
    "                    '{}TxGain:D{}: {TxGain_D}\\n',\n",
    "                ], 'filter_exps': {\n",
    "                    'RxRfGain_A': \"row['RxRfGain_A_abnormal'] = True if (float(row['RxRfGain_A']['value']) < 7) | (float(row['RxRfGain_A']['value']) > 13) else False\",\n",
    "                    'RxRfGain_B': \"row['RxRfGain_B_abnormal'] = True if (float(row['RxRfGain_B']['value']) < 7) | (float(row['RxRfGain_B']['value']) > 13) else False\",\n",
    "                    'RxRfGain_C': \"row['RxRfGain_C_abnormal'] = True if (float(row['RxRfGain_C']['value']) < 7) | (float(row['RxRfGain_C']['value']) > 13) else False\",\n",
    "                    'RxRfGain_D': \"row['RxRfGain_D_abnormal'] = True if (float(row['RxRfGain_D']['value']) < 7) | (float(row['RxRfGain_D']['value']) > 13) else False\",\n",
    "                    'RxRfGain0_A': \"row['RxRfGain0_A_abnormal'] = True if (float(row['RxRfGain0_A']['value']) < 228) | (float(row['RxRfGain0_A']['value']) > 228) else False\",\n",
    "                    'RxRfGain0_B': \"row['RxRfGain0_B_abnormal'] = True if (float(row['RxRfGain0_B']['value']) < 228) | (float(row['RxRfGain0_B']['value']) > 228) else False\",\n",
    "                    'RxRfGain0_C': \"row['RxRfGain0_C_abnormal'] = True if (float(row['RxRfGain0_C']['value']) < 228) | (float(row['RxRfGain0_C']['value']) > 228) else False\",\n",
    "                    'RxRfGain0_D': \"row['RxRfGain0_D_abnormal'] = True if (float(row['RxRfGain0_D']['value']) < 228) | (float(row['RxRfGain0_D']['value']) > 228) else False\",\n",
    "                    'TorAttenuator_A': \"row['TorAttenuator_A_abnormal'] = True if (float(row['TorAttenuator_A']['value']) < 218) | (float(row['TorAttenuator_A']['value']) > 247) else False\",\n",
    "                    'TorAttenuator_B': \"row['TorAttenuator_B_abnormal'] = True if (float(row['TorAttenuator_B']['value']) < 218) | (float(row['TorAttenuator_B']['value']) > 247) else False\",\n",
    "                    'TorAttenuator_C': \"row['TorAttenuator_C_abnormal'] = True if (float(row['TorAttenuator_C']['value']) < 218) | (float(row['TorAttenuator_C']['value']) > 247) else False\",\n",
    "                    'TorAttenuator_D': \"row['TorAttenuator_D_abnormal'] = True if (float(row['TorAttenuator_D']['value']) < 218) | (float(row['TorAttenuator_D']['value']) > 247) else False\",\n",
    "                    'TxAttenuation_A': \"row['TxAttenuation_A_abnormal'] = True if (float(row['TxAttenuation_A']['value']) < 9) | (float(row['TxAttenuation_A']['value']) > 25) else False\",\n",
    "                    'TxAttenuation_B': \"row['TxAttenuation_B_abnormal'] = True if (float(row['TxAttenuation_B']['value']) < 9) | (float(row['TxAttenuation_B']['value']) > 25) else False\",\n",
    "                    'TxAttenuation_C': \"row['TxAttenuation_C_abnormal'] = True if (float(row['TxAttenuation_C']['value']) < 9) | (float(row['TxAttenuation_C']['value']) > 25) else False\",\n",
    "                    'TxAttenuation_D': \"row['TxAttenuation_D_abnormal'] = True if (float(row['TxAttenuation_D']['value']) < 9) | (float(row['TxAttenuation_D']['value']) > 25) else False\",\n",
    "                    'TxAttenuation0_A': \"row['TxAttenuation0_A_abnormal'] = True if (float(row['TxAttenuation0_A']['value']) < 1300) | (float(row['TxAttenuation0_A']['value']) > 1300) else False\",\n",
    "                    'TxAttenuation0_B': \"row['TxAttenuation0_B_abnormal'] = True if (float(row['TxAttenuation0_B']['value']) < 1300) | (float(row['TxAttenuation0_B']['value']) > 1300) else False\",\n",
    "                    'TxAttenuation0_C': \"row['TxAttenuation0_C_abnormal'] = True if (float(row['TxAttenuation0_C']['value']) < 1300) | (float(row['TxAttenuation0_C']['value']) > 1300) else False\",\n",
    "                    'TxAttenuation0_D': \"row['TxAttenuation0_D_abnormal'] = True if (float(row['TxAttenuation0_D']['value']) < 1300) | (float(row['TxAttenuation0_D']['value']) > 1300) else False\",\n",
    "                    'TxGain_A': \"row['TxGain_A_abnormal'] = True if (float(row['TxGain_A']['value']) < 1000) | (float(row['TxGain_A']['value']) > 3000) else False\",\n",
    "                    'TxGain_B': \"row['TxGain_B_abnormal'] = True if (float(row['TxGain_B']['value']) < 1000) | (float(row['TxGain_B']['value']) > 3000) else False\",\n",
    "                    'TxGain_C': \"row['TxGain_C_abnormal'] = True if (float(row['TxGain_C']['value']) < 1000) | (float(row['TxGain_C']['value']) > 3000) else False\",\n",
    "                    'TxGain_D': \"row['TxGain_D_abnormal'] = True if (float(row['TxGain_D']['value']) < 1000) | (float(row['TxGain_D']['value']) > 3000) else False\",\n",
    "                }, 'search_type': 'range', 'extract_type': 'batch_notime', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} rvc r{}', 'end_exp': '{}================{}'},\n",
    "\n",
    "}\n",
    "\n",
    "def abnormal_condition(row, code):\n",
    "    exec(code)\n",
    "    return row\n",
    "\n",
    "origin_data = ''\n",
    "if os.path.exists(origin_data_output):\n",
    "    origin_data = pd.read_csv(origin_data_output)\n",
    "    finished_files = list(set(origin_data.file_name.values))\n",
    "\n",
    "for file_index, file_name in enumerate(iterate_files_in_directory(dir_path)):\n",
    "    if type(origin_data) != str:\n",
    "        if file_name in finished_files:\n",
    "            continue\n",
    "    \n",
    "    path = f'{dir_path}/{file_name}'\n",
    "    print(f'{file_index} Start handle {file_name}.')\n",
    "    with open(path, 'r') as f:\n",
    "        try:\n",
    "            lines = f.readlines()\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            continue\n",
    "\n",
    "        # find map table\n",
    "        flag = False\n",
    "        product_flag = False\n",
    "        table = {}\n",
    "        for line in lines:\n",
    "            if list(set([True if word in line else False  for word in map_table_start_mark]))[0] == True:\n",
    "                flag = True\n",
    "            if flag:\n",
    "                r = parse(map_table_exp, line)\n",
    "                if r is not None:\n",
    "                    table[r.named['assigned_name'].strip()] = r.named['product_name'].strip()\n",
    "                    if product_name == r.named['product_name']:\n",
    "                        product_flag = True\n",
    "            if (map_table_end_mark in line) & flag:\n",
    "                break\n",
    "                \n",
    "        if not product_flag:\n",
    "            continue\n",
    "            \n",
    "        result = []\n",
    "        cs = ContentSearch(lines)\n",
    "        for cmd in exps.keys():\n",
    "            search_contents = cs.search_by_range(exps[cmd]['start_exp'], exps[cmd]['end_exp'])\n",
    "            cmd_batch = {}\n",
    "            for search_content in search_contents:\n",
    "                if search_content['start_exp_parse']['assigned_name'] not in table:\n",
    "                    continue\n",
    "                if product_name != table[search_content['start_exp_parse']['assigned_name']]:\n",
    "                    continue\n",
    "\n",
    "                if search_content['start_exp_parse']['assigned_name'] not in cmd_batch:\n",
    "                    cmd_batch[search_content['start_exp_parse']['assigned_name']] = 0\n",
    "                else:\n",
    "                    cmd_batch[search_content['start_exp_parse']['assigned_name']] += 1\n",
    "                kve = KeyValueExtract(search_content['lines'])\n",
    "                if exps[cmd]['extract_type'] == 'batch':\n",
    "                    kv = kve.extract_in_batch(exps[cmd]['kv_exps'])\n",
    "                    for keyword in exps[cmd]['filter_exps'].keys():\n",
    "                        an = keyword+'_abnormal'\n",
    "                        ptmp = pd.DataFrame(kv)\n",
    "                        if len(ptmp) == 0:\n",
    "                            break\n",
    "                        ptmp = ptmp.apply(lambda x: abnormal_condition(x, exps[cmd]['filter_exps'][keyword]), axis=1)\n",
    "                        abnormal = []\n",
    "                        for dot in list(ptmp.loc[(ptmp[an] == True), keyword].values):\n",
    "                            dot['global_index'] = search_content['indices'][dot['index']]\n",
    "                            dot['search_index'] = dot.pop('index')\n",
    "                            abnormal.append(dot)\n",
    "                        result.append({'file_name':file_name, 'product_name':product_name, 'assigned_name': search_content['start_exp_parse']['assigned_name'], 'cmd':cmd , 'cmd_batch':cmd_batch[search_content['start_exp_parse']['assigned_name']],\n",
    "                                      'keyword': keyword, 'abnormal': abnormal})\n",
    "                elif exps[cmd]['extract_type'] == 'batch_notime':\n",
    "                    kv = kve.extract_in_batch_notime(exps[cmd]['kv_exps'])\n",
    "                    for keyword in exps[cmd]['filter_exps'].keys():\n",
    "                        an = keyword+'_abnormal'\n",
    "                        ptmp = pd.DataFrame(kv)\n",
    "                        if len(ptmp) == 0:\n",
    "                            break\n",
    "                        ptmp = ptmp.apply(lambda x: abnormal_condition(x, exps[cmd]['filter_exps'][keyword]), axis=1)\n",
    "                        abnormal = []\n",
    "                        for dot in list(ptmp.loc[(ptmp[an] == True), keyword].values):\n",
    "                            dot['global_index'] = search_content['indices'][dot['index']]\n",
    "                            dot['search_index'] = dot.pop('index')\n",
    "                            abnormal.append(dot)\n",
    "                        result.append({'file_name':file_name, 'product_name':product_name, 'assigned_name': search_content['start_exp_parse']['assigned_name'], 'cmd':cmd , 'cmd_batch':cmd_batch[search_content['start_exp_parse']['assigned_name']],\n",
    "                                      'keyword': keyword, 'abnormal': abnormal})\n",
    "                elif exps[cmd]['extract_type'] == 'embedded':\n",
    "                    kv = kve.extract_in_embedded(exps[cmd]['kv_exps'])\n",
    "                    for keyword in exps[cmd]['filter_exps'].keys():\n",
    "                        abnormal = []\n",
    "                        if keyword in kv:\n",
    "                            for dot in kv[keyword]:\n",
    "                                dot['global_index'] = search_content['indices'][dot['index']]\n",
    "                                dot['search_index'] = dot.pop('index')\n",
    "                                abnormal.append(dot)\n",
    "                        result.append({'file_name':file_name, 'product_name':product_name, 'assigned_name': search_content['start_exp_parse']['assigned_name'], 'cmd':cmd , 'cmd_batch':cmd_batch[search_content['start_exp_parse']['assigned_name']],\n",
    "                                      'keyword': keyword, 'abnormal': abnormal})\n",
    "    pd.DataFrame(result).to_csv(origin_data_output, index=False, mode='a', header=not os.path.exists(origin_data_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8720de-d625-4832-bf87-04fbe7045793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d47fd-8821-4a25-824f-4c7dbfb8cb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.read_csv(origin_data_output)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18675aa9-f395-4554-990d-41099c5e4770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kve = KeyValueExtract(search_result['trx status'][0]['lines'])\n",
    "kve.extract_in_batch(extract_exps['trx status']['kv_exps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b968c-2ce8-4d43-b11f-6efba7208e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgm = 'D:/projects/ericsson_flow/new_files/Dot4455/AKH167_242367_230215_112831_CET_MSRBS-LN_CXP2010174-1_R56J19_dcgm.zip'\n",
    "configs = {\n",
    "    'telog':{'extract_path': '*_logfiles.zip/teread.log', 'cmds':{\n",
    "                'telog read':{'extract_exps': [], \n",
    "                             'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "                            }},\n",
    "    # 'elog':{'extract_path': '*_e2.log.gz/*_dcg_e2.log', 'cmds':[\n",
    "    #             {'extract_exps': [], \n",
    "    #              'cmd':'', 'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "    #             ]},\n",
    "    # 'modump':{'extract_path': '*_modump.zip/*_dcg_k.log.gz/*_dcg_k.log', 'cmds':[\n",
    "    #             {'extract_exps': [], \n",
    "    #              'cmd':'', 'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "    #             ]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabaf4a-e96f-48f8-92ed-c0769ad94d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # init \n",
    "#     files_cmds_content = {}\n",
    "#     for file_name in configs.keys():\n",
    "#         files_cmds_content[file_name] = {}\n",
    "#         for cmd in configs[file_name]['cmds'].keys():\n",
    "#             files_cmds_content[file_name][cmd] = {}\n",
    "\n",
    "#     # find cmd content\n",
    "#     for file_name in files_origin_lines.keys():\n",
    "#         for cmd in configs[file_name]['cmds'].keys():\n",
    "#             flag = False\n",
    "#             lines = []\n",
    "#             assigned_name = ''\n",
    "#             for index, line in enumerate(files_origin_lines[file_name]):\n",
    "#                 if flag:\n",
    "#                     r = parse(cmd['end_exp'], line)\n",
    "#                     if r is not None:\n",
    "#                         flag = False\n",
    "#                         files_cmds_content[file_name][cmd][assigned_name].append(lines)\n",
    "#                         lines = []\n",
    "#                     else:\n",
    "#                         lines.append({'global_index':index, 'text':line})\n",
    "#                         continue\n",
    "#                 r = parse(cmd['start_exp'], line)\n",
    "#                 if r is not None:\n",
    "#                     if r['assigned_name'] not in files_cmds_content[file_name][cmd]:\n",
    "#                         files_cmds_content[file_name][cmd][r['assigned_name']] = []\n",
    "#                     flag = True\n",
    "#                     assigned_name = r['assigned_name']\n",
    "#                     lines.append({'global_index':index, 'text':line})\n",
    "\n",
    "#     # extract key value\n",
    "#     for file_name in files_origin_lines.keys():\n",
    "#         for cmd in configs[file_name]['cmds'].keys():\n",
    "#             for assigned in files_cmds_content[file_name][cmd].keys():\n",
    "#                 cmd_batch = files_cmds_content[file_name][cmd][assigned]\n",
    "#                 for batch_index, lines in enumerate(cmd_batch):\n",
    "#                     tmp = {}\n",
    "#                     cmd_config = configs[file_name]['cmds'][cmd]\n",
    "#                     for extract_key in cmd_config['extract_exps'].keys():\n",
    "#                         if extract_key != 'timestamp':\n",
    "#                             tmp[extract_key] = []\n",
    "\n",
    "#                     if cmd_config['time_type'] == 'embedded':\n",
    "#                         for line in lines:\n",
    "#                             for extract_key in cmd_config['extract_exps'].keys():\n",
    "#                                 r = parse(cmd_config['extract_exps'][extract_key]['exp'], line['text'])\n",
    "#                                 if r is not None:\n",
    "#                                     item = {\n",
    "#                                             'file_name':file_name, 'assigned_name':content['assigned_name'], \n",
    "#                                             'cmd':cmd, 'keywords':extract_key, 'global_index': line['global_index'], 'value':'',\n",
    "#                                             'cmd_batch_index': batch_index, 'timestamp': convert_datetime_timestamp(r.named['timestamp']), 'x': random.randint(0, 100), 'y':random.randint(0, 100)\n",
    "#                                             }\n",
    "#                                     tmp[extract_key].append(item)\n",
    "#                     elif exps[key]['time_type'] == 'batch':\n",
    "#                         timestamp = ''\n",
    "#                         for line in lines:\n",
    "#                             for extract_key in cmd_config['extract_exps'].keys():\n",
    "#                                 r = parse(cmd_config['extract_exps'][extract_key]['exp'], line['text'])\n",
    "#                                 if r is not None:\n",
    "#                                     if 'timestamp' in r.named:\n",
    "#                                         timestamp = convert_datetime_timestamp(r.named['timestamp'])\n",
    "#                                         break\n",
    "#                                     item = {\n",
    "#                                             'file_name':file_name, 'product_name':table[content['assigned_name']], 'assigned_name':content['assigned_name'], \n",
    "#                                             'cmd':key, 'keywords':extract_key, 'global_index': line['global_index'], 'value':r.named[extract_key],\n",
    "#                                             'cmd_batch': cmd_batch, 'timestamp': timestamp, 'x': random.randint(0, 100), 'y':random.randint(0, 100)\n",
    "#                                             }\n",
    "#                                     tmp[extract_key].append(item)\n",
    "\n",
    "#                     for keyword in tmp.keys():\n",
    "#                         max_len = max([len(v) for v in tmp.values()])\n",
    "#                         for k, v in tmp.items():\n",
    "#                             if len(v) < max_len:\n",
    "#                                 v.extend([None] * (max_len - len(v)))\n",
    "\n",
    "#                         an = keyword+'_abnormal'\n",
    "#                         ptmp = pd.DataFrame(tmp)\n",
    "#                         if len(ptmp) == 0:\n",
    "#                             break\n",
    "#                         ptmp = ptmp.reset_index().rename(columns={'index':'occur_batch'})\n",
    "#                         ptmp = ptmp.apply(lambda x: abnormal_condition(x, exps[key]['extract_exps'][keyword]['cond']), axis=1)\n",
    "#                         abnormal = []\n",
    "#                         for item,occur_batch  in ptmp.loc[(ptmp[an] == True), [keyword, 'occur_batch']].values:\n",
    "#                             item['occur_batch'] = occur_batch\n",
    "#                             abnormal.append(item)\n",
    "#                         res.append({'file_name': file_name, 'product_name': table[content['assigned_name']],'assigned_name': content['assigned_name'], 'cmd': key, 'keywords': keyword, 'abnormal':abnormal})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson_toolsets_env",
   "language": "python",
   "name": "ericsson_toolsets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
