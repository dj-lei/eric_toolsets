{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a543a9b8-78fc-4d29-aa0d-d2c60de6bb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp', '', 'txAtt:d', '', 'torTemperature:d', '', 'avgIMpa0:d', '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "str1 = '[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}'\n",
    "re.findall('\\{(.*?)\\}', str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-activity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "branch = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "for index in range(12):\n",
    "    item = {}\n",
    "    item['role_path'] = 'root.' + 'branch' + str(branch[index]) + '.search_branch' + str(branch[index])\n",
    "    item['identifier'] = 'search_branch' + str(branch[index])\n",
    "    item['desc'] = 'Branch ' + str(branch[index]) + ' common use KeyValue and Mark'\n",
    "    item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+').*(txAtt|Pma|linearization fault)'\n",
    "    item['exp_extract'] = [\n",
    "                        \"{}[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "                        # \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "                        \"{}[{timestamp}] {}\"\n",
    "                        ]\n",
    "    item['exp_mark'] = [{\"abbr\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}]\n",
    "    item['is_active'] = False\n",
    "    item['is_case_sensitive'] = True\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    if index == 0:\n",
    "        item['is_active'] = True\n",
    "    config['search'].append(item)\n",
    "\n",
    "keys = ['txAtt', 'torTemperature', 'avgIMpa0', 'LF']\n",
    "for search_config in config['search']:\n",
    "    item = {}\n",
    "    item['role_path'] = search_config['role_path'].replace('search', 'chart')\n",
    "    item['identifier'] = search_config['identifier'].replace('search', 'chart')\n",
    "    item['desc'] = item['identifier'] + ' all KeyValue and Mark'\n",
    "    item['check'] = False\n",
    "    item['key_value_tree'] = {'namespace': 'KeyValue', 'name':'Key Value', 'check':False, 'children':[]}\n",
    "    for search_config2 in config['search']:\n",
    "        search_atom = {}\n",
    "        search_atom['namespace'] = search_config2['identifier']\n",
    "        search_atom['name'] = search_config2['identifier']\n",
    "        search_atom['check'] = False\n",
    "        search_atom['children'] = []\n",
    "        for key in keys:\n",
    "            if search_config['identifier'] == search_config2['identifier']:\n",
    "                search_atom['children'].append({'name': key, 'check': True})\n",
    "            else:\n",
    "                search_atom['children'].append({'name': key, 'check': False})\n",
    "        item['key_value_tree']['children'].append(search_atom)\n",
    "    config['chart'].append(item)\n",
    "\n",
    "# for index in range(12):\n",
    "#     item = {}\n",
    "#     item['name'] = 'insight_branch' + str(branch[index])\n",
    "#     item['desc'] = 'Branch Insight' + str(branch[index])\n",
    "#     item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+')'\n",
    "#     item['exp_extract'] = \"{}[{timestamp}]{}, msg = {msg}\"\n",
    "#     item['exp_mark'] = {\"name\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}\n",
    "#     item['is_case_sensitive'] = True\n",
    "#     item['forward_rows'] = 0\n",
    "#     item['backward_rows'] = 0\n",
    "#     config['insight'].append(item)\n",
    "\n",
    "# for index in range(12):\n",
    "#     item = {}\n",
    "#     item['name'] = 'statistic_branch' + str(branch[index])\n",
    "#     item['desc'] = 'Branch ' + str(branch[index]) + ' statistic txAtt'\n",
    "#     item['code'] = \"self.result = self.text_file_model.data['\" + 'search_branch' + str(branch[index]) + \"'].res_key_value['txAtt']['global_index']\"\n",
    "#     config['statistic'].append(item)\n",
    "    \n",
    "json_object = json.dumps(config)\n",
    "with open(\"E:\\\\projects\\\\ericsson_flow\\\\new_files\\\\config.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04930e7e-18d5-4970-a453-e0b638883997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "def add_search_config(parent, express, processes, keyword, mark):\n",
    "    config = []\n",
    "    \n",
    "    item = {}\n",
    "    item['identifier'] = f'{parent}_ErrorFaultABN'\n",
    "    identifier = item['identifier']\n",
    "    item['role_path'] = f'root.{parent}.EFA.{identifier}'\n",
    "\n",
    "    item['desc'] = parent + ' Error Fault ABN'\n",
    "    item['exp_search'] = parent + '.*(error| fault|ABN)'\n",
    "    item['exp_extract'] = [\n",
    "                            parent + express\n",
    "                        ]\n",
    "    item['exp_mark'] = [\n",
    "                            {\"abbr\":\"ER\",\"exp\":\"error\",\"color\":\"#f00000\"},\n",
    "                            {\"abbr\":\"FA\",\"exp\":\" fault\",\"color\":\"#f00000\"},\n",
    "                            {\"abbr\":\"ABN\",\"exp\":\"ABN\",\"color\":\"#ffff00\"}\n",
    "                        ]\n",
    "    item['is_active'] = True\n",
    "    item['is_case_sensitive'] = False\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    config.append(item)\n",
    "\n",
    "    for index, process in enumerate(processes):\n",
    "        item = {}\n",
    "        name = process.replace(',','_')\n",
    "        item['identifier'] = f'{parent}_{name}'\n",
    "        identifier = item['identifier']\n",
    "        item['role_path'] = f'root.{parent}.{identifier}' if (keyword not in process) else f'root.{parent}.{process}.{identifier}'\n",
    "        item['desc'] =  parent + ' ' + process + ' common use KeyValue and Mark'\n",
    "        item['exp_search'] = f'{parent}.*{process}'\n",
    "        item['exp_extract'] = [\n",
    "                                parent + express\n",
    "                            ]\n",
    "        item['exp_mark'] = mark if (keyword in process) else []\n",
    "        item['is_active'] = False\n",
    "        item['is_case_sensitive'] = True\n",
    "        item['forward_rows'] = 0\n",
    "        item['backward_rows'] = 0\n",
    "        config.append(item)\n",
    "    return config\n",
    "        \n",
    "def add_chart_config(tmp_search):\n",
    "    config = []\n",
    "    for search_config in tmp_search:\n",
    "\n",
    "        if len(search_config['exp_mark']) == 0:\n",
    "            continue\n",
    "\n",
    "        item = {}\n",
    "        item['role_path'] = search_config['role_path'] + '_Chart'\n",
    "        item['identifier'] = search_config['identifier'] + '_Chart'\n",
    "        item['desc'] = item['identifier'] + ' all KeyValue and Mark'\n",
    "        item['check'] = False\n",
    "        item['key_value_tree'] = {'namespace': 'KeyValue', 'name':'Key Value', 'check':False, 'children':[]}\n",
    "        for search_config2 in tmp_search:\n",
    "            search_atom = {}\n",
    "            search_atom['namespace'] = search_config2['identifier']\n",
    "            search_atom['name'] = search_config2['identifier']\n",
    "            search_atom['check'] = False\n",
    "            search_atom['children'] = []\n",
    "            if len(search_config2['exp_mark']) > 0:\n",
    "                keys = []\n",
    "                for mark in search_config2['exp_mark']:\n",
    "                    keys.append(mark['abbr'])\n",
    "                    \n",
    "                for key in keys:\n",
    "                    if search_config['identifier'] == search_config2['identifier']:\n",
    "                        search_atom['children'].append({'name': key, 'check': True})\n",
    "                    else:\n",
    "                        search_atom['children'].append({'name': key, 'check': False})\n",
    "                        \n",
    "            item['key_value_tree']['children'].append(search_atom)\n",
    "        config.append(item)\n",
    "    return config\n",
    "\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "\n",
    "processes = []\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\ErrorLog\\\\DOT TE LOG.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        res = re.findall(' \\((.*?)\\): ', line)\n",
    "        if len(res) > 0:\n",
    "            processes.append(res[0]) \n",
    "processes = list(set(processes))\n",
    "processes.sort()\n",
    "config['search'].extend(add_search_config('DOT_TE_LOG', \":{timestamp} ({}\", processes, 'kkkkkkkkkkkkk', []))\n",
    "\n",
    "processes = []\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\ErrorLog\\\\DU1 TE LOG.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        res = re.findall('procname = \\\"(.*?)\\\"', line)\n",
    "        if len(res) > 0:\n",
    "            processes.append(res[0])\n",
    "processes = list(set(processes))\n",
    "processes.sort()\n",
    "config['search'].extend(add_search_config('DU1_TE_LOG', \":[{timestamp}]{}\", processes, 'kkkkkkkkkkkkk', []))\n",
    "config['search'].extend(add_search_config('DU2_TE_LOG', \":[{timestamp}]{}\", processes, 'kkkkkkkkkkkkk', []))\n",
    "\n",
    "processes = []\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\ErrorLog\\\\RU1 TE LOG.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        res = re.findall(', { \\\"(.*?)\\\"', line)\n",
    "        if len(res) > 0:\n",
    "            processes.append(res[0])\n",
    "processes = list(set(processes))\n",
    "processes.sort()\n",
    "mark = [\n",
    "            {\"abbr\":\"ED\",\"exp\":\"EVENT_DEACTIVATE\",\"color\":\"#759aa0\"},\n",
    "            {\"abbr\":\"ER\",\"exp\":\"EVENT_RELEASE\",\"color\":\"#e69d87\"},\n",
    "            {\"abbr\":\"ES\",\"exp\":\"EVENT_SETUP\",\"color\":\"#8dc1a9\"},\n",
    "            {\"abbr\":\"EA\",\"exp\":\"EVENT_ACTIVATE\",\"color\":\"#ea7e53\"},\n",
    "            {\"abbr\":\"IND\",\"exp\":\"IND_ACTIVATE\",\"color\":\"#eedd78\"}\n",
    "        ]\n",
    "tmp_search = add_search_config('RU1_TE_LOG', '{}[{timestamp}]{}', processes, 'TxBranchCtrl', mark)\n",
    "config['search'].extend(tmp_search)\n",
    "config['chart'].extend(add_chart_config(tmp_search))\n",
    "\n",
    "tmp_search = add_search_config('RU2_TE_LOG', '{}[{timestamp}]{}', processes, 'TxBranchCtrl', mark)\n",
    "config['search'].extend(tmp_search)\n",
    "config['chart'].extend(add_chart_config(tmp_search))\n",
    "\n",
    "json_object = json.dumps(config)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\DotConfigFull.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c84793c-8d6e-4a8a-b079-5a1e3368c144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Result ('\\tfru_2051: ', '  144: ', ': DC_AISG_U:0 exceeds the limists. Value(mV): 587, limits[EXCEPTIONAL_HI,NORMAL_HI, NORMAL_LOW, EXCEPTIONAL_LOW](13125,13125,11875,11875)') {'timestamp': '230201 120650'}>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from parse import parse\n",
    "\n",
    "str1 = 'RU2_TE_LOG:BXP_2: [2023-02-23 10:31:25.766459124] com_ericsson_trithread:INFO: { 0 }, { \"TxBranchCtrlC\", \"logManager.cc:37\", \"Branch does not support different power level (txChangeCycleStatePrepare.cc:517)\" }'\n",
    "# str2 = 'BXP_3: [2022-12-10 15:55:26.739019220] (+0.000025340) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"TxBranchCtrlB\", fileAndLine = \"txChangeCycleHelper.cc:264\", msg = \"Txl branch J restart due to txL linearization fault!\" }'\n",
    "str1 = \"\tfru_2051: [230201 120650]  144: PSU enters: DC_AISG_U:0 exceeds the limists. Value(mV): 587, limits[EXCEPTIONAL_HI,NORMAL_HI, NORMAL_LOW, EXCEPTIONAL_LOW](13125,13125,11875,11875)\"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] \\(%{STRING:cost}\\) \"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}Pma:%{FLOAT:Pma0}\\[%{DROP:tmp1}DpdPma:%{FLOAT:DpdPma0}\\[%{DROP:tmp2}Pmb:%{FLOAT:Pmb}, TorPmb:%{FLOAT:TorPmb0}\\[%{FLOAT:TorPmb1} %{FLOAT:TorPmb2}\\] \"\n",
    "exp_extract = '{}[{timestamp}]{}PSU enters{}'\n",
    "r_extract = parse(exp_extract, str1)\n",
    "print(r_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b75e39c-8976-42e1-9b52-517eed5c85c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# processes = []\n",
    "# with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\4449\\\\faillog 4449 ULSA.txt\", \"r\") as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         res = re.findall(\"{ \\\"(.*?)\\\",\", line)\n",
    "#         if len(res) > 0:\n",
    "#             # if ('BranchCtrl' not in res[0]) & ('PhaseCtrl' not in res[0]):\n",
    "#             processes.append(res[0])\n",
    "            \n",
    "# with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\4449\\\\passlog 4449 ULSA.txt\", \"r\") as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         res = re.findall(\"{ \\\"(.*?)\\\",\", line)\n",
    "#         if len(res) > 0:\n",
    "#             # if ('BranchCtrl' not in res[0]) & ('PhaseCtrl' not in res[0]):\n",
    "#             processes.append(res[0])\n",
    "            \n",
    "# processes = list(set(processes))\n",
    "# processes.sort()\n",
    "# processes\n",
    "processes = [\n",
    " 'AntennaModule',\n",
    " 'EquipCtrl',\n",
    " 'PaSrvDC',\n",
    " 'PimcTdiHandler',\n",
    " 'RICRAI_SERVER',\n",
    " 'RxBranchCtrlA',\n",
    " 'RxBranchCtrlB',\n",
    " 'RxBranchCtrlC',\n",
    " 'RxBranchCtrlD',\n",
    " 'RxRmcService',\n",
    " 'TorLoSrvCD',\n",
    " 'TxBranchCtrlC',\n",
    " 'TxBranchCtrlD',\n",
    " 'TxCoordinationSrvCD',\n",
    " 'TxLoSrvC',\n",
    " 'TxLoSrvD',\n",
    " 'TxTimingPhaseCtrlC',\n",
    " 'antpServerProc_',\n",
    " 'bcProc',\n",
    " 'brhProc',\n",
    " 'carrierListElogScheduler.cc',\n",
    " 'carrierResourceHandlerImpl.cc',\n",
    " 'child.c',\n",
    " 'cmd_proc',\n",
    " 'cmd_proc(COLI)',\n",
    " 'cpriCtrlProc',\n",
    " 'cprilhmd.c',\n",
    " 'crhCarrierCtrl.cc',\n",
    " 'crhCarrierListHandler.cc',\n",
    " 'crhProxyProc',\n",
    " 'ecp_x11.c',\n",
    " 'faultManagerProc',\n",
    " 'iqIqcSwitchingAlgorithmCpri.cc',\n",
    " 'iqIqcSwitchingResourceHandlerIf.cc',\n",
    " 'iqIqcSwitchingResourceHandlerMs.cc',\n",
    " 'ledProc',\n",
    " 'libecp_x11.c',\n",
    " 'lrciRasCapDbFacadeAbfaas.cc',\n",
    " 'lrciRasCapDbFacadeBase.cc',\n",
    " 'lrciRasCapabilities.cc',\n",
    " 'radioTrDcServer',\n",
    " 'rfPort.cc',\n",
    " 'rftProc',\n",
    " 'rhd-lh.c',\n",
    " 'rmcProc',\n",
    " 'rtsCtrl',\n",
    " 'rtsCtrl_requestProcessor',\n",
    " 'rxBranchTimingInfoReporter.cc',\n",
    " 'stimenotifyd.c',\n",
    " 'tmoSchedulerEqp',\n",
    " 'tmoSchedulerTx',\n",
    " 'trDcProc',\n",
    " 'txBranchReporterCrh.cc',\n",
    " 'txlProcBranchC',\n",
    " 'txlProcBranchD',\n",
    " 'ulh_hdlc.c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61df44f1-6796-4d8c-bd7d-4e72bab7f918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "product_name = 'Radio4449'\n",
    "processes = processes\n",
    "config = {'search':[], 'insight':[], 'chart':[], 'statistic':[]}\n",
    "\n",
    "item = {}\n",
    "item['role_path'] = f'{product_name}.TimedoutErrorFaultABN'\n",
    "item['identifier'] = 'TimedoutErrorFaultABN'\n",
    "item['desc'] = 'Error Fault ABN Timedout'\n",
    "item['exp_search'] = 'error| fault|ABN|Timed out'\n",
    "item['exp_extract'] = [\n",
    "                    \"[{timestamp}] {}\" \n",
    "                    ]\n",
    "item['exp_mark'] = [\n",
    "                        {\"abbr\":\"TO\",\"exp\":\"Timed out\",\"color\":\"#FFB6C1\"},\n",
    "                        {\"abbr\":\"ER\",\"exp\":\"error\",\"color\":\"#f00000\"},\n",
    "                        {\"abbr\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"},\n",
    "                        {\"abbr\":\"ABN\",\"exp\":\"ABN:\",\"color\":\"#ffff00\"}\n",
    "                    ]\n",
    "item['is_active'] = True\n",
    "item['is_case_sensitive'] = True\n",
    "item['forward_rows'] = 0\n",
    "item['backward_rows'] = 0\n",
    "config['search'].append(item)\n",
    "\n",
    "for index, process in enumerate(processes):\n",
    "    item = {}\n",
    "    item['role_path'] = f'{product_name}.' + process.replace('.','_').replace('(','_').replace(')','_')\n",
    "    item['identifier'] = process\n",
    "    item['desc'] =  process + ' common use KeyValue and Mark'\n",
    "    item['exp_search'] = '\"'+process.replace('(','\\\\(').replace(')','\\\\)')+'\", '\n",
    "    item['exp_extract'] = [\n",
    "                        # \"[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "                        # \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "                        \"[{timestamp}] {}\" \n",
    "                        ]\n",
    "    # item['exp_mark'] = [\n",
    "    #                         {\"abbr\":\"ED\",\"exp\":\"EVENT_DEACTIVATE\",\"color\":\"#e00000\"},\n",
    "    #                         {\"abbr\":\"ER\",\"exp\":\"EVENT_RELEASE\",\"color\":\"#d00000\"},\n",
    "    #                         {\"abbr\":\"ES\",\"exp\":\"EVENT_SETUP\",\"color\":\"#c00000\"},\n",
    "    #                         {\"abbr\":\"EA\",\"exp\":\"EVENT_ACTIVATE\",\"color\":\"#b00000\"},\n",
    "    #                         {\"abbr\":\"IND\",\"exp\":\"IND_ACTIVATE\",\"color\":\"#a00000\"}\n",
    "    #                     ]\n",
    "    item['is_active'] = False\n",
    "    item['is_case_sensitive'] = True\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    config['search'].append(item)\n",
    "\n",
    "# tmp_search = []\n",
    "# processes = range(2)\n",
    "# for index in processes:\n",
    "#     item = {}\n",
    "#     branch_num = str(index)\n",
    "#     item['role_path'] = f'{product_name}.' + 'branch' + branch_num + '.search_branch' + branch_num\n",
    "#     item['identifier'] = 'search_branch' + branch_num\n",
    "#     item['desc'] = 'Branch ' + branch_num + ' common use KeyValue and Mark'\n",
    "#     item['exp_search'] = f'(process = \"txlProcBranch'+branch_num+'\"|process = \"TxBranchCtrl'+branch_num+'\")'\n",
    "#     item['exp_extract'] = [\n",
    "#                         \"[{timestamp}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "#                         # \"{}[{timestamp}] {}Pma:{Pma:f}[{}DpdPma:{DpdPma:f}[{}Pmb:{Pmb:f}[{}TorPmb:{TorPmb:f}{}avgTxPma:{avgTxPma:f} {}\",\n",
    "#                         \"[{timestamp}] {}\" \n",
    "#                         ]\n",
    "#     item['exp_mark'] = [\n",
    "#                             {\"abbr\":\"ED\",\"exp\":\"EVENT_DEACTIVATE\",\"color\":\"#759aa0\"},\n",
    "#                             {\"abbr\":\"ER\",\"exp\":\"EVENT_RELEASE\",\"color\":\"#e69d87\"},\n",
    "#                             {\"abbr\":\"ES\",\"exp\":\"EVENT_SETUP\",\"color\":\"#8dc1a9\"},\n",
    "#                             {\"abbr\":\"EA\",\"exp\":\"EVENT_ACTIVATE\",\"color\":\"#ea7e53\"},\n",
    "#                             {\"abbr\":\"IND\",\"exp\":\"IND_ACTIVATE\",\"color\":\"#eedd78\"}\n",
    "#                         ]\n",
    "#     item['is_active'] = False\n",
    "#     item['is_case_sensitive'] = True\n",
    "#     item['forward_rows'] = 0\n",
    "#     item['backward_rows'] = 0\n",
    "#     config['search'].append(item)\n",
    "#     tmp_search.append(item)\n",
    "        \n",
    "# keys = ['txAtt', 'avgIMpa0', 'ED', 'ER', 'ES', 'EA', 'IND']\n",
    "# for search_config in tmp_search:\n",
    "#     item = {}\n",
    "#     item['role_path'] = search_config['role_path'].replace('search', 'chart')\n",
    "#     item['identifier'] = search_config['identifier'].replace('search', 'chart')\n",
    "#     item['desc'] = item['identifier'] + ' all KeyValue and Mark'\n",
    "#     tree = {'namespace': 'KeyValue', 'name':'Key Value', 'check':False, 'children':[]}\n",
    "#     for search_config2 in tmp_search:\n",
    "#         search_atom = {}\n",
    "#         search_atom['namespace'] = search_config2['identifier']\n",
    "#         search_atom['name'] = search_config2['identifier']\n",
    "#         search_atom['check'] = False\n",
    "#         search_atom['children'] = []\n",
    "#         for key in keys:\n",
    "#             if search_config['identifier'] == search_config2['identifier']:\n",
    "#                 search_atom['children'].append({'name': key, 'check': True})\n",
    "#             else:\n",
    "#                 search_atom['children'].append({'name': key, 'check': False})\n",
    "#         tree['children'].append(search_atom)\n",
    "#     item['key_value_tree'] = [{'id': '', 'type': 'TidyTree', 'elements':tree}]\n",
    "#     config['chart'].append(item)\n",
    "    \n",
    "json_object = json.dumps(config)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\4449Config.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697de069-294c-45fc-b3fe-cd1cafe52cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import gzip\n",
    "import io\n",
    "from utils import *\n",
    "\n",
    "class ZipDecompress(object):\n",
    "    def __init__(self):\n",
    "        self.path = path\n",
    "        self.files = {}\n",
    "        \n",
    "    def decompress(self, extract_paths):\n",
    "        with zipfile.ZipFile(self.path, 'r') as file:\n",
    "            for extract_path in extract_paths:\n",
    "                file_name, lines = self.decompress_file(file, extract_path)\n",
    "                self.files[file_name] = lines\n",
    "        \n",
    "    def decompress_file(self, f_refer, extract_path):\n",
    "        path_node = extract_path.split('/')[0].replace('*', '')\n",
    "        tg = ''\n",
    "        for file in f_refer.filelist:\n",
    "            if path_node in file.filename:\n",
    "                tg = file.filename\n",
    "\n",
    "        if '.zip' in tg:\n",
    "            with f_refer.open(tg, 'r') as nest:\n",
    "                zfile = io.BytesIO(nest.read())\n",
    "                with zipfile.ZipFile(zfile) as nested_zip:\n",
    "                    return extract_file(nested_zip, '/'.join(extract_path.split('/')[1:]))\n",
    "        elif '.gz' in tg:\n",
    "            with f_refer.open(tg, 'r') as nest:\n",
    "                zfile = io.BytesIO(nest.read())\n",
    "                lines = gzip.open(zfile, 'r')\n",
    "                return nest.name, [line.decode(\"utf-8\") for line in lines]\n",
    "        else:\n",
    "            with f_refer.open(tg, 'r') as nest:\n",
    "                lines = nest.readlines()\n",
    "                return tg, [line.decode(\"utf-8\") for line in lines]\n",
    "            \n",
    "class FileSearch(object):\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        \n",
    "        \n",
    "    def search_by_range(self, start_exp, end_exp):\n",
    "        res = []\n",
    "        \n",
    "        flag = False\n",
    "        lines = []\n",
    "        assigned_name = ''\n",
    "        for index, line in enumerate(self.lines):\n",
    "            if flag:\n",
    "                r = parse(end_exp, line)\n",
    "                if r is not None:\n",
    "                    flag = False\n",
    "                    res.append(lines)\n",
    "                    lines = []\n",
    "                else:\n",
    "                    lines.append({'global_index':index, 'text':line})\n",
    "                    continue\n",
    "            r = parse(start_exp, line)\n",
    "            if r is not None:\n",
    "                for key in r.named.keys():\n",
    "                    \n",
    "                if r['assigned_name'] not in files_cmds_content[file_name][cmd]:\n",
    "                    files_cmds_content[file_name][cmd][r['assigned_name']] = []\n",
    "                flag = True\n",
    "                assigned_name = r['assigned_name']\n",
    "                lines.append({'global_index':index, 'text':line})\n",
    "                    \n",
    "    def search_by_regular(self):\n",
    "        pass\n",
    "            \n",
    "class TextExtract(object):\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "\n",
    "    # init \n",
    "    files_cmds_content = {}\n",
    "    for file_name in configs.keys():\n",
    "        files_cmds_content[file_name] = {}\n",
    "        for cmd in configs[file_name]['cmds'].keys():\n",
    "            files_cmds_content[file_name][cmd] = {}\n",
    "\n",
    "    # find cmd content\n",
    "    for file_name in files_origin_lines.keys():\n",
    "        for cmd in configs[file_name]['cmds'].keys():\n",
    "            flag = False\n",
    "            lines = []\n",
    "            assigned_name = ''\n",
    "            for index, line in enumerate(files_origin_lines[file_name]):\n",
    "                if flag:\n",
    "                    r = parse(cmd['end_exp'], line)\n",
    "                    if r is not None:\n",
    "                        flag = False\n",
    "                        files_cmds_content[file_name][cmd][assigned_name].append(lines)\n",
    "                        lines = []\n",
    "                    else:\n",
    "                        lines.append({'global_index':index, 'text':line})\n",
    "                        continue\n",
    "                r = parse(cmd['start_exp'], line)\n",
    "                if r is not None:\n",
    "                    if r['assigned_name'] not in files_cmds_content[file_name][cmd]:\n",
    "                        files_cmds_content[file_name][cmd][r['assigned_name']] = []\n",
    "                    flag = True\n",
    "                    assigned_name = r['assigned_name']\n",
    "                    lines.append({'global_index':index, 'text':line})\n",
    "\n",
    "    # extract key value\n",
    "    for file_name in files_origin_lines.keys():\n",
    "        for cmd in configs[file_name]['cmds'].keys():\n",
    "            for assigned in files_cmds_content[file_name][cmd].keys():\n",
    "                cmd_batch = files_cmds_content[file_name][cmd][assigned]\n",
    "                for batch_index, lines in enumerate(cmd_batch):\n",
    "                    tmp = {}\n",
    "                    cmd_config = configs[file_name]['cmds'][cmd]\n",
    "                    for extract_key in cmd_config['extract_exps'].keys():\n",
    "                        if extract_key != 'timestamp':\n",
    "                            tmp[extract_key] = []\n",
    "\n",
    "                    if cmd_config['time_type'] == 'embedded':\n",
    "                        for line in lines:\n",
    "                            for extract_key in cmd_config['extract_exps'].keys():\n",
    "                                r = parse(cmd_config['extract_exps'][extract_key]['exp'], line['text'])\n",
    "                                if r is not None:\n",
    "                                    item = {\n",
    "                                            'file_name':file_name, 'assigned_name':content['assigned_name'], \n",
    "                                            'cmd':cmd, 'keywords':extract_key, 'global_index': line['global_index'], 'value':'',\n",
    "                                            'cmd_batch_index': batch_index, 'timestamp': convert_datetime_timestamp(r.named['timestamp']), 'x': random.randint(0, 100), 'y':random.randint(0, 100)\n",
    "                                            }\n",
    "                                    tmp[extract_key].append(item)\n",
    "                    elif exps[key]['time_type'] == 'batch':\n",
    "                        timestamp = ''\n",
    "                        for line in lines:\n",
    "                            for extract_key in cmd_config['extract_exps'].keys():\n",
    "                                r = parse(cmd_config['extract_exps'][extract_key]['exp'], line['text'])\n",
    "                                if r is not None:\n",
    "                                    if 'timestamp' in r.named:\n",
    "                                        timestamp = convert_datetime_timestamp(r.named['timestamp'])\n",
    "                                        break\n",
    "                                    item = {\n",
    "                                            'file_name':file_name, 'product_name':table[content['assigned_name']], 'assigned_name':content['assigned_name'], \n",
    "                                            'cmd':key, 'keywords':extract_key, 'global_index': line['global_index'], 'value':r.named[extract_key],\n",
    "                                            'cmd_batch': cmd_batch, 'timestamp': timestamp, 'x': random.randint(0, 100), 'y':random.randint(0, 100)\n",
    "                                            }\n",
    "                                    tmp[extract_key].append(item)\n",
    "\n",
    "                    for keyword in tmp.keys():\n",
    "                        max_len = max([len(v) for v in tmp.values()])\n",
    "                        for k, v in tmp.items():\n",
    "                            if len(v) < max_len:\n",
    "                                v.extend([None] * (max_len - len(v)))\n",
    "\n",
    "                        an = keyword+'_abnormal'\n",
    "                        ptmp = pd.DataFrame(tmp)\n",
    "                        if len(ptmp) == 0:\n",
    "                            break\n",
    "                        ptmp = ptmp.reset_index().rename(columns={'index':'occur_batch'})\n",
    "                        ptmp = ptmp.apply(lambda x: abnormal_condition(x, exps[key]['extract_exps'][keyword]['cond']), axis=1)\n",
    "                        abnormal = []\n",
    "                        for item,occur_batch  in ptmp.loc[(ptmp[an] == True), [keyword, 'occur_batch']].values:\n",
    "                            item['occur_batch'] = occur_batch\n",
    "                            abnormal.append(item)\n",
    "                        res.append({'file_name': file_name, 'product_name': table[content['assigned_name']],'assigned_name': content['assigned_name'], 'cmd': key, 'keywords': keyword, 'abnormal':abnormal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b968c-2ce8-4d43-b11f-6efba7208e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgm = 'D:/projects/ericsson_flow/new_files/Dot4455/AKH167_242367_230215_112831_CET_MSRBS-LN_CXP2010174-1_R56J19_dcgm.zip'\n",
    "configs = {\n",
    "    'telog':{'extract_path': '*_logfiles.zip/teread.log', 'cmds':{\n",
    "                'telog read':{'extract_exps': [], \n",
    "                             'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "                            }},\n",
    "    # 'elog':{'extract_path': '*_e2.log.gz/*_dcg_e2.log', 'cmds':[\n",
    "    #             {'extract_exps': [], \n",
    "    #              'cmd':'', 'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "    #             ]},\n",
    "    # 'modump':{'extract_path': '*_modump.zip/*_dcg_k.log.gz/*_dcg_k.log', 'cmds':[\n",
    "    #             {'extract_exps': [], \n",
    "    #              'cmd':'', 'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "    #             ]},\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson_toolsets_env",
   "language": "python",
   "name": "ericsson_toolsets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
