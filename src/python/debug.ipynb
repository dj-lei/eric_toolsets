{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc2e3a-893f-4652-b085-d5bb4c10dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zlib\n",
    "import base64\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import configparser\n",
    "from utils import *\n",
    "from sys import platform\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# import torch\n",
    "# from tslearn.metrics import dtw, dtw_path\n",
    "# from tslearn.metrics import lcss, lcss_path\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# tokenizer = BertTokenizer.from_pretrained('google/bert_uncased_L-2_H-128_A-2')\n",
    "# model = BertModel.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "# model = model.to(device)\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253b509-184b-441e-9a6c-08d7d625752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = configparser.ConfigParser()\n",
    "cf.read('config/config.cfg')\n",
    "\n",
    "env = 'DEVELOP'\n",
    "if 'win' in platform:\n",
    "    env = 'DEVELOP'\n",
    "elif 'linux' in platform:\n",
    "    env = 'PRODUCT'\n",
    "    \n",
    "class EsCtrl(object):\n",
    "    def __init__(self):\n",
    "        self.es_ctrl = Elasticsearch(cf['ENV_'+env]['ADDR'], ca_certs=cf['ELASTICSEARCH']['CA_CERTS'])\n",
    "\n",
    "    def query_index_logs(self, index):\n",
    "        # query = {\n",
    "        #     \"match\": {\n",
    "        #         \"trace\": \"com_ericsson_trithread:INFO\"\n",
    "        #     }\n",
    "        # }\n",
    "        #data = self.es_ctrl.search(index=index, query=query, scroll='1s', size=10000)\n",
    "        data = self.es_ctrl.search(index=index, scroll='1s', size=10000)\n",
    "        sid = data['_scroll_id']\n",
    "        scroll_size = len(data['hits']['hits'])\n",
    "        res = []\n",
    "        while scroll_size > 0:\n",
    "            # Before scroll, process current batch of hits\n",
    "            res.extend(data['hits']['hits'])\n",
    "            data = self.es_ctrl.scroll(scroll_id=sid, scroll='1s')\n",
    "            # Update the scroll ID\n",
    "            sid = data['_scroll_id']\n",
    "            # Get the number of results that returned in the last scroll\n",
    "            scroll_size = len(data['hits']['hits'])\n",
    "        return res\n",
    "\n",
    "    def query_indices(self):\n",
    "        res = []\n",
    "        for key in self.es_ctrl.indices.get_alias().keys():\n",
    "            if len(key) > 0:\n",
    "                if '.analyzed_' in key:\n",
    "                    res.append(key.replace('.analyzed_', ''))\n",
    "        return res\n",
    "\n",
    "    def is_exists(self, index):\n",
    "        return self.es_ctrl.indices.exists(index=index)\n",
    "\n",
    "    def count_index(self, index):\n",
    "        return self.es_ctrl.count(index=index)['count']\n",
    "\n",
    "    def store_index(self, index, data):\n",
    "        data = deflate_and_base64_encode(json.dumps(data).encode('utf-8'))\n",
    "        return self.es_ctrl.index(index=index, body={'content': data})\n",
    "\n",
    "    def query_index(self, index):\n",
    "        data = self.es_ctrl.search(index=index)\n",
    "        data = json.loads(decode_base64_and_inflate(data['hits']['hits'][0]['_source']['content']))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-construction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tslearn.generators import random_walks\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn import metrics\n",
    "\n",
    "\n",
    "# numpy.random.seed(0)\n",
    "# n_ts, sz, d = 2, 100, 1\n",
    "# dataset = random_walks(n_ts=n_ts, sz=sz, d=d, random_state=5)\n",
    "\n",
    "kv_a = [int(item) for item in story_a['kv']['txlProcBranchH']['txAtt(c)'][0]]\n",
    "kv_b = [int(item) for item in story_b['kv']['txlProcBranchH']['txAtt(c)'][0]]\n",
    "[kv_b.insert(0,0) for _ in range(0, len(kv_a) - len(kv_b))]\n",
    "\n",
    "dataset = [kv_a, kv_b]\n",
    "scaler = TimeSeriesScalerMeanVariance(mu=0., std=1.)  # Rescale time series\n",
    "dataset_scaled = scaler.fit_transform(dataset)\n",
    "\n",
    "lcss_path, sim_lcss = metrics.lcss_path(dataset_scaled[0, :, 0], dataset_scaled[1, :, 0], eps=1.5)\n",
    "dtw_path, sim_dtw = metrics.dtw_path(dataset_scaled[0, :, 0], dataset_scaled[1, :, 0])\n",
    "\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "\n",
    "plt.plot(dataset_scaled[0, :, 0], \"b-\", label='First time series')\n",
    "plt.plot(dataset_scaled[1, :, 0], \"g-\", label='Second time series')\n",
    "\n",
    "for positions in lcss_path:\n",
    "    plt.plot([positions[0], positions[1]],\n",
    "             [dataset_scaled[0, positions[0], 0], dataset_scaled[1, positions[1], 0]], color='orange')\n",
    "plt.legend()\n",
    "plt.title(\"Time series matching with LCSS\")\n",
    "\n",
    "plt.figure(2, figsize=(8, 8))\n",
    "plt.plot(dataset_scaled[0, :, 0], \"b-\", label='First time series')\n",
    "plt.plot(dataset_scaled[1, :, 0], \"g-\", label='Second time series')\n",
    "\n",
    "for positions in dtw_path:\n",
    "    plt.plot([positions[0], positions[1]],\n",
    "             [dataset_scaled[0, positions[0], 0], dataset_scaled[1, positions[1], 0]], color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time series matching with DTW\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5301e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract import *\n",
    "\n",
    "path = 'exiosuu_LTE_TALAGAKOCAK_GH_BXP_2053_telog'\n",
    "fe = FileExtract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe7250-7976-4c1a-879b-bd4b83ad470d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw, dtw_path\n",
    "from tslearn.metrics import lcss, lcss_path\n",
    "import numpy\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from extract import *\n",
    "\n",
    "def cal_lcss_path_and_score(s_y1, s_y2):\n",
    "    path, score = lcss_path(s_y1, s_y2)\n",
    "    return path, score\n",
    "\n",
    "def cal_dtw_path_and_score(s_y1, s_y2):\n",
    "    path, score = dtw_path(s_y1, s_y2)\n",
    "    return path, score\n",
    "\n",
    "with open(cf['ENV_'+env]['LOG_STORE_PATH'] + 'GLT_SUKAMULYA_CBN_CM_BXP_2051_telog.log_BXP_2051_radio6626_2022_10_10', \"rb\") as myfile:\n",
    "    S = myfile.read()\n",
    "story_a = json.loads(gzip.decompress(S))\n",
    "\n",
    "with open(cf['ENV_'+env]['LOG_STORE_PATH'] + 'exiosuu_LTE_TALAGAKOCAK_GH_2052.log_BXP_2052_radio6626_2022_10_10', \"rb\") as myfile:\n",
    "    S = myfile.read()\n",
    "story_b = json.loads(gzip.decompress(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-richmond",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bisect import bisect\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def del_list_inplace(l, id_to_del):\n",
    "    for i in sorted(id_to_del, reverse=True):\n",
    "        del(l[i])\n",
    "\n",
    "keyword = 'Pma(c)'\n",
    "final = pd.DataFrame()\n",
    "kv_a_global_indices = [int(item) for item in story_a['kv']['txlProcBranchH'][keyword][-1]]\n",
    "kv_b_global_indices = [int(item) for item in story_b['kv']['txlProcBranchH'][keyword][-1]]\n",
    "\n",
    "kv_a = [[i, kv_a_global_indices[i], float(item)] for i, item in enumerate(story_a['kv']['txlProcBranchH'][keyword][0])]\n",
    "kv_b = [[i, kv_b_global_indices[i], float(item)] for i, item in enumerate(story_b['kv']['txlProcBranchH'][keyword][0])]\n",
    "\n",
    "kv_a = pd.DataFrame(kv_a, columns=['x', 'global_index','value'])\n",
    "kv_a['category'] = 'story_a'\n",
    "kv_a['loop'] = 'origin'\n",
    "\n",
    "kv_b = pd.DataFrame(kv_b, columns=['x', 'global_index','value'])\n",
    "kv_b['category'] = 'story_b'\n",
    "kv_b['loop'] = 'origin'\n",
    "\n",
    "final = final.append(kv_a).reset_index(drop=True)\n",
    "final = final.append(kv_b).reset_index(drop=True)\n",
    "\n",
    "for loop,_ in enumerate(range(0, 2)):\n",
    "    path, score = lcss_path(NormalizeData(list(kv_a.value.values)), NormalizeData(list(kv_b.value.values)), eps=0.1)\n",
    "    o_a = [[i, kv_a['global_index'][item[0]], kv_a['value'][item[0]]] for i, item in enumerate(path)]\n",
    "    o_b = [[i, kv_b['global_index'][item[1]], kv_b['value'][item[1]]] for i, item in enumerate(path)]\n",
    "    tmp_a = pd.DataFrame(o_a, columns=['x', 'global_index','value'])\n",
    "    tmp_a['category'] = 'story_a'\n",
    "    tmp_a['loop'] = 'loop'+str(loop)\n",
    "    tmp_b = pd.DataFrame(o_b, columns=['x', 'global_index','value'])\n",
    "    tmp_b['category'] = 'story_b'\n",
    "    tmp_b['loop'] = 'loop'+str(loop)\n",
    "    final = final.append(tmp_a).reset_index(drop=True)\n",
    "    final = final.append(tmp_b).reset_index(drop=True)\n",
    "\n",
    "    kv_a = kv_a.drop(kv_a.index[ [item[0] for item in path] ]).reset_index(drop=True)\n",
    "    kv_b = kv_b.drop(kv_b.index[ [item[1] for item in path] ]).reset_index(drop=True)\n",
    "    \n",
    "sns.relplot(\n",
    "    data=final, kind=\"line\",\n",
    "    x=\"x\", y=\"value\", col=\"category\", hue=\"loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = final.loc[(final['loop'] != 'origin'), :].reset_index(drop=True)\n",
    "sns.relplot(\n",
    "    data=tmp, kind=\"line\",\n",
    "    x=\"x\", y=\"value\", col=\"category\", hue=\"loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=final, kind=\"line\",\n",
    "    x=\"global_index\", y=\"value\", col=\"category\", hue=\"loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = 'txlProcBranchH'\n",
    "\n",
    "highlight_story = {}\n",
    "story_a_error_global_indices = []\n",
    "for i, p in enumerate(story_a['inverted_index_table']['error']['process']):\n",
    "    if p == process:\n",
    "        story_a_error_global_indices.append(int(story_a['inverted_index_table']['error']['x'][i]))\n",
    "        \n",
    "story_b_error_global_indices = []\n",
    "for i, p in enumerate(story_b['inverted_index_table']['error']['process']):\n",
    "    if p == process:\n",
    "        story_b_error_global_indices.append(int(story_b['inverted_index_table']['error']['x'][i]))\n",
    "\n",
    "highlight_story = {'story_a':story_a_error_global_indices, 'story_b':story_b_error_global_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-valve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for loop in set(final.loop.values):\n",
    "    for story in set(final.category.values):\n",
    "        gi = final.loc[(final['loop'] == loop)&(final['category'] == story), :].global_index.values\n",
    "        print(loop, story, len(gi))\n",
    "        tmp = []\n",
    "        for index in highlight_story[story]:\n",
    "            tmp.append(bisect(gi, index))\n",
    "        res.append({'loop':loop, 'category':story, 'position': sorted(set(tmp), key=tmp.index)})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(final.loc[(final['loop'] == 'loop1')&(final['category'] == 'story_a'), :].value.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(final.loc[(final['loop'] == 'loop0')&(final['category'] == 'story_a'), :].value.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-elite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = 132\n",
    "b = [0, 10, 30, 60, 100, 150, 210, 280, 340, 480, 530]\n",
    "print(bisect(b, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-staff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.值范围 2.相似线段形态 3.highlight落在区间内 4.方差大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "str1 = 'BXP_2: [2022-11-18 12:51:26.550407110] (+0.004950450) radio6626 com_ericsson_trithread:INFO: { cpu_id = 2 }, { process = \"txlProcBranchI\", fileAndLine = \"dpdController.cc:1886\", msg = \"Gain started. Pma:-21.79[-41.54 -9.50] dB, DpdPma:-25.83[-26.49 -25.09] dB, Pmb:-21.79, TorPmb:-21.92[-56.79 -9.50] dB, avgTxPma:-inf dB, pmDpdIrqStat:0x00000000, pmScaleFactor: 65K\" }\\n'\n",
    "regex = \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}txAtt:%{INT:txAtt}, %{DROP:tmp}avgIMpa0:%{INT:avgIMpa0} \"\n",
    "# regex = \"%{STRING:device}: \\[%{TIMESTAMP:time}\\] \"\n",
    "v_regex = regex\n",
    "for i, r in enumerate(re.findall('%\\{.*?\\}', regex)):\n",
    "    regex = regex.replace(r, '(.*?)')\n",
    "    v_regex = v_regex.replace(r, '<font color=\"color:#FFFFFF\">'+\"\\\\\"+str(i+1)+'</font>')\n",
    "\n",
    "re.findall(regex, str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json #mcbPwr trxTxPwr\n",
    "\n",
    "path = 'save_log/Visby_Telog_All_Branch_txAtt_torpmb_avgImpa.txt'\n",
    "with open(path, 'r') as f:\n",
    "    theme = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bearing-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "branch = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "config = {'search':[], 'chart':[], 'statistic':[]}\n",
    "for index in range(12):\n",
    "    item = {}\n",
    "    item['alias'] = 'Branch' + str(branch[index])\n",
    "    item['desc'] = 'Branch ' + str(branch[index]) + ' common use KeyValue and Mark'\n",
    "    item['exp_search'] = '(txlProcBranch'+str(branch[index])+'|TxBranchCtrl'+str(branch[index])+').*(txAtt|linearization fault|external fault)'\n",
    "    item['exp_extract'] = [\n",
    "                        \"{}[{timestamp:ti}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}\",\n",
    "                        \"{}[{timestamp:ti}] {}\"\n",
    "                        ]\n",
    "    item['exp_mark'] = [{\"alias\":\"LF\",\"exp\":\"linearization fault\",\"color\":\"#f00000\"}]\n",
    "    item['is_case_sensitive'] = True\n",
    "    item['forward_rows'] = 0\n",
    "    item['backward_rows'] = 0\n",
    "    config['search'].append(item)\n",
    "\n",
    "config['insight'] = []\n",
    "config['chart'] = []\n",
    "config['statistic'] = []\n",
    "    \n",
    "# Serializing json\n",
    "json_object = json.dumps(config)\n",
    "# Writing to sample.json\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\config.txt\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "branch = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "config = {'search':[], 'keyValueTree':[]}\n",
    "for index in range(12):\n",
    "    item = {}\n",
    "    item['uid'] = str(uuid.uuid4()).replace('-','')\n",
    "    item['desc'] = 'PA measured values for driver name ' + 'Branch' + str(branch[index])\n",
    "    item['search'] = 'PA & measured & driver'\n",
    "    item['regexs'] = [\n",
    "                        \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}PaVddSv:\"+str(index)+\"; value: %{INT:PaVddSv\"+str(index)+\"}; \",\n",
    "                        \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}DpaVddSv:\"+str(index)+\"; value: %{INT:DpaVddSv\"+str(index)+\"}; \",\n",
    "                        \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}IMpaSv:\"+str(index)+\"\\.0; value: %{INT:IMpaSv\"+str(index)+\"0}; \",\n",
    "                        \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}IMpaSv:\"+str(index)+\"\\.1; value: %{INT:IMpaSv\"+str(index)+\"1}; \",\n",
    "                        \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}IDpaSv:\"+str(index)+\"\\.0; value: %{INT:IDpaSv\"+str(index)+\"0}; \",\n",
    "                        \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}IDpaSv:\"+str(index)+\"\\.1; value: %{INT:IDpaSv\"+str(index)+\"1}; \",\n",
    "                        \"\\[%{TIMESTAMP:time}\\] \\(%{DROP:tmp}\\) \"\n",
    "                        ]\n",
    "    item['highlights'] = []\n",
    "    config['search'].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-crazy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.findall('txPma +: (.*?),(.*?)txDpdPma +: (.*?),(.*?)', str1, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from text_analysis import TextAnalysisModel\n",
    "\n",
    "search_model = {\n",
    "    \"namespace\": '',\n",
    "    'alias': 'test',\n",
    "    \"desc\": 'test search',\n",
    "    \"exp_search\": '(txlProcBranchJ|TxBranchCtrlJ).*(txAtt|linearization fault|external fault)',\n",
    "    \"exp_extract\": [\n",
    "                    '{}[{timestamp:ti}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}',\n",
    "                    '{}[{timestamp:ti}] {}'\n",
    "                    ],\n",
    "    \"exp_mark\": [{'exp':'linearization fault', 'alias':'LF'}, {'exp':'external fault', 'alias':'EF'}],\n",
    "}\n",
    "\n",
    "statistic_model = {\n",
    "    \"namespace\": '',\n",
    "    'alias': 'statistic',\n",
    "    \"desc\": 'test statistic',\n",
    "    \"exp\": 'str(BranchA.txAtt)',\n",
    "}\n",
    "\n",
    "insight_model = {\n",
    "    \"namespace\": '/test',\n",
    "    'alias': 'test',\n",
    "    \"exp_search\": '(txlProcBranchJ|TxBranchCtrlJ).*(txAtt|linearization fault)',\n",
    "    \"exp_extract\": '{}[{timestamp:ti}]{}, msg = {msg}',\n",
    "    \"exp_mark\": {'exp':'linearization fault', 'alias':'LF'},\n",
    "}\n",
    "\n",
    "path = 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\E55G948878_LE_SARONGGE_BXP_6_telog.log'\n",
    "test_text_analysis_model = TextAnalysisModel()\n",
    "\n",
    "text_file_model_namespace = test_text_analysis_model.file_container_model.namespace + '/'+ str(uuid.uuid4())\n",
    "tes_text_analysis_model.file_container_model.on_new_file('', text_file_model_namespace, path)\n",
    "\n",
    "text_file_model = tes_text_analysis_model.file_container_model.text_file_models[text_file_model_namespace]\n",
    "model['namespace'] = text_file_model.text_file_function_model.search_function_model.namespace + '/'+ str(uuid.uuid4())\n",
    "search_function_model = tes_text_analysis_model.file_container_model.text_file_models[text_file_model_namespace].text_file_function_model.search_function_model.unit_test(model)\n",
    "search_atom_model = search_function_model.search_atom_models[model['namespace']].unit_test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from text_analysis import InsightAtomModel\n",
    "\n",
    "insight_model = {\n",
    "    \"namespace\": '/test',\n",
    "    'alias': 'test',\n",
    "    \"exp_search\": '(txlProcBranchJ|TxBranchCtrlJ)',\n",
    "    \"exp_extract\": '{}[{timestamp:ti}]{}, msg = {msg}',\n",
    "    \"exp_mark\": {'exp':'linearization fault', 'alias':'LF', 'color': '#f00000'},\n",
    "}\n",
    "\n",
    "path = 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\E55G948878_LE_SARONGGE_BXP_6_telog.log'\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "text_file_model = json_to_object({'lines': lines})\n",
    "            \n",
    "insightAtomModel = InsightAtomModel('/test')\n",
    "insightAtomModel.__dict__.update(insight_model)\n",
    "insightAtomModel.text_file_model = text_file_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respective-orbit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insightAtomModel.insight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "insightAtomModel.res_key_value['avgTxPma_float']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handed-collector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 15:55:18.153628 mark  ENABLED filterBranch 54 carrierId 788 \n",
      "2022-12-10 15:55:18.153695 mark  New 1 \n",
      "2022-12-10 15:55:18.153695 str event:  EVENT_SETUP --> EVENT_ACTIVATE\n",
      "2022-12-10 15:55:18.153695 str fbsState:  SETUP --> ENABLED\n",
      "2022-12-10 15:55:18.153695 str cycleRequired:  NO --> YES\n",
      "2022-12-10 15:55:18.153720 mark  Start Power Measurement Supervision successfully on TX branch J \n",
      "2022-12-10 15:55:18.153734 mark  Start Input Power Measurement Supervision successfully on TX branch J \n",
      "2022-12-10 15:55:18.154913 mark  Cascaded status for cpriPortPair 0 1 is 0 \n",
      "2022-12-10 15:55:18.156583 mark  ConfigSetFreqRanges \n",
      "2022-12-10 15:55:18.156748 mark  SetFreqRanges SetFreqRanges LTE_FDD \n",
      "2022-12-10 15:55:18.156861 mark  665743682us \n",
      "2022-12-10 15:55:18.158559 mark  Sending TorGain 0 update to subscriber \n",
      "2022-12-10 15:55:18.159605 mark  ConfigSetTorGainRelative \n",
      "2022-12-10 15:55:18.163309 mark  ==== TxLO change start zero \n",
      "2022-12-10 15:55:18.163315 mark  Suppressing txChangeCycleStateTxLoChange messages to trace group 1 for 300 ms. \n",
      "2022-12-10 15:55:18.163762 str RUEV:  TXL_FREQ_RANGE --> NCO\n",
      "2022-12-10 15:55:18.163762 mark  665750565us \n",
      "2022-12-10 15:55:18.163796 mark  No need update CFR for first \n",
      "2022-12-10 15:55:18.163877 mark  SynthTxLoSetFreq 2140000 \n",
      "2022-12-10 15:55:18.165817 mark  Execute 5 txOnDefault 6 start \n",
      "2022-12-10 15:55:18.165849 mark  LuaEngine MutexTor m_lockTor m_torSupported \n",
      "2022-12-10 15:55:18.165885 mark  lockTorEntry area started for \n",
      "2022-12-10 15:55:18.165947 mark  lockTorEntry area current run \n",
      "2022-12-10 15:55:18.175267 mark  Acquire DPL TOR lock completed for \n",
      "2022-12-10 15:55:18.175271 mark  TOR lock acquired. \n",
      "2022-12-10 15:55:18.177577 mark  PREDISTORTION_DB IQ configured \n",
      "2022-12-10 15:55:18.179373 mark  PREDISTORTION_DB init_lut_setup configured \n",
      "2022-12-10 15:55:18.186794 mark  PREDISTORTION_DB init_lut_execution configured \n",
      "2022-12-10 15:55:18.188428 mark  unlockTorEntry area started for \n",
      "2022-12-10 15:55:18.188453 mark  unlockTorEntry area completed for \n",
      "2022-12-10 15:55:18.188458 mark  Release DPL TOR lock completed for \n",
      "2022-12-10 15:55:18.188463 mark  Execute 5 txOnDefault 6 done \n",
      "2022-12-10 15:55:18.188535 mark  SynthTorLoSetFreq 2140000 \n",
      "2022-12-10 15:55:18.192659 mark  ==== TxLO change remove zero \n",
      "2022-12-10 15:55:18.252678 str RUEV:  NCO --> PF5X_STEPATT\n",
      "2022-12-10 15:55:18.252678 mark  665839496us \n",
      "2022-12-10 15:55:18.263525 mark  665850340us \n",
      "2022-12-10 15:55:18.263525 str RUEV:  PF5X_STEPATT --> S0_SET\n",
      "2022-12-10 15:55:18.275315 str RUEV:  S0_SET --> CHFIL\n",
      "2022-12-10 15:55:18.275315 mark  665862124us \n",
      "2022-12-10 15:55:18.308548 mark  Set \n",
      "2022-12-10 15:55:18.308606 mark  665895421us \n",
      "2022-12-10 15:55:18.308606 str RUEV:  CHFIL --> PA0\n",
      "2022-12-10 15:55:18.308636 mark  0.1 dB for \n",
      "2022-12-10 15:55:18.308647 mark  MPL set individual \n",
      "2022-12-10 15:55:18.328764 str RUEV:  PA0 --> ZI_OFF\n",
      "2022-12-10 15:55:18.328764 mark  665915577us \n",
      "2022-12-10 15:55:18.329195 mark  ConfigSetPowerLevel 4600 \n",
      "2022-12-10 15:55:18.330794 mark  power 4600 channelPower 4600 \n",
      "2022-12-10 15:55:18.330954 mark  TOR temperature 1050 0.1C \n",
      "2022-12-10 15:55:18.331062 str TOR:  PowerLevel:INIT --> PowerLevel:STEP:\n",
      "2022-12-10 15:55:18.331070 mark  DBG \n",
      "2022-12-10 15:55:18.335168 mark  0.01dBm 39 W 0.01dBm 39 W \n",
      "2022-12-10 15:55:18.335401 mark  Use Doherty table I Q default values \n",
      "2022-12-10 15:55:18.335446 mark  Configuration initialization completed. \n",
      "2022-12-10 15:55:18.347952 float 10:  7.0 --> 1.0 --> 7.0\n",
      "2022-12-10 15:55:18.347952 mark  INIT_DP_HW GAIN SW dpdGainCoarseHyst dpdGainFineHyst \n",
      "2022-12-10 15:55:18.348513 mark  Spi device channel configuration from legacy \n",
      "2022-12-10 15:55:18.348531 mark  INIT_DP_HW SPI \n",
      "2022-12-10 15:55:18.362593 str sections:  initIqParams --> txOnDefault\n",
      "2022-12-10 15:55:18.362593 mark  Execute 6 activateCarrier 19 start \n",
      "2022-12-10 15:55:18.362637 mark  lockTorEntry area queue 0 7 \n",
      "2022-12-10 15:55:18.466587 mark  lockTorEntry area queue 2 \n",
      "2022-12-10 15:55:18.475914 mark  activateCarrier is running \n",
      "2022-12-10 15:55:18.487905 mark  PREDISTORTION_DB Method for setting TOR ALG filter \n",
      "2022-12-10 15:55:18.488201 mark  PREDISTORTION_DB No Tor Alg filter set in parameter torAlgLpFilter default filter 1000 will be used \n",
      "2022-12-10 15:55:18.488225 mark  PREDISTORTION_DB Setting Lowpass Filter 1000 in Tor Alg \n",
      "2022-12-10 15:55:18.489827 mark  PREDISTORTION_DB Writing Lowpass Filter to TOR ALG \n",
      "2022-12-10 15:55:18.504082 mark  unlockTorEntry area queue 2 7 0 \n",
      "2022-12-10 15:55:18.504113 mark  Execute 6 activateCarrier 19 done \n",
      "2022-12-10 15:55:18.504200 str RUEV:  ZI_OFF --> TXL_START\n",
      "2022-12-10 15:55:18.504200 mark  666091017us \n",
      "2022-12-10 15:55:18.504242 mark  CtrlLinStart \n",
      "2022-12-10 15:55:18.504275 mark  lockTorEntry area queue 7 0 \n",
      "2022-12-10 15:55:18.549987 mark  lockTorEntry area queue 2 7 \n",
      "2022-12-10 15:55:18.559505 mark  doGainStart \n",
      "2022-12-10 15:55:18.559519 mark  gain 666146ms \n",
      "2022-12-10 15:55:18.614736 mark  EvcSwitch \n",
      "2022-12-10 15:55:18.618824 mark  startGainCalibration \n",
      "2022-12-10 15:55:18.626617 mark  Execute 5 dpdInit 2 txOnDefault 6 start \n",
      "2022-12-10 15:55:18.626617 str sections:  txOnDefault --> initIqParams\n",
      "2022-12-10 15:55:18.626656 float list:  9.0 --> 0.0 --> 9.0\n",
      "2022-12-10 15:55:18.626656 mark  lockTorEntry area queue 8 2 \n",
      "2022-12-10 15:55:18.626656 float list:  9.0 --> 0.0\n",
      "2022-12-10 15:55:18.752689 mark  lockTorEntry area queue \n",
      "2022-12-10 15:55:18.761938 mark  PREDISTORTION_DB accSchdInit configured \n",
      "2022-12-10 15:55:18.765183 mark  PREDISTORTION_DB algCtrlCompDelays configured \n",
      "2022-12-10 15:55:18.779106 mark  unlockTorEntry area queue \n",
      "2022-12-10 15:55:18.779169 mark  Execute 5 dpdInit 2 txOnDefault 6 done \n",
      "2022-12-10 15:55:18.784070 str sections:  initIqParams --> txOnDefault\n",
      "2022-12-10 15:55:18.854206 mark  Training \n",
      "2022-12-10 15:55:18.854260 str state:  on --> STATE_IDLE\n",
      "2022-12-10 15:55:18.854260 mark  TrainingSignal TS loading \n",
      "2022-12-10 15:55:18.854273 str type:  Change --> TX_ATT_TUN_TS\n",
      "2022-12-10 15:55:18.854273 mark  Found in cache \n",
      "2022-12-10 15:55:18.854287 mark  Activate TrainingSignal \n",
      "2022-12-10 15:55:18.854287 str state:  STATE_IDLE --> STATE_LOADED\n",
      "2022-12-10 15:55:18.854347 mark  TXL_CC 0 \n",
      "2022-12-10 15:55:18.854396 mark  TXL_CC 40 \n",
      "2022-12-10 15:55:18.854546 mark  TXL_CC BB disabled TS enabled \n",
      "2022-12-10 15:55:18.854568 mark  Training Signal sequence successfully done. Activated \n",
      "2022-12-10 15:55:18.854568 str state:  STATE_LOADED --> STATE_ACTIVATED\n",
      "2022-12-10 15:55:18.854579 mark  CtrlGainStateWait setUp takes 0 ms to activate training signal \n",
      "2022-12-10 15:55:18.856372 mark  Wait for data. -41.54 -9.50 dB -22.19 -20.79 dB -52.49 -9.50 dB dB \n",
      "2022-12-10 15:55:18.858041 mark  0.1C 0.01dB 0.01dB mAmp \n",
      "2022-12-10 15:55:18.864077 mark  Start ramping. -41.54 -9.50 dB -22.19 -20.79 dB -52.49 -9.50 dB dB \n",
      "2022-12-10 15:55:24.884128 mark  DP 3497819 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884145 str trace:  224: --> 225:\n",
      "2022-12-10 15:55:24.884145 mark  DP 3507781 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884154 mark  DP 3517726 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884154 str trace:  225: --> 226:\n",
      "2022-12-10 15:55:24.884163 mark  DP 3527346 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884163 str trace:  226: --> 227:\n",
      "2022-12-10 15:55:24.884249 str trace:  227: --> 228:\n",
      "2022-12-10 15:55:24.884249 mark  DP 3536726 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884259 mark  DP 3546461 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884259 str trace:  228: --> 229:\n",
      "2022-12-10 15:55:24.884268 mark  DP 3556568 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884268 str trace:  229: --> 230:\n",
      "2022-12-10 15:55:24.884277 mark  DP 3565920 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884277 str trace:  230: --> 231:\n",
      "2022-12-10 15:55:24.884285 mark  DP 3575486 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884285 str trace:  231: --> 232:\n",
      "2022-12-10 15:55:24.884294 str trace:  232: --> 233:\n",
      "2022-12-10 15:55:24.884294 mark  DP 3585741 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884303 str trace:  233: --> 234:\n",
      "2022-12-10 15:55:24.884303 mark  DP 3595148 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884311 str trace:  234: --> 235:\n",
      "2022-12-10 15:55:24.884311 mark  DP 3604961 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.884320 str trace:  235: --> 236:\n",
      "2022-12-10 15:55:24.884320 mark  DP 3614965 gain.c 1488 gain total step is above limit - use 2500 \n",
      "2022-12-10 15:55:24.887632 mark  timeout \n",
      "2022-12-10 15:55:24.887706 mark  -41.54 -9.50 dB -22.19 -20.79 dB -52.49 -9.50 dB dB \n",
      "2022-12-10 15:55:24.889339 float avgIMpa0:  0.0 --> 490.0\n",
      "2022-12-10 15:55:24.889339 float txAtt:  278.0 --> 2500.0\n",
      "2022-12-10 15:55:24.891212 mark  dBm 39W \n",
      "2022-12-10 15:55:24.891212 float txAtt:  278.0 --> 2500.0 --> 278.0\n",
      "2022-12-10 15:55:24.891222 mark  mAmp 0.1C BoardFreq :preInit init initIqParams dpdInit txOnDefault initIqParams txOnDefault section1 txOnDefault \n",
      "2022-12-10 15:55:24.891222 str state:  STATE_ACTIVATED --> on\n",
      "2022-12-10 15:55:24.891222 float avgIMpa0:  0.0 --> 490.0 --> 0.0\n",
      "2022-12-10 15:55:24.891230 mark  initIqParams dpdInit txOnDefault section1 txOnDefault \n",
      "2022-12-10 15:55:24.894534 mark  Find and erase by Type and Branch \n",
      "2022-12-10 15:55:24.894590 mark  Restore and tearDown \n",
      "2022-12-10 15:55:24.894692 mark  TrainingSignal stop playing \n",
      "2022-12-10 15:55:24.895854 str state:  on --> STATE_LOADED\n",
      "2022-12-10 15:55:24.895854 mark  TrainingSignal Deactivate \n",
      "2022-12-10 15:55:24.895868 mark  gain stopped \n",
      "2022-12-10 15:55:24.895881 mark  Fault \n",
      "2022-12-10 15:55:24.895896 mark  fault state TX_FAULT_RECEIVED \n",
      "2022-12-10 15:55:24.896056 mark  linFault action branchPaMeasurement powerDecrease branchRestart \n",
      "2022-12-10 15:55:24.896084 mark  dB \n",
      "2022-12-10 15:55:24.896159 mark  expected back off dB \n",
      "2022-12-10 15:55:24.896230 mark  branch shutdown - branchId 9 blockId 124 \n",
      "2022-12-10 15:55:24.896312 mark  672483125us \n",
      "2022-12-10 15:55:24.896312 str RUEV:  TXL_START --> ZI_ON\n",
      "2022-12-10 15:55:24.908722 float 10:  1.0 --> 7.0 --> 1.0\n",
      "2022-12-10 15:55:24.921824 mark  clearFault \n",
      "2022-12-10 15:55:24.921916 str RUEV:  ZI_ON --> TXL_STOP\n",
      "2022-12-10 15:55:24.921916 mark  672508730us \n",
      "2022-12-10 15:55:24.921983 mark  PA shutdown request for branchId 9 blockId 124 \n",
      "2022-12-10 15:55:24.922006 mark  paControl Off for PaSrvCHJK for branchId 9 blockId TxBranchCtrlJ \n",
      "2022-12-10 15:55:24.922060 str RUEV:  TXL_STOP --> MPA_OFF\n",
      "2022-12-10 15:55:24.922060 mark  672508883us \n",
      "2022-12-10 15:55:26.738993 mark  fault state TX_BRANCH_RESTART_PENDING \n",
      "2022-12-10 15:55:26.738993 str change:  TX_FAULT_PROCESS_DONE-- --> TX_FAULT_RECEIVED--\n",
      "2022-12-10 15:55:26.739019 mark  Txl branch J restart due to txL linearization fault \n",
      "2022-12-10 15:55:26.739441 mark  674326261us \n",
      "2022-12-10 15:55:26.739441 str RUEV:  MPA_OFF --> MPA_ON\n",
      "2022-12-10 15:55:26.739461 mark  9 SET TO STATUS ON \n",
      "2022-12-10 15:55:26.739589 str RUEV:  MPA_ON --> TXL_STOP\n",
      "2022-12-10 15:55:26.739589 mark  674326410us \n",
      "2022-12-10 15:55:26.759662 mark  674346476us \n",
      "2022-12-10 15:55:26.759662 str RUEV:  TXL_STOP --> ZI_OFF\n",
      "2022-12-10 15:55:26.760021 mark  Txl start request \n",
      "2022-12-10 15:55:26.760046 str RUEV:  ZI_OFF --> TXL_START\n",
      "2022-12-10 15:55:26.760046 mark  674346868us \n",
      "2022-12-10 15:55:26.765047 mark  gain 674351ms \n",
      "2022-12-10 15:55:26.765098 mark  fault state TX_FAULT_PROCESS_DONE \n",
      "2022-12-10 15:55:26.765098 str change:  TX_FAULT_RECEIVED-- --> TX_BRANCH_RESTART_PENDING--\n",
      "2022-12-10 15:55:26.782793 str sections:  txOnDefault --> initIqParams\n",
      "2022-12-10 15:55:26.808799 str sections:  initIqParams --> txOnDefault\n",
      "2022-12-10 15:55:26.808843 float list:  9.0 --> 9.0\n",
      "2022-12-10 15:55:26.851994 mark  TrainingSignal start playing \n",
      "2022-12-10 15:55:26.852164 str state:  STATE_LOADED --> STATE_ACTIVATED\n",
      "2022-12-10 15:55:26.852176 mark  CtrlGainStateWait setUp takes 3 ms to activate training signal \n",
      "2022-12-10 15:55:26.857147 float torGainBackoff:  0.0 --> -20.0\n",
      "2022-12-10 15:55:26.857147 float avgIMpa0:  490.0 --> 0.0\n",
      "2022-12-10 15:55:26.857147 float txAtt:  2500.0 --> 278.0\n",
      "2022-12-10 15:55:26.857147 float torGainLin:  3.56041 --> 3.64334\n",
      "2022-12-10 15:55:26.860563 float TorPmb:  -56.85 --> -56.97\n",
      "2022-12-10 15:55:26.739019 manual linearization fault\n"
     ]
    }
   ],
   "source": [
    "for o in insightAtomModel.outlier:\n",
    "    print(o['timestamp'], o['type'], o['desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(insightAtomModel.outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from parse import parse\n",
    "\n",
    "str1 = 'BXP_3: [2022-11-23 22:04:44.572174570] (+0.000333470) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"txlProcBranchB\", fileAndLine = \"dpdController.cc:1887\", msg = \"txAtt:289, txAttPeak:0, dpGainLoopEnable:true, dpGainCtrlType:DSA_AD_TXFE, torTemperature:495 (0.1C), torGainBackoff:0 (0.01dB), torGainLin:3.49543(0.01dB), torStepBit:6, cc0Ctrl1=0x00000118 , avgIMpa0:1980 [mAmp]\" }'\n",
    "str2 = 'BXP_3: [2022-12-10 15:55:26.739019220] (+0.000025340) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"TxBranchCtrlB\", fileAndLine = \"txChangeCycleHelper.cc:264\", msg = \"Txl branch J restart due to txL linearization fault!\" }'\n",
    "# str1 = \"BXP_2: [221120 164014] 27: PA measured values for driver name: DpaVddSv:7; value: 26992; branch Id: 7\"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] \\(%{STRING:cost}\\) \"\n",
    "# exp = \"\\[%{TIMESTAMP:time}\\] %{DROP:tmp}Pma:%{FLOAT:Pma0}\\[%{DROP:tmp1}DpdPma:%{FLOAT:DpdPma0}\\[%{DROP:tmp2}Pmb:%{FLOAT:Pmb}, TorPmb:%{FLOAT:TorPmb0}\\[%{FLOAT:TorPmb1} %{FLOAT:TorPmb2}\\] \"\n",
    "exp_search = '(txlProcBranchB|TxBranchCtrlB).*(txAtt|linearization fault)'\n",
    "exp_extract = '{}[{timestamp:ti}] {}txAtt:{txAtt:d}, {}torTemperature:{torTemperature:d} {}avgIMpa0:{avgIMpa0:d} {}'\n",
    "r_search = re.findall(exp_search, str1)\n",
    "r_extract = parse(exp_extract, str1)\n",
    "print(r_search)\n",
    "print(r_extract.named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import lcss_path\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2110743.0, 2110743.0, 22500000.0, 2117500.0]\n",
    "b = [0,100,0]\n",
    "# lcss_path(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scale(a, feature_range=(0, 100))[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [0,100,0,100,0,100]\n",
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amino-potato",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class A():\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "        self.b = 2\n",
    "        \n",
    "    def __dict__(self):\n",
    "        return \n",
    "        \n",
    "    def test(self, num):\n",
    "        print(num)\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c = 3\n",
    "        self.d = {'ins': ''}\n",
    "        \n",
    "class PubSub():\n",
    "    def __init__(self):\n",
    "        self.room = {}\n",
    "        self.wait = {}\n",
    "\n",
    "    def reference(self, namespace):\n",
    "        return self.room[namespace]['ins']\n",
    "\n",
    "    def book(self, namespace, ins, func):\n",
    "        self.room[namespace] = {'ins': ins, 'subscriber': [], 'action': func}\n",
    "        if namespace in self.wait:\n",
    "            for func in self.wait[namespace]:\n",
    "                self.room[namespace]['subscriber'].append(func)\n",
    "            del self.wait[namespace]\n",
    "        \n",
    "# a = A()\n",
    "b = B()\n",
    "c = B()\n",
    "d = PubSub()\n",
    "e = d.reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressed-distributor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from parse import parse\n",
    "\n",
    "def key_value_replace(word):\n",
    "    print(word.group(0), word.group(1), word.group(2))\n",
    "    return ''\n",
    "    \n",
    "def clean_special_symbols(text, symbol):\n",
    "    for ch in ['::', '/','*','{','}','[',']','(',')','#','+','!',';',',','\"','\\'','>','<','@','`','$','^','&','|','\\n']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch,symbol)\n",
    "    return re.sub(symbol+\"+\", symbol, text)\n",
    "\n",
    "# msg = 'BXP_3: [2022-11-23 22:04:44.572174570] (+0.000333470) radio6626 com_ericsson_trithread:INFO: { cpu_id = 1 }, { process = \"txlProcBranchB\", fileAndLine = \"dpdController.cc:1887\", msg = \"txAtt:289, txAttPeak:0, dpGainLoopEnable:true, dpGainCtrlType:DSA_AD_TXFE, torTemperature:495 (0.1C), torGainBackoff:0 (0.01dB), torGainLin:3.49543(0.01dB), torStepBit:6, cc0Ctrl1=0x00000118 , avgIMpa0:1980 [mAmp]\" }'\n",
    "msg = 'BXP_5: [2022-12-10 02:23:19.912787758] (+0.000603078) radio6626 com_ericsson_trithread:INFO: { cpu_id = 2 }, { process = \"txlProcBranchH\", fileAndLine = \"dpdController.cc:1886\", msg = \"Wait for data. Pma:-17.49[-41.54 -9.50] dB, DpdPma:-21.52[-22.19 -20.79] dB, Pmb:-17.49, TorPmb:-27.69[-52.49 -9.50] dB, avgTxPma:-inf dB, pmDpdIrqStat:0x00000000, pmScaleFactor: 4K\" }'\n",
    "msg = parse('{}[{timestamp:ti}]{}, msg = {msg}', msg)\n",
    "msg = clean_special_symbols(msg.named['msg'], ' ')\n",
    "\n",
    "# for k, v in re.findall('([A-Za-z0-9_.]+?)[ ]?[:=][ ]?(.*?) ', msg):\n",
    "#     print(k, v)\n",
    "\n",
    "re.sub('([A-Za-z0-9_.]+?)[ ]?[:=][ ]?(.*?) ', key_value_replace, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg.named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "r = 66\n",
    "x = np.array(list(data.x.values)[0:r])\n",
    "y = np.array(list(data.y.values)[0:r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94201c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m = 2.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    return data[s<m]\n",
    "\n",
    "reject_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "reject_outliers(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_spl = UnivariateSpline(x,y,s=0,k=4)\n",
    "\n",
    "plt.semilogy(x,y,'ro',label = 'data')\n",
    "x_range = np.linspace(x[0],x[-1],1000)\n",
    "plt.semilogy(x_range,y_spl(x_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc5666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25367511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
