{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15f085-259f-4074-bd31-ab7a8720e801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import socketio\n",
    "sio = socketio.AsyncClient()\n",
    "\n",
    "file1 = \"ru_lock_unlock_normal1_simple.log\"\n",
    "file2 = \"ru_lock_unlock_dpd_hw_fault_simple.log\"\n",
    "\n",
    "await sio.connect('http://127.0.0.1:8000', namespaces=['/TextAnalysis/FileContainer', '/TextAnalysis/TextFileCompare'])\n",
    "await sio.emit('new_file', [f'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\{file1}'], namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(0.2)\n",
    "await sio.emit('load_config', 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419config.ecfg', namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(10)\n",
    "await sio.emit('new_file', [f'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\{file2}'], namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(0.2)\n",
    "await sio.emit('load_config', 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419config.ecfg', namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(10)\n",
    "await sio.emit('exec', {'first_file_namespace': f'/TextAnalysis/FileContainer/{file1}', 'second_file_namespace': f'/TextAnalysis/FileContainer/{file2}'}, namespace='/TextAnalysis/TextFileCompare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb27fd-377f-4b2f-a56d-b7f99749cbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sio1 = socketio.AsyncClient()\n",
    "await sio1.connect('http://127.0.0.1:8000', namespaces=[\n",
    "'/TextAnalysis/FileContainer',\n",
    "'/TextAnalysis/TextFileCompare',\n",
    "'/TextAnalysis/FileContainer/ru_lock_unlock_normal1_simple.log/TextFileFunction/SearchFunction/txlProcBranch0',\n",
    "'/TextAnalysis/FileContainer/ru_lock_unlock_dpd_hw_fault_simple.log/TextFileFunction/SearchFunction/txlProcBranch0'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b7ebe-2c69-452b-92a6-b819d607f3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = {}\n",
    "model2 = {}\n",
    "\n",
    "def set_data1(model):\n",
    "    model1.update(model)\n",
    "def set_data2(model):\n",
    "    model2.update(model)\n",
    "await sio1.emit('model', namespace='/TextAnalysis/FileContainer/ru_lock_unlock_normal1_simple.log/TextFileFunction/SearchFunction/txlProcBranch0', callback=set_data1)\n",
    "await asyncio.sleep(0.2)\n",
    "await sio1.emit('model', namespace='/TextAnalysis/FileContainer/ru_lock_unlock_dpd_hw_fault_simple.log/TextFileFunction/SearchFunction/txlProcBranch0', callback=set_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5c649-c93d-4e58-9400-7952d83b5b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "string = '       air_mongoose com_ericsson_trithread INFO cpu_id  process txlProcBranch fileAndLine spiMaster cc  msg Warning Slow response to SPI_SEND_REQ for device paCtrlDevice   took ms '\n",
    "re.sub(' '+\"+\", ' ', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514940e7-4ba2-401d-91fe-565b8b3b3003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = 'Power measurement'\n",
    "for item in model1['res_clean_lines']:\n",
    "    if s in item:\n",
    "        print('model1', item)\n",
    "        \n",
    "for item in model2['res_clean_lines']:\n",
    "    if s in item:\n",
    "        print('model2', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f4edf-0413-4bf3-ac33-ac63a293845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t[14:56:47.927884604] (+0.001409563) air6419_mongoose com_ericsson_trithread:INFO: { cpu_id = 2 }, { process = \"WorkerTaskAas\", fileAndLine = \"algAasHelper.cc:659\", msg = \"Missing subbandMappingExt param, using default fullband instead.\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26446a-5c23-406a-9ba8-3ada3a5745ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2['res_clean_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1768f2-5582-488b-882b-3c5bad989fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "        self.b = 2\n",
    "        \n",
    "    def __getattribute__(self, obj):\n",
    "        print(obj)\n",
    "        return object.__getattribute__(self, obj)\n",
    "    \n",
    "c = A()\n",
    "c.a * c.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68ae71-a31a-43eb-b5c8-5858319c55e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from asyncio import get_event_loop\n",
    "from text_analysis import *\n",
    "\n",
    "# loop = get_event_loop()\n",
    "# loop.run_until_complete(TextAnalysisModel('parallel'))\n",
    "\n",
    "web.run_app(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bed893-12aa-40c5-8aa0-685e15d37007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as dp\n",
    "\n",
    "str(dp('221210-12:40:51', yearfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843578f-c129-4057-abfe-4e4633cc13e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if '2022-12-11 01:12:21.105110' > '2022-12-11 01:12:22':\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d155b-32e7-4219-8d01-047fc736d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from parse import parse\n",
    "\n",
    "str1 = '230228-16:19:06+0100 172.21.11.66 23.0b MSRBS_NODE_MODEL_22.Q2_566.28125.116_3317 stopfile=/tmp/11737'\n",
    "str2 = 'BXP_7:     769,dl-1  disabled        false    essFdd150_Id2       B     dl    2162500         BandI      0,       0    469            469     SETUP     SETUP'\n",
    "# exp_extract = '{}MSRBS_NODE_MODEL_{version}_{}'\n",
    "exp_extract = '{bxp}:{:s}{carrierId}{:s}{Enabled}{:s}{RealRelease}{:s}{carrierType}{:s}{rfPort}{:s}dl{:s}{Frequency}{:s}{Band}{:s}{Arfcn_min}{:s}{Arfcn_max}{:s}{Power}{:s}{ReservedPower}{:s}{tr}{:s}{bdconf}'\n",
    "r_extract = parse(exp_extract, str2)\n",
    "print(r_extract.named)\n",
    "# print(r_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc08b0-17cb-4a11-bbc8-14f46f0f8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for index in self.text_file.data['test'].res_lines:\n",
    "    lines.append(self.text_file.lines[index])\n",
    "\n",
    "with open('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\ru_lock_unlock_normal2_simple.log', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(lines))\n",
    "    \n",
    "# jesd|dfe|radiosw|rProxyMedian.cc # (txlProcBranch0|TxBranchCtrl0).*event com_ericsson_trithread:INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da1f0d-de24-450c-b58b-010130d4d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = self.text_file.data['dl'].res_key_value\n",
    "file = pd.DataFrame(pd.Series(data['Band']['value']), columns=['Band'])\n",
    "\n",
    "file['rfPort'] = pd.Series(data['rfPort']['value'])\n",
    "file['rfPort'] = 'Port_' + file['rfPort']\n",
    "file['carrierType'] = pd.Series(data['carrierType']['value'])\n",
    "file['Power'] = pd.Series(data['Power']['value'])\n",
    "\n",
    "result = {\n",
    "            'SiteName': self.text_file.file_name.split('_radio4480')[0],\n",
    "            'Version': self.text_file.data['version'].res_key_value['version']['value'][0],\n",
    "            'RadioQuantity': len(self.text_file.data['device'].res_lines)\n",
    "         }\n",
    "for band,port,carrier,power in file.values:\n",
    "    result[band+'_'+port+'_carrier_config'] = carrier\n",
    "    result[band+'_'+port+'_output_power_config'] = power\n",
    "\n",
    "self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07042a0-ce72-48ff-8dd7-11415ec32f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\KaiHong_4480config_origin_data.csv')\n",
    "data = data.fillna('')\n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "band1.extend(band3)\n",
    "columns = band1\n",
    "total = len(data)\n",
    "res = data.groupby(columns).size().reset_index(name='RadioAmount')\n",
    "for index,item in enumerate(json.loads(res.to_json(orient='records'))):\n",
    "    band1_dbm = []\n",
    "    band3_dbm = []\n",
    "    total_dbm = 0\n",
    "    for key in item.keys():\n",
    "        if ('output_power_BandIII' in key) & (item[key] != ''):\n",
    "            band3_dbm.append(item[key])\n",
    "        elif ('output_power_BandI' in key) & (item[key] != ''):\n",
    "            band1_dbm.append(item[key])\n",
    "    band1_dbm = sum(band1_dbm) if len(band1_dbm) > 0 else 0\n",
    "    band3_dbm = sum(band3_dbm) if len(band3_dbm) > 0 else 0\n",
    "    total_dbm = band1_dbm + band3_dbm\n",
    "    res.loc[index, ['BandI_dBm', 'BandIII_dBm', 'BandI+BandIII_dBm']] = [band1_dbm,band3_dbm,total_dbm]\n",
    "res['Percentage'] = res['RadioAmount'] / total\n",
    "res.to_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\6651_config_Sweden_204_Nodes_config_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaa13e-e71e-4a3c-8078-c27a7cdb7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = self.text_analysis.batch_statistic.table['table'].values\n",
    "data = pd.DataFrame()\n",
    "for index, item in enumerate(items):\n",
    "    print(index)\n",
    "    try:\n",
    "        tmp = pd.DataFrame(item)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue\n",
    "    data = data.append(tmp, ignore_index=True)\n",
    "    \n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "columns.extend(band1)\n",
    "columns.extend(band3)\n",
    "data = data.reindex(columns=columns)\n",
    "data.to_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\KaiHong_4480config_origin_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532a7d2-c2ec-41ae-806b-0a25c956fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = self.text_file.data['dl'].res_key_value\n",
    "file = pd.DataFrame(pd.Series(data['Band']['value']), columns=['Band'])\n",
    "\n",
    "file['bxp'] = pd.Series(data['bxp']['value'])\n",
    "file['rfPort'] = pd.Series(data['rfPort']['value'])\n",
    "file['rfPort'] = 'Port_' + file['rfPort']\n",
    "file['carrierType'] = pd.Series(data['carrierType']['value'])\n",
    "file['Power'] = pd.Series(data['Power']['value'])\n",
    "\n",
    "result = []\n",
    "for bxp in set(file['bxp'].values):\n",
    "    item = {\n",
    "                'SiteName': self.text_file.file_name.split('.log')[0],\n",
    "                'Bxp': bxp,\n",
    "                'Version': self.text_file.data['version'].res_key_value['version']['value'][0]\n",
    "             }\n",
    "    tmp = file.loc[(file['bxp'] == bxp), :].reset_index(drop=True)\n",
    "    for band,bxp,port,carrier,power in tmp.values:\n",
    "        if band in ['BandI', 'BandIII']:\n",
    "            cc = band+'_'+port+'_carrier_config'\n",
    "            pc = band+'_'+port+'_output_power_config'\n",
    "            dBm = 'output_power_' + band+'_'+port + '_dBm'\n",
    "            if cc in item:\n",
    "                item[cc] = carrier + ' + ' + item[cc] if carrier < item[cc] else item[cc] + ' + ' + carrier\n",
    "                item[pc] = power + ' + ' + item[pc] if carrier < item[cc] else item[pc] + ' + ' + power\n",
    "                item[dBm] = item[dBm] + round(10**(int(power)/100)/1000, 1)\n",
    "            else:\n",
    "                item[cc] = carrier\n",
    "                item[pc] = power\n",
    "                item[dBm] = round(10**(int(power)/100)/1000, 1)\n",
    "    if len(item.keys())> 3:\n",
    "        result.append(item)\n",
    "\n",
    "self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a20888-6166-4e92-a73a-0844aba40c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "sheet_names = pd.read_excel(file_path, sheet_name=None).keys()\n",
    "sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bcf46-dc83-4475-b363-8afa60666fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_excel(file_path, sheet_name='Claro_4480_cc_SW', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcf6166-9977-4946-ba30-3b460b7be537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Start Handle Claro_4480_cc_SW...\n",
      "Start Handle Vivo_4480_cc_SW...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "print('Loading file...')\n",
    "sheet_names = pd.read_excel(file_path, sheet_name=None).keys()\n",
    "for sheet_name in sheet_names:\n",
    "    print(f'Start Handle {sheet_name}...')\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    result = []\n",
    "    x= list(data['SerialNo'].values)\n",
    "    sns = sorted(set(x), key=x.index)\n",
    "    for sn in sns:\n",
    "        radio = data.loc[(data['SerialNo'] == sn)&(data['MaxTxPower_br'].notna()), :].reset_index(drop=True)\n",
    "        if len(radio) == 0:\n",
    "            continue\n",
    "        item = {'SerialNo': sn, 'SwPack': list(radio['SwPack'].values)[0]}\n",
    "        for port,band,power in radio[['rfPortId', 'freqBand', 'MaxTxPower_br']].values:\n",
    "            if band in [1,3]:\n",
    "                item['Band'+str(int(band))+'_Port'+port+'_MaxTxPower_br'] = power\n",
    "\n",
    "        band1_power = []\n",
    "        band3_power = []\n",
    "        for key in item.keys():\n",
    "            if 'Band1' in key:\n",
    "                band1_power.append(item[key])\n",
    "            if 'Band3' in key:\n",
    "                band3_power.append(item[key])\n",
    "\n",
    "        item['Band1_MaxTxPower_br'] = sum(band1_power) if len(band1_power) > 0 else 0\n",
    "        item['Band3_MaxTxPower_br'] = sum(band3_power) if len(band3_power) > 0 else 0\n",
    "        item['Band1+Band3_MaxTxPower_br'] = item['Band1_MaxTxPower_br'] + item['Band3_MaxTxPower_br']\n",
    "        result.append(item)\n",
    "    data = ''\n",
    "    del data\n",
    "    origin_data = pd.DataFrame(result)\n",
    "    origin_data.to_csv(f'{output_path}\\\\{sheet_name}_Origin_Data.csv', index=False)\n",
    "\n",
    "    origin_data = origin_data.fillna('')\n",
    "    total = len(origin_data)\n",
    "    summary = origin_data.groupby(list(origin_data.columns[2:])).size().reset_index(name='RadioAmount')\n",
    "    summary['Percentage'] = summary['RadioAmount'] / total\n",
    "    summary.to_csv(f'{output_path}\\\\{sheet_name}_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a92b56-d3d2-4fbf-88f3-dbaf16daab6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def iterate_files_in_directory(directory):\n",
    "    # iterate over files in\n",
    "    # that directory\n",
    "    res = []\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            res.append(filename)\n",
    "    return res\n",
    "\n",
    "path = 'D:\\\\projects\\\\ericsson_flow\\\\ErrorLog'\n",
    "result = []\n",
    "for file in iterate_files_in_directory(path):\n",
    "    with open(path+'\\\\'+file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        tmp = []\n",
    "        for line in lines:\n",
    "            tmp.append(file.replace(' ','_').replace('.txt','')+':'+line)\n",
    "    result.extend(tmp)\n",
    "with open(path+'\\\\'+'DotErrorCase.log', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee65326-e770-4a6d-98fa-038c92d76935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.my_variable = 0\n",
    "    \n",
    "    def my_method(self):\n",
    "        pass\n",
    "    \n",
    "    def my_other_method(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def my_static_method():\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def my_class_method(cls):\n",
    "        pass\n",
    "\n",
    "# 获取MyClass对象的所有属性和方法\n",
    "all_attributes = dir(MyClass)\n",
    "\n",
    "# 遍历所有属性，标注哪些是函数哪些是变量\n",
    "for attribute in all_attributes:\n",
    "    # 判断属性是否是函数，并打印函数名称和类型\n",
    "    if callable(getattr(MyClass, attribute)):\n",
    "        print(f\"{attribute} is a function\")\n",
    "    # 如果不是函数，则打印属性名称和类型\n",
    "    else:\n",
    "        print(f\"{attribute} is a variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe86ef3-05cd-443e-8b7e-df84fcac089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script name: my_script.py\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: March 28, 2023\n",
    "Description: Collect the configuration information for multiple 4480 radios.\n",
    "Process: \n",
    "        1.Extract file returned by 'carrierListHandler print table' command.\n",
    "        2.Extract (version carrierType rfPort dl/ul Band Power)\n",
    "        3.Batch extraction and output to a table. \n",
    "        4.Export origin data based on a single radio.\n",
    "        5.Export summary information based on the configuration information of all radios.\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.dir_path = 'C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\6651_config_Denmark_68_Nodes'\n",
    "# Config Location\n",
    "self.config_path = 'D:\\\\projects\\\\ericsson_flow\\\\configs\\\\4480_Configure_Statistic_Config.ecfg'\n",
    "# Output Location\n",
    "self.output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "# Save name\n",
    "self.save_name = '6651_config_Denmark_68_Nodes'\n",
    "\n",
    "###################### Batch handle file, according to config ###############################\n",
    "table = await self.batch_handle(self.dir_path, self.config_path)\n",
    "table = table.drop(['search_atoms', 'chart_atoms', 'statistic_atoms'], axis=1)\n",
    "\n",
    "###################### Export origin data ###############################\n",
    "items = table['table'].values\n",
    "data = pd.DataFrame()\n",
    "for index, item in enumerate(items):\n",
    "    try:\n",
    "        tmp = pd.DataFrame(item)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue\n",
    "    data = data.append(tmp, ignore_index=True)\n",
    "    \n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "columns.extend(band1)\n",
    "columns.extend(band3)\n",
    "data = data.reindex(columns=columns)\n",
    "data.to_csv(f'{self.output_path}//{self.save_name}_origin_data.csv', index=False)\n",
    "await self.on_console(msg='Export Origin Data Finish!')\n",
    "\n",
    "###################### Export summary data ###############################\n",
    "data = data.fillna('')\n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "band1.extend(band3)\n",
    "columns = band1\n",
    "total = len(data)\n",
    "res = data.groupby(columns).size().reset_index(name='RadioAmount')\n",
    "for index,item in enumerate(json.loads(res.to_json(orient='records'))):\n",
    "    band1_dbm = []\n",
    "    band3_dbm = []\n",
    "    total_dbm = 0\n",
    "    for key in item.keys():\n",
    "        if ('output_power_BandIII' in key) & (item[key] != ''):\n",
    "            band3_dbm.append(item[key])\n",
    "        elif ('output_power_BandI' in key) & (item[key] != ''):\n",
    "            band1_dbm.append(item[key])\n",
    "    band1_dbm = sum(band1_dbm) if len(band1_dbm) > 0 else 0\n",
    "    band3_dbm = sum(band3_dbm) if len(band3_dbm) > 0 else 0\n",
    "    total_dbm = band1_dbm + band3_dbm\n",
    "    res.loc[index, ['BandI_dBm', 'BandIII_dBm', 'BandI+BandIII_dBm']] = [band1_dbm,band3_dbm,total_dbm]\n",
    "res['Percentage'] = res['RadioAmount'] / total\n",
    "res.to_csv(f'{self.output_path}//{self.save_name}_summary.csv', index=False)\n",
    "await self.on_console(msg='Export Summary Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848a8a4-f080-49cf-bfbd-22ed2d9a0c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect the configuration information for 4480 radios xslx.\n",
    "\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "CreateTime: 2023.3.20\n",
    "ChangeTime: 2023.3.30\n",
    "Version: 1.1\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.xslx_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "# Output Location\n",
    "self.output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "print('Loading file...')\n",
    "sheet_names = pd.read_excel(self.xslx_path, sheet_name=None).keys()\n",
    "for sheet_name in sheet_names:\n",
    "    print(f'Start Handle {sheet_name}...')\n",
    "    data = pd.read_excel(self.xslx_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    \n",
    "    ###################### Export origin data ###############################\n",
    "    result = []\n",
    "    x= list(data['SerialNo'].values)\n",
    "    sns = sorted(set(x), key=x.index)\n",
    "    for sn in sns:\n",
    "        radio = data.loc[(data['SerialNo'] == sn)&(data['MaxTxPower_br'].notna()), :].reset_index(drop=True)\n",
    "        if len(radio) == 0:\n",
    "            continue\n",
    "        item = {'SerialNo': sn, 'SwPack': list(radio['SwPack'].values)[0]}\n",
    "        for port,band,power in radio[['rfPortId', 'freqBand', 'MaxTxPower_br']].values:\n",
    "            if band in [1,3]:\n",
    "                item['Band'+str(int(band))+'_Port'+port+'_MaxTxPower_br'] = power\n",
    "\n",
    "        band1_power = []\n",
    "        band3_power = []\n",
    "        for key in item.keys():\n",
    "            if 'Band1' in key:\n",
    "                band1_power.append(item[key])\n",
    "            if 'Band3' in key:\n",
    "                band3_power.append(item[key])\n",
    "\n",
    "        item['Band1_MaxTxPower_br'] = sum(band1_power) if len(band1_power) > 0 else 0\n",
    "        item['Band3_MaxTxPower_br'] = sum(band3_power) if len(band3_power) > 0 else 0\n",
    "        item['Band1+Band3_MaxTxPower_br'] = item['Band1_MaxTxPower_br'] + item['Band3_MaxTxPower_br']\n",
    "        result.append(item)\n",
    "    data = ''\n",
    "    del data\n",
    "    origin_data = pd.DataFrame(result)\n",
    "    origin_data.to_csv(f'{self.output_path}\\\\{sheet_name}_Origin_Data.csv', index=False)\n",
    "    \n",
    "    ###################### Export summary data ###############################\n",
    "    origin_data = origin_data.fillna('')\n",
    "    total = len(origin_data)\n",
    "    summary = origin_data.groupby(list(origin_data.columns[2:])).size().reset_index(name='RadioAmount')\n",
    "    summary['Percentage'] = summary['RadioAmount'] / total\n",
    "    summary.to_csv(f'{self.output_path}\\\\{sheet_name}_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5907757-acef-438b-beb7-60aacea15e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script name: my_script.py\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: March 28, 2023\n",
    "Description: Collect the configuration information for multiple 4480 radios.\n",
    "Process: \n",
    "        1.Extract file returned by 'carrierListHandler print table' command.\n",
    "        2.Extract (version carrierType rfPort dl/ul Band Power)\n",
    "        3.Batch extraction and output to a table. \n",
    "        4.Export origin data based on a single radio.\n",
    "        5.Export summary information based on the configuration information of all radios.\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.file_path = 'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\ru_lock_unlock_normal1_simple.log'\n",
    "# Config Location\n",
    "self.config_path = 'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\6419ConfigSimple.ecfg'\n",
    "\n",
    "new_file_namespace = self.text_analysis.file_container.namespace+'/'+create_uuid4()\n",
    "tmp_file = await TextFileModel(self.text_analysis.file_container, new_file_namespace, self.file_path, 'batch')\n",
    "\n",
    "await self.on_console(msg='Loading config wait...')\n",
    "await tmp_file.on_load_all_config('', self.config_path)\n",
    "\n",
    "# data_tree = tmp_file.on_get_roles(_type='tree')\n",
    "data_list = tmp_file.on_get_roles(_type='list')\n",
    "\n",
    "def linear_scale(domain, range):\n",
    "    def scale(x):\n",
    "        return np.interp(x, domain, range)\n",
    "    return scale\n",
    "\n",
    "pixel_width = 5000\n",
    "align_type = 'timestamp'\n",
    "line_story_height = 20\n",
    "line_chart_height = 200\n",
    "interval_height = 10\n",
    "\n",
    "line_type = 'dash'\n",
    "\n",
    "glyph = []\n",
    "# define xaxis\n",
    "start_x = []\n",
    "end_x = []\n",
    "for node in data_list:\n",
    "    if node['data'] is not None:\n",
    "        if align_type == 'timestamp':\n",
    "            if(node['data']['start_timestamp'] != 0) & (node['data']['end_timestamp'] != 0):\n",
    "                start_x.append(node['data']['start_timestamp'])\n",
    "                end_x.append(node['data']['end_timestamp'])\n",
    "        else:\n",
    "            start_x.append(node['data']['start_global_index'])\n",
    "            end_x.append(node['data']['end_global_index'])\n",
    "glyph.append({\n",
    "    'type': 'XAxis',\n",
    "    'pixel_width': pixel_width,\n",
    "    'lower_bound': min(start_x),\n",
    "    'upper_bound': max(end_x)\n",
    "})\n",
    "\n",
    "inter_global = linear_scale([min(start_x), max(end_x)], [0, pixel_width])\n",
    "# define indented tree\n",
    "line_stories = []\n",
    "line_charts = []\n",
    "current_height = 0\n",
    "for node in data_list:\n",
    "    # print(node['identifier'], current_height)\n",
    "    if node['data'] is None:\n",
    "        node['data'] = {}\n",
    "        node['data']['sx'] = 0\n",
    "        node['data']['sy'] = current_height\n",
    "        node['data']['height'] = line_story_height\n",
    "        current_height = current_height + line_story_height + interval_height\n",
    "    else:\n",
    "        node['data']['sy'] = current_height\n",
    "        if align_type == 'timestamp':\n",
    "            if (node['data']['start_timestamp'] != 0) & (node['data']['end_timestamp'] != 0):\n",
    "                node['data']['sx'] = inter_global(node['data']['start_timestamp'])\n",
    "                node['data']['ex'] = inter_global(node['data']['end_timestamp'])\n",
    "            else:\n",
    "                node['data']['sx'] = 0\n",
    "                node['data']['ex'] = 0\n",
    "        else:\n",
    "            node['data']['sx'] = inter_global(node['data']['start_global_index'])\n",
    "            node['data']['ex'] = inter_global(node['data']['end_global_index'])\n",
    "            \n",
    "        inter_local = linear_scale([node['data']['sx'], node['data']['ex']], [0, node['data']['ex'] - node['data']['sx']])\n",
    "        if node['data']['type'] == 'chart':\n",
    "            for key in node['data']['select_lines'].keys():\n",
    "                for dot in node['data']['select_lines'][key]:\n",
    "                    if align_type == 'timestamp':\n",
    "                        dot['x'] = inter_local(inter_global(dot['timestamp']))\n",
    "                    else:\n",
    "                        dot['x'] = inter_local(inter_global(dot['global_index']))\n",
    "            node['data']['width'] = node['data']['ex'] - node['data']['sx']\n",
    "            node['data']['height'] = line_chart_height\n",
    "            node['data']['line_type'] = line_type\n",
    "            current_height = current_height + line_chart_height + interval_height\n",
    "            line_charts.append(node)\n",
    "        elif node['data']['type'] == 'search':\n",
    "            for key in node['data']['res_marks'].keys():\n",
    "                for dot in node['data']['res_marks'][key]:\n",
    "                    if align_type == 'timestamp':\n",
    "                        dot['x'] = inter_local(inter_global(dot['timestamp']))\n",
    "                    else:\n",
    "                        dot['x'] = inter_local(inter_global(dot['global_index']))\n",
    "                        \n",
    "            if (len(node['data']['res_compare_special_lines']) > 0):\n",
    "                for dot in node['data']['res_compare_special_lines']:\n",
    "                    if align_type == 'timestamp':\n",
    "                        dot['x'] = inter_local(inter_global(dot['timestamp']))\n",
    "                    else:\n",
    "                        dot['x'] = inter_local(inter_global(dot['global_index']))\n",
    "            node['data']['height'] = line_story_height\n",
    "            node['data']['top_triangles'] = node['data']['res_marks']\n",
    "            node['data']['bottom_triangles'] = node['data']['res_compare_special_lines']\n",
    "            current_height = current_height + line_story_height + interval_height\n",
    "            line_stories.append(node)\n",
    "    tmp_file.roles.update_node(node[\"identifier\"], data=node[\"data\"])\n",
    "\n",
    "data_tree = tmp_file.on_get_roles(_type='tree')\n",
    "glyph.append({\n",
    "    'type': 'IndentedTree',\n",
    "    'data': [{'identifier': '6419','data':data_tree}]\n",
    "})\n",
    "glyph.append({\n",
    "    'type': 'LineStory',\n",
    "    'data': line_stories\n",
    "})\n",
    "glyph.append({\n",
    "    'type': 'LineChart',\n",
    "    'data': line_charts\n",
    "})\n",
    "\n",
    "await self.on_draw('', glyph)\n",
    "await tmp_file.on_delete('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9e91fc-e786-4662-906e-99e5640877ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inter_global = np.interp(x=[5.2], xp=[5, 6], fp=[0, 10])\n",
    "inter_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075f8a3a-7b8a-4f21-8a9e-808913eee470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "\n",
    "# 创建一个示例树\n",
    "tree = Tree()\n",
    "tree.create_node(\"Node 1\", \"1\", data={\"key\": \"value1\"})\n",
    "tree.create_node(\"Node 2\", \"2\", parent=\"1\", data={\"key\": \"value2\"})\n",
    "\n",
    "# 输出树的结构，包括节点 ID 和默认属性\n",
    "node_list = tree.to_dict(sort=True, with_data=True)\n",
    "# for node_dict in node_list:\n",
    "#     node_id = node_dict[\"data\"][\"id\"]\n",
    "#     node_data = node_dict[\"data\"][\"key\"]\n",
    "#     node_children = node_dict.get(\"children\", [])\n",
    "#     print(f\"Node {node_id}: data={node_data}, children={node_children}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abaf33fa-32df-4e39-a42b-6d62b3949088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Node 1': {'children': [{'Node 2': {'data': {'key': 'value2'}}}],\n",
       "  'data': {'key': 'value1'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174bcd22-c113-4dfd-8c3c-643d9e9b4e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson_toolsets_env",
   "language": "python",
   "name": "ericsson_toolsets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
