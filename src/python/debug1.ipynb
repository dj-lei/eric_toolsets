{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15f085-259f-4074-bd31-ab7a8720e801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import socketio\n",
    "sio = socketio.AsyncClient()\n",
    "\n",
    "file1 = \"ru_lock_unlock_normal1_simple.log\"\n",
    "file2 = \"ru_lock_unlock_dpd_hw_fault_simple.log\"\n",
    "\n",
    "await sio.connect('http://127.0.0.1:8000', namespaces=['/TextAnalysis/FileContainer', '/TextAnalysis/TextFileCompare'])\n",
    "await sio.emit('new_file', [f'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\{file1}'], namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(0.2)\n",
    "await sio.emit('load_config', 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419config.ecfg', namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(10)\n",
    "await sio.emit('new_file', [f'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\{file2}'], namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(0.2)\n",
    "await sio.emit('load_config', 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419config.ecfg', namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(10)\n",
    "await sio.emit('exec', {'first_file_namespace': f'/TextAnalysis/FileContainer/{file1}', 'second_file_namespace': f'/TextAnalysis/FileContainer/{file2}'}, namespace='/TextAnalysis/TextFileCompare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb27fd-377f-4b2f-a56d-b7f99749cbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sio1 = socketio.AsyncClient()\n",
    "await sio1.connect('http://127.0.0.1:8000', namespaces=[\n",
    "'/TextAnalysis/FileContainer',\n",
    "'/TextAnalysis/TextFileCompare',\n",
    "'/TextAnalysis/FileContainer/ru_lock_unlock_normal1_simple.log/TextFileFunction/SearchFunction/txlProcBranch0',\n",
    "'/TextAnalysis/FileContainer/ru_lock_unlock_dpd_hw_fault_simple.log/TextFileFunction/SearchFunction/txlProcBranch0'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b7ebe-2c69-452b-92a6-b819d607f3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = {}\n",
    "model2 = {}\n",
    "\n",
    "def set_data1(model):\n",
    "    model1.update(model)\n",
    "def set_data2(model):\n",
    "    model2.update(model)\n",
    "await sio1.emit('model', namespace='/TextAnalysis/FileContainer/ru_lock_unlock_normal1_simple.log/TextFileFunction/SearchFunction/txlProcBranch0', callback=set_data1)\n",
    "await asyncio.sleep(0.2)\n",
    "await sio1.emit('model', namespace='/TextAnalysis/FileContainer/ru_lock_unlock_dpd_hw_fault_simple.log/TextFileFunction/SearchFunction/txlProcBranch0', callback=set_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5c649-c93d-4e58-9400-7952d83b5b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "string = '       air_mongoose com_ericsson_trithread INFO cpu_id  process txlProcBranch fileAndLine spiMaster cc  msg Warning Slow response to SPI_SEND_REQ for device paCtrlDevice   took ms '\n",
    "re.sub(' '+\"+\", ' ', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514940e7-4ba2-401d-91fe-565b8b3b3003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = 'Power measurement'\n",
    "for item in model1['res_clean_lines']:\n",
    "    if s in item:\n",
    "        print('model1', item)\n",
    "        \n",
    "for item in model2['res_clean_lines']:\n",
    "    if s in item:\n",
    "        print('model2', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f4edf-0413-4bf3-ac33-ac63a293845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t[14:56:47.927884604] (+0.001409563) air6419_mongoose com_ericsson_trithread:INFO: { cpu_id = 2 }, { process = \"WorkerTaskAas\", fileAndLine = \"algAasHelper.cc:659\", msg = \"Missing subbandMappingExt param, using default fullband instead.\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26446a-5c23-406a-9ba8-3ada3a5745ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2['res_clean_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1768f2-5582-488b-882b-3c5bad989fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "        self.b = 2\n",
    "        \n",
    "    def __getattribute__(self, obj):\n",
    "        print(obj)\n",
    "        return object.__getattribute__(self, obj)\n",
    "    \n",
    "c = A()\n",
    "c.a * c.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68ae71-a31a-43eb-b5c8-5858319c55e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from asyncio import get_event_loop\n",
    "from text_analysis import *\n",
    "\n",
    "# loop = get_event_loop()\n",
    "# loop.run_until_complete(TextAnalysisModel('parallel'))\n",
    "\n",
    "web.run_app(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bed893-12aa-40c5-8aa0-685e15d37007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as dp\n",
    "\n",
    "str(dp('221210-12:40:51', yearfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843578f-c129-4057-abfe-4e4633cc13e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if '2022-12-11 01:12:21.105110' > '2022-12-11 01:12:22':\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d155b-32e7-4219-8d01-047fc736d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from parse import parse\n",
    "\n",
    "str1 = '230228-16:19:06+0100 172.21.11.66 23.0b MSRBS_NODE_MODEL_22.Q2_566.28125.116_3317 stopfile=/tmp/11737'\n",
    "str2 = 'BXP_7:     769,dl-1  disabled        false    essFdd150_Id2       B     dl    2162500         BandI      0,       0    469            469     SETUP     SETUP'\n",
    "# exp_extract = '{}MSRBS_NODE_MODEL_{version}_{}'\n",
    "exp_extract = '{bxp}:{:s}{carrierId}{:s}{Enabled}{:s}{RealRelease}{:s}{carrierType}{:s}{rfPort}{:s}dl{:s}{Frequency}{:s}{Band}{:s}{Arfcn_min}{:s}{Arfcn_max}{:s}{Power}{:s}{ReservedPower}{:s}{tr}{:s}{bdconf}'\n",
    "r_extract = parse(exp_extract, str2)\n",
    "print(r_extract.named)\n",
    "# print(r_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc08b0-17cb-4a11-bbc8-14f46f0f8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for index in self.text_file.data['test'].res_lines:\n",
    "    lines.append(self.text_file.lines[index])\n",
    "\n",
    "with open('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\ru_lock_unlock_normal2_simple.log', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(lines))\n",
    "    \n",
    "# jesd|dfe|radiosw|rProxyMedian.cc # (txlProcBranch0|TxBranchCtrl0).*event com_ericsson_trithread:INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da1f0d-de24-450c-b58b-010130d4d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = self.text_file.data['dl'].res_key_value\n",
    "file = pd.DataFrame(pd.Series(data['Band']['value']), columns=['Band'])\n",
    "\n",
    "file['rfPort'] = pd.Series(data['rfPort']['value'])\n",
    "file['rfPort'] = 'Port_' + file['rfPort']\n",
    "file['carrierType'] = pd.Series(data['carrierType']['value'])\n",
    "file['Power'] = pd.Series(data['Power']['value'])\n",
    "\n",
    "result = {\n",
    "            'SiteName': self.text_file.file_name.split('_radio4480')[0],\n",
    "            'Version': self.text_file.data['version'].res_key_value['version']['value'][0],\n",
    "            'RadioQuantity': len(self.text_file.data['device'].res_lines)\n",
    "         }\n",
    "for band,port,carrier,power in file.values:\n",
    "    result[band+'_'+port+'_carrier_config'] = carrier\n",
    "    result[band+'_'+port+'_output_power_config'] = power\n",
    "\n",
    "self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07042a0-ce72-48ff-8dd7-11415ec32f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\KaiHong_4480config_origin_data.csv')\n",
    "data = data.fillna('')\n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "band1.extend(band3)\n",
    "columns = band1\n",
    "total = len(data)\n",
    "res = data.groupby(columns).size().reset_index(name='RadioAmount')\n",
    "for index,item in enumerate(json.loads(res.to_json(orient='records'))):\n",
    "    band1_dbm = []\n",
    "    band3_dbm = []\n",
    "    total_dbm = 0\n",
    "    for key in item.keys():\n",
    "        if ('output_power_BandIII' in key) & (item[key] != ''):\n",
    "            band3_dbm.append(item[key])\n",
    "        elif ('output_power_BandI' in key) & (item[key] != ''):\n",
    "            band1_dbm.append(item[key])\n",
    "    band1_dbm = sum(band1_dbm) if len(band1_dbm) > 0 else 0\n",
    "    band3_dbm = sum(band3_dbm) if len(band3_dbm) > 0 else 0\n",
    "    total_dbm = band1_dbm + band3_dbm\n",
    "    res.loc[index, ['BandI_dBm', 'BandIII_dBm', 'BandI+BandIII_dBm']] = [band1_dbm,band3_dbm,total_dbm]\n",
    "res['Percentage'] = res['RadioAmount'] / total\n",
    "res.to_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\6651_config_Sweden_204_Nodes_config_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaa13e-e71e-4a3c-8078-c27a7cdb7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = self.text_analysis.batch_statistic.table['table'].values\n",
    "data = pd.DataFrame()\n",
    "for index, item in enumerate(items):\n",
    "    print(index)\n",
    "    try:\n",
    "        tmp = pd.DataFrame(item)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue\n",
    "    data = data.append(tmp, ignore_index=True)\n",
    "    \n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "columns.extend(band1)\n",
    "columns.extend(band3)\n",
    "data = data.reindex(columns=columns)\n",
    "data.to_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\KaiHong_4480config_origin_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532a7d2-c2ec-41ae-806b-0a25c956fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = self.text_file.data['dl'].res_key_value\n",
    "file = pd.DataFrame(pd.Series(data['Band']['value']), columns=['Band'])\n",
    "\n",
    "file['bxp'] = pd.Series(data['bxp']['value'])\n",
    "file['rfPort'] = pd.Series(data['rfPort']['value'])\n",
    "file['rfPort'] = 'Port_' + file['rfPort']\n",
    "file['carrierType'] = pd.Series(data['carrierType']['value'])\n",
    "file['Power'] = pd.Series(data['Power']['value'])\n",
    "\n",
    "result = []\n",
    "for bxp in set(file['bxp'].values):\n",
    "    item = {\n",
    "                'SiteName': self.text_file.file_name.split('.log')[0],\n",
    "                'Bxp': bxp,\n",
    "                'Version': self.text_file.data['version'].res_key_value['version']['value'][0]\n",
    "             }\n",
    "    tmp = file.loc[(file['bxp'] == bxp), :].reset_index(drop=True)\n",
    "    for band,bxp,port,carrier,power in tmp.values:\n",
    "        if band in ['BandI', 'BandIII']:\n",
    "            cc = band+'_'+port+'_carrier_config'\n",
    "            pc = band+'_'+port+'_output_power_config'\n",
    "            dBm = 'output_power_' + band+'_'+port + '_dBm'\n",
    "            if cc in item:\n",
    "                item[cc] = carrier + ' + ' + item[cc] if carrier < item[cc] else item[cc] + ' + ' + carrier\n",
    "                item[pc] = power + ' + ' + item[pc] if carrier < item[cc] else item[pc] + ' + ' + power\n",
    "                item[dBm] = item[dBm] + round(10**(int(power)/100)/1000, 1)\n",
    "            else:\n",
    "                item[cc] = carrier\n",
    "                item[pc] = power\n",
    "                item[dBm] = round(10**(int(power)/100)/1000, 1)\n",
    "    if len(item.keys())> 3:\n",
    "        result.append(item)\n",
    "\n",
    "self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a20888-6166-4e92-a73a-0844aba40c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "sheet_names = pd.read_excel(file_path, sheet_name=None).keys()\n",
    "sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bcf46-dc83-4475-b363-8afa60666fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_excel(file_path, sheet_name='Claro_4480_cc_SW', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf6166-9977-4946-ba30-3b460b7be537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "print('Loading file...')\n",
    "sheet_names = pd.read_excel(file_path, sheet_name=None).keys()\n",
    "for sheet_name in sheet_names:\n",
    "    print(f'Start Handle {sheet_name}...')\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    result = []\n",
    "    x= list(data['SerialNo'].values)\n",
    "    sns = sorted(set(x), key=x.index)\n",
    "    for sn in sns:\n",
    "        radio = data.loc[(data['SerialNo'] == sn)&(data['MaxTxPower_br'].notna()), :].reset_index(drop=True)\n",
    "        if len(radio) == 0:\n",
    "            continue\n",
    "        item = {'SerialNo': sn, 'SwPack': list(radio['SwPack'].values)[0]}\n",
    "        for port,band,power in radio[['rfPortId', 'freqBand', 'MaxTxPower_br']].values:\n",
    "            if band in [1,3]:\n",
    "                item['Band'+str(int(band))+'_Port'+port+'_MaxTxPower_br'] = power\n",
    "\n",
    "        band1_power = []\n",
    "        band3_power = []\n",
    "        for key in item.keys():\n",
    "            if 'Band1' in key:\n",
    "                band1_power.append(item[key])\n",
    "            if 'Band3' in key:\n",
    "                band3_power.append(item[key])\n",
    "\n",
    "        item['Band1_MaxTxPower_br'] = sum(band1_power) if len(band1_power) > 0 else 0\n",
    "        item['Band3_MaxTxPower_br'] = sum(band3_power) if len(band3_power) > 0 else 0\n",
    "        item['Band1+Band3_MaxTxPower_br'] = item['Band1_MaxTxPower_br'] + item['Band3_MaxTxPower_br']\n",
    "        result.append(item)\n",
    "    data = ''\n",
    "    del data\n",
    "    origin_data = pd.DataFrame(result)\n",
    "    origin_data.to_csv(f'{output_path}\\\\{sheet_name}_Origin_Data.csv', index=False)\n",
    "\n",
    "    origin_data = origin_data.fillna('')\n",
    "    total = len(origin_data)\n",
    "    summary = origin_data.groupby(list(origin_data.columns[2:])).size().reset_index(name='RadioAmount')\n",
    "    summary['Percentage'] = summary['RadioAmount'] / total\n",
    "    summary.to_csv(f'{output_path}\\\\{sheet_name}_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a92b56-d3d2-4fbf-88f3-dbaf16daab6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def iterate_files_in_directory(directory):\n",
    "    # iterate over files in\n",
    "    # that directory\n",
    "    res = []\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            res.append(filename)\n",
    "    return res\n",
    "\n",
    "path = 'D:\\\\projects\\\\ericsson_flow\\\\ErrorLog'\n",
    "result = []\n",
    "for file in iterate_files_in_directory(path):\n",
    "    with open(path+'\\\\'+file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        tmp = []\n",
    "        for line in lines:\n",
    "            tmp.append(file.replace(' ','_').replace('.txt','')+':'+line)\n",
    "    result.extend(tmp)\n",
    "with open(path+'\\\\'+'DotErrorCase.log', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee65326-e770-4a6d-98fa-038c92d76935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        self.my_variable = 0\n",
    "    \n",
    "    def my_method(self):\n",
    "        pass\n",
    "    \n",
    "    def my_other_method(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def my_static_method():\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def my_class_method(cls):\n",
    "        pass\n",
    "\n",
    "# 获取MyClass对象的所有属性和方法\n",
    "all_attributes = dir(MyClass)\n",
    "\n",
    "# 遍历所有属性，标注哪些是函数哪些是变量\n",
    "for attribute in all_attributes:\n",
    "    # 判断属性是否是函数，并打印函数名称和类型\n",
    "    if callable(getattr(MyClass, attribute)):\n",
    "        print(f\"{attribute} is a function\")\n",
    "    # 如果不是函数，则打印属性名称和类型\n",
    "    else:\n",
    "        print(f\"{attribute} is a variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe86ef3-05cd-443e-8b7e-df84fcac089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script name: my_script.py\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: March 28, 2023\n",
    "Description: Collect the configuration information for multiple 4480 radios.\n",
    "Process: \n",
    "        1.Extract file returned by 'carrierListHandler print table' command.\n",
    "        2.Extract (version carrierType rfPort dl/ul Band Power)\n",
    "        3.Batch extraction and output to a table. \n",
    "        4.Export origin data based on a single radio.\n",
    "        5.Export summary information based on the configuration information of all radios.\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.dir_path = 'C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\6651_config_Denmark_68_Nodes'\n",
    "# Config Location\n",
    "self.config_path = 'D:\\\\projects\\\\ericsson_flow\\\\configs\\\\4480_Configure_Statistic_Config.ecfg'\n",
    "# Output Location\n",
    "self.output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "# Save name\n",
    "self.save_name = '6651_config_Denmark_68_Nodes'\n",
    "\n",
    "###################### Batch handle file, according to config ###############################\n",
    "table = await self.batch_handle(self.dir_path, self.config_path)\n",
    "table = table.drop(['search_atoms', 'chart_atoms', 'statistic_atoms'], axis=1)\n",
    "\n",
    "###################### Export origin data ###############################\n",
    "items = table['table'].values\n",
    "data = pd.DataFrame()\n",
    "for index, item in enumerate(items):\n",
    "    try:\n",
    "        tmp = pd.DataFrame(item)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue\n",
    "    data = data.append(tmp, ignore_index=True)\n",
    "    \n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "columns.extend(band1)\n",
    "columns.extend(band3)\n",
    "data = data.reindex(columns=columns)\n",
    "data.to_csv(f'{self.output_path}//{self.save_name}_origin_data.csv', index=False)\n",
    "await self.on_console(msg='Export Origin Data Finish!')\n",
    "\n",
    "###################### Export summary data ###############################\n",
    "data = data.fillna('')\n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "band1.extend(band3)\n",
    "columns = band1\n",
    "total = len(data)\n",
    "res = data.groupby(columns).size().reset_index(name='RadioAmount')\n",
    "for index,item in enumerate(json.loads(res.to_json(orient='records'))):\n",
    "    band1_dbm = []\n",
    "    band3_dbm = []\n",
    "    total_dbm = 0\n",
    "    for key in item.keys():\n",
    "        if ('output_power_BandIII' in key) & (item[key] != ''):\n",
    "            band3_dbm.append(item[key])\n",
    "        elif ('output_power_BandI' in key) & (item[key] != ''):\n",
    "            band1_dbm.append(item[key])\n",
    "    band1_dbm = sum(band1_dbm) if len(band1_dbm) > 0 else 0\n",
    "    band3_dbm = sum(band3_dbm) if len(band3_dbm) > 0 else 0\n",
    "    total_dbm = band1_dbm + band3_dbm\n",
    "    res.loc[index, ['BandI_dBm', 'BandIII_dBm', 'BandI+BandIII_dBm']] = [band1_dbm,band3_dbm,total_dbm]\n",
    "res['Percentage'] = res['RadioAmount'] / total\n",
    "res.to_csv(f'{self.output_path}//{self.save_name}_summary.csv', index=False)\n",
    "await self.on_console(msg='Export Summary Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848a8a4-f080-49cf-bfbd-22ed2d9a0c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect the configuration information for 4480 radios xslx.\n",
    "\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "CreateTime: 2023.3.20\n",
    "ChangeTime: 2023.3.30\n",
    "Version: 1.1\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.xslx_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "# Output Location\n",
    "self.output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "print('Loading file...')\n",
    "sheet_names = pd.read_excel(self.xslx_path, sheet_name=None).keys()\n",
    "for sheet_name in sheet_names:\n",
    "    print(f'Start Handle {sheet_name}...')\n",
    "    data = pd.read_excel(self.xslx_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    \n",
    "    ###################### Export origin data ###############################\n",
    "    result = []\n",
    "    x= list(data['SerialNo'].values)\n",
    "    sns = sorted(set(x), key=x.index)\n",
    "    for sn in sns:\n",
    "        radio = data.loc[(data['SerialNo'] == sn)&(data['MaxTxPower_br'].notna()), :].reset_index(drop=True)\n",
    "        if len(radio) == 0:\n",
    "            continue\n",
    "        item = {'SerialNo': sn, 'SwPack': list(radio['SwPack'].values)[0]}\n",
    "        for port,band,power in radio[['rfPortId', 'freqBand', 'MaxTxPower_br']].values:\n",
    "            if band in [1,3]:\n",
    "                item['Band'+str(int(band))+'_Port'+port+'_MaxTxPower_br'] = power\n",
    "\n",
    "        band1_power = []\n",
    "        band3_power = []\n",
    "        for key in item.keys():\n",
    "            if 'Band1' in key:\n",
    "                band1_power.append(item[key])\n",
    "            if 'Band3' in key:\n",
    "                band3_power.append(item[key])\n",
    "\n",
    "        item['Band1_MaxTxPower_br'] = sum(band1_power) if len(band1_power) > 0 else 0\n",
    "        item['Band3_MaxTxPower_br'] = sum(band3_power) if len(band3_power) > 0 else 0\n",
    "        item['Band1+Band3_MaxTxPower_br'] = item['Band1_MaxTxPower_br'] + item['Band3_MaxTxPower_br']\n",
    "        result.append(item)\n",
    "    data = ''\n",
    "    del data\n",
    "    origin_data = pd.DataFrame(result)\n",
    "    origin_data.to_csv(f'{self.output_path}\\\\{sheet_name}_Origin_Data.csv', index=False)\n",
    "    \n",
    "    ###################### Export summary data ###############################\n",
    "    origin_data = origin_data.fillna('')\n",
    "    total = len(origin_data)\n",
    "    summary = origin_data.groupby(list(origin_data.columns[2:])).size().reset_index(name='RadioAmount')\n",
    "    summary['Percentage'] = summary['RadioAmount'] / total\n",
    "    summary.to_csv(f'{self.output_path}\\\\{sheet_name}_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf33fa-32df-4e39-a42b-6d62b3949088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script name: DOT4455_Abnormal_Analyze.escp\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: April 11, 2023\n",
    "Description: Batch analyze DOT4455 abnormal keywords and group them based on RU, RdPort, and Abnormal.\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "group = ['Root','RU','RP','Abnormal']\n",
    "# Files directory Location\n",
    "self.dir_path = 'D:/projects/ericsson_flow/new_files/low_tx_power_log0331'\n",
    "self.exps = [\n",
    "                {'name': 'DPD errorCode 0x340a', 'exp': '{RU}: OK {} {timestampd} {timestampt} {}: DPD errorCode 0x340a{}'},\n",
    "                {'name': 'Low tx Power', 'exp': '{RU}: OK {} {timestampd} {timestampt} {}: Low tx Power{}'}\n",
    "            ]\n",
    "self.end_marker = '{}Done RdId:{RI}, RdPort:{RP}{}'\n",
    "origin_data_output = 'D:/projects/ericsson_flow/new_files/OriginData.csv'\n",
    "root_name = 'DOT4455'\n",
    "pixel_width = 5000\n",
    "\n",
    "###################### Execution area ###############################\n",
    "await self.on_console(msg='Script running...')\n",
    "# extract keywords and generate origin data\n",
    "result = pd.DataFrame()\n",
    "for file_name in iterate_files_in_directory(self.dir_path):\n",
    "    path = f'{self.dir_path}\\\\{file_name}'\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    rd_port = []\n",
    "    for line in lines:\n",
    "        for exp in self.exps:\n",
    "            r = parse(exp['exp'], line)\n",
    "            if r is not None:\n",
    "                rd_port.append({'IP': file_name, 'RU': r['RU'], 'Abnormal': exp['name'], 'timestamp': convert_datetime_timestamp(r['timestampd'] + ' ' + r['timestampt'])})\n",
    "        if parse(self.end_marker, line) is not None:\n",
    "            tmp = pd.DataFrame(rd_port)\n",
    "            tmp['RP'] = parse(self.end_marker, line)['RP']\n",
    "            result = result.append(tmp).reset_index(drop=True)\n",
    "            rd_port = []\n",
    "    await self.on_console(msg=f'Finish {file_name}.')\n",
    "result['Root'] = root_name\n",
    "result['RP'] = result['RP'].astype(str)\n",
    "result = result.loc[:, ['Root','IP','RU','RP','Abnormal','timestamp']]\n",
    "result.to_csv(origin_data_output, index=False)\n",
    "\n",
    "# result = pd.read_csv('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\OriginData.csv')\n",
    "# result['RP'] = result['RP'].astype(str)\n",
    "\n",
    "# organize the required data.\n",
    "items = []\n",
    "grouped = result.groupby(group)\\\n",
    "    .apply(lambda x: x[['IP', 'timestamp']].assign(api='that.textAnalysisView.fileContainerView.controlNewFile([\"'+self.dir_path+'/'+x['IP']+'\"])').to_dict('records'))\\\n",
    "    .reset_index(name='data')\n",
    "group.append('data')\n",
    "for p in grouped[group].values:\n",
    "    groups = p[0: -1]\n",
    "    data = p[-1]\n",
    "    items.append({'path': list(groups), 'graph_type': 'ScatterPlot', 'start_timestamp': min(pd.DataFrame(data)['timestamp'].values), 'end_timestamp': max(pd.DataFrame(data)['timestamp'].values), 'elements': data})\n",
    "\n",
    "start_x = []\n",
    "end_x = []\n",
    "for item in items:\n",
    "    start_x.append(item['start_timestamp'])\n",
    "    end_x.append(item['end_timestamp'])\n",
    "\n",
    "graphs = []\n",
    "# define xaxis\n",
    "graphs.append({\n",
    "    'type': 'XAxis',\n",
    "    'width': pixel_width,\n",
    "    'lower_bound': min(start_x),\n",
    "    'upper_bound': max(end_x),\n",
    "    'tick_format_func': 'formatTimestamp'\n",
    "})\n",
    "\n",
    "# define IndentedTree\n",
    "global_inter = linear_scale([min(start_x), max(end_x)], [0, pixel_width])\n",
    "tree = IndentedTree('', 0, pixel_width, pixel_width, items, global_inter)\n",
    "graphs.append({'id': tree.id, 'type': 'IndentedTree', 'elements': convert_dict_format(tree.to_dict(sort=False, with_data=True))})\n",
    "\n",
    "nodes = tree.get_all_nodes_to_list()\n",
    "for node in nodes:\n",
    "    if node['elements'] is not None:\n",
    "        sp = ScatterPlot(node['id'],node['sx'],node['ex'],node['ex'] - node['sx'],node['elements'],global_inter)\n",
    "        node['type'] = 'ScatterPlot'\n",
    "        graphs.append(node)\n",
    "\n",
    "graphs.append({\n",
    "    'type': 'Brush',\n",
    "    'width': pixel_width,\n",
    "    'height': tree.height\n",
    "})\n",
    "await self.on_draw('', graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb2b81-c3bd-41c4-852b-2d12fd1eef14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from graph import *\n",
    "\n",
    "self.dir_path = 'D:/projects/ericsson_flow/new_files/low_tx_power_log0331'\n",
    "pixel_width = 5000\n",
    "\n",
    "group = ['Root','RU','RP','Abnormal']\n",
    "result = pd.read_csv('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\OriginData.csv')\n",
    "result['RP'] = result['RP'].astype(str)\n",
    "\n",
    "items = []\n",
    "# create tree\n",
    "grouped = result.groupby(group)\\\n",
    "    .apply(lambda x: x[['IP', 'timestamp']].assign(api='that.textAnalysisView.fileContainerView.controlNewFile([\"'+self.dir_path+'/'+x['IP']+'\"])').to_dict('records'))\\\n",
    "    .reset_index(name='data')\n",
    "group.append('data')\n",
    "for p in grouped[group].values:\n",
    "    groups = p[0: -1]\n",
    "    data = p[-1]\n",
    "    items.append({'path': list(groups), 'graph_type': 'ScatterPlot', 'start_timestamp': min(pd.DataFrame(data)['timestamp'].values), 'end_timestamp': max(pd.DataFrame(data)['timestamp'].values), 'elements': data})\n",
    "\n",
    "start_x = []\n",
    "end_x = []\n",
    "for item in items:\n",
    "    start_x.append(item['start_timestamp'])\n",
    "    end_x.append(item['end_timestamp'])\n",
    "\n",
    "graphs = []\n",
    "# define xaxis\n",
    "graphs.append({\n",
    "    'type': 'XAxis',\n",
    "    'width': pixel_width,\n",
    "    'lower_bound': min(start_x),\n",
    "    'upper_bound': max(end_x),\n",
    "    'tick_format_func': 'formatTimestamp'\n",
    "})\n",
    "\n",
    "global_inter = linear_scale([min(start_x), max(end_x)], [0, pixel_width])\n",
    "tree = IndentedTree('', 0, pixel_width, pixel_width, items, global_inter)\n",
    "graphs.append({'id': tree.id, 'type': 'IndentedTree', 'elements': convert_dict_format(tree.to_dict(sort=False, with_data=True))})\n",
    "\n",
    "nodes = tree.get_all_nodes_to_list()\n",
    "for node in nodes:\n",
    "    if node['elements'] is not None:\n",
    "        sp = ScatterPlot(node['id'],node['sx'],node['ex'],node['ex'] - node['sx'],node['elements'],global_inter)\n",
    "        node['type'] = 'ScatterPlot'\n",
    "        graphs.append(node)\n",
    "\n",
    "graphs.append({\n",
    "    'type': 'Brush',\n",
    "    'width': pixel_width,\n",
    "    'height': tree.height\n",
    "})\n",
    "await self.on_draw('', graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2767f8db-5805-4146-8717-ff0ad068194e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trx status': {'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}',\n",
       "  'end_exp': 'coli>/fruacc/lhsh{}',\n",
       "  'extract_exps': {'txPma': {'exp': '{}txPma{}: {txPma:f},{}',\n",
       "    'cond': \"row['txPma_abnormal'] = False\"},\n",
       "   'txDpdPma': {'exp': '{}txDpdPma{}: {txDpdPma:f},{}',\n",
       "    'cond': \"row['txDpdPma_abnormal'] = True if row['txPma']['value'] - row['txDpdPma']['value'] > 4 else False\"},\n",
       "   'txPmb': {'exp': '{}txPmb{}: {txPmb:f},{}',\n",
       "    'cond': \"row['txPmb_abnormal'] = True if row['txPma']['value'] - row['txPmb']['value'] != 0 else False\"},\n",
       "   'txTorPmb': {'exp': '{}txTorPmb{}: {txTorPmb:f},{}',\n",
       "    'cond': \"row['txTorPmb_abnormal'] = True if row['txPma']['value'] - row['txTorPmb']['value'] > 0.1 else False\"},\n",
       "   'dpd': {'exp': '{}dpd {}: {dpd},{}',\n",
       "    'cond': \"row['dpd_abnormal'] = True if row['dpd']['value'] in ['off'] else False\"},\n",
       "   'dpdStateMachine': {'exp': '{}dpdStateMachine{}: {dpdStateMachine},{}',\n",
       "    'cond': \"row['dpdStateMachine_abnormal'] = True if row['dpdStateMachine']['value'] in ['OFF'] else False\"},\n",
       "   'gainStateMachine': {'exp': '{}gainStateMachine{}: {gainStateMachine},{}',\n",
       "    'cond': \"row['gainStateMachine_abnormal'] = True if row['gainStateMachine']['value'] in ['CtrlGainStateIdle:started', 'ns:stopped'] else False\"},\n",
       "   'linearizationStateMachine': {'exp': '{}linearizationStateMachine{}: {linearizationStateMachine},{}',\n",
       "    'cond': \"row['linearizationStateMachine_abnormal'] = True if row['linearizationStateMachine']['value'] in ['ns:stopped'] else False\"}}}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = {\n",
    "    'trx status': {'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}', 'extract_exps': {\n",
    "                                                                                                                        'txPma':{'exp':'{}txPma{}: {txPma:f},{}', 'cond': \"row['txPma_abnormal'] = False\"},\n",
    "                                                                                                                        'txDpdPma':{'exp':'{}txDpdPma{}: {txDpdPma:f},{}', 'cond': \"row['txDpdPma_abnormal'] = True if row['txPma']['value'] - row['txDpdPma']['value'] > 4 else False\"},\n",
    "                                                                                                                        'txPmb':{'exp':'{}txPmb{}: {txPmb:f},{}', 'cond': \"row['txPmb_abnormal'] = True if row['txPma']['value'] - row['txPmb']['value'] != 0 else False\"},\n",
    "                                                                                                                        'txTorPmb':{'exp':'{}txTorPmb{}: {txTorPmb:f},{}', 'cond': \"row['txTorPmb_abnormal'] = True if row['txPma']['value'] - row['txTorPmb']['value'] > 0.1 else False\"},\n",
    "                                                                                                                        'dpd':{'exp':'{}dpd {}: {dpd},{}', 'cond': \"row['dpd_abnormal'] = True if row['dpd']['value'] in ['off'] else False\"},\n",
    "                                                                                                                        'dpdStateMachine':{'exp':'{}dpdStateMachine{}: {dpdStateMachine},{}', 'cond': \"row['dpdStateMachine_abnormal'] = True if row['dpdStateMachine']['value'] in ['OFF'] else False\"},\n",
    "                                                                                                                        'gainStateMachine':{'exp':'{}gainStateMachine{}: {gainStateMachine},{}', 'cond': \"row['gainStateMachine_abnormal'] = True if row['gainStateMachine']['value'] in ['CtrlGainStateIdle:started', 'ns:stopped'] else False\"},\n",
    "                                                                                                                        'linearizationStateMachine':{'exp':'{}linearizationStateMachine{}: {linearizationStateMachine},{}', 'cond': \"row['linearizationStateMachine_abnormal'] = True if row['linearizationStateMachine']['value'] in ['ns:stopped'] else False\"},\n",
    "                                                                                                                    }},\n",
    "}\n",
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7eefed1f-a5d0-4d97-896c-b9b65b738633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI-NB\\AppData\\Local\\Temp\\ipykernel_20404\\3027549251.py:92: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(data).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script name: AIR3268B42_Abnormal_Analyze.escp\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: April 12, 2023\n",
    "Description: Batch analyze AIR3268B42 abnormal keywords and group them based on RU, RdPort, and Abnormal.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from graph import *\n",
    "import random\n",
    "\n",
    "###################### User Define ###############################\n",
    "group = ['Cmd','Keywords','Abnormal']\n",
    "# Files directory Location\n",
    "dir_path = 'D:/projects/ericsson_flow/new_files/AIR3268B42_log'\n",
    "\n",
    "map_table_start_mark = 'FRU       ;LNH      ;BOARD      ;ST ;FAULT ;OPER ;MAINT ;STAT ;PRODUCTNUMBER   ;REV     ;SERIAL        ;DATE     ;PMTEMP  ; TEMP ; UPT'\n",
    "map_table_end_mark = '---------------------------------------------------------------------'\n",
    "map_table_exp = '{} ;{assigned_name} ;{product_name} {}'\n",
    "origin_data_output = 'D:/projects/ericsson_flow/new_files/AIR3268OriginData.csv'\n",
    "locate_name = 'AIR3268B42'\n",
    "pixel_width = 5000\n",
    "\n",
    "###################### Execution area ###############################\n",
    "# await self.on_console(msg='Script running...')\n",
    "# extract keywords and generate origin data\n",
    "def abnormal_condition(row, code):\n",
    "    exec(code)\n",
    "    return row\n",
    "    \n",
    "result = pd.DataFrame()\n",
    "for file_name in iterate_files_in_directory(dir_path):\n",
    "    path = f'{dir_path}\\\\{file_name}'\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    flag = False\n",
    "    table = {}\n",
    "    for line in lines:\n",
    "        if map_table_start_mark in line:\n",
    "            flag = True\n",
    "        if flag:\n",
    "            r = parse(map_table_exp, line)\n",
    "            if r is not None:\n",
    "                table[r.named['assigned_name']] = r.named['product_name']\n",
    "        if (map_table_end_mark in line) & flag:\n",
    "            break\n",
    "\n",
    "    search_contents = {}\n",
    "    for key in exps.keys():\n",
    "        search_contents[key] = []\n",
    "        \n",
    "    for key in exps.keys():\n",
    "        flag = False\n",
    "        content = {'lines':[]}\n",
    "        for index, line in enumerate(lines):\n",
    "            if flag:\n",
    "                r = parse(exps[key]['end_exp'], line)\n",
    "                if r is not None:\n",
    "                    flag = False\n",
    "                    search_contents[key].append(content)\n",
    "                    content = {'lines':[]}\n",
    "                else:\n",
    "                    content['lines'].append({'global_index':index, 'text':line})\n",
    "                    continue\n",
    "            r = parse(exps[key]['start_exp'], line)\n",
    "            if r is not None:\n",
    "                flag = True\n",
    "                content['assigned_name'] = r['assigned_name']\n",
    "                content['lines'].append({'global_index':index, 'text':line})\n",
    "\n",
    "    res = []\n",
    "    for key in search_contents.keys():\n",
    "        for content in search_contents[key]:\n",
    "            tmp = {}\n",
    "            for line in content['lines']:\n",
    "                for extract_key in exps[key]['extract_exps'].keys():\n",
    "                    r = parse(exps[key]['extract_exps'][extract_key]['exp'], line['text'])\n",
    "                    if r is not None:\n",
    "                        for name in r.named.keys():\n",
    "                            if name not in tmp:\n",
    "                                tmp[name] = [{'timestamp':random.randint(0, 100), 'file_name':file_name, 'product_name':table[content['assigned_name']], 'file_name':file_name, 'assigned_name':content['assigned_name'], 'cmd':key, 'keywords':extract_key, 'global_index': line['global_index'], 'value':r.named[name]}]\n",
    "                            else:\n",
    "                                tmp[name].append({'timestamp':random.randint(0, 100), 'file_name':file_name, 'product_name':table[content['assigned_name']], 'file_name':file_name, 'assigned_name':content['assigned_name'], 'cmd':key, 'keywords':extract_key, 'global_index': line['global_index'], 'value':r.named[name]})\n",
    "            # print(tmp)\n",
    "            for keyword in tmp.keys():\n",
    "                an = keyword+'_abnormal'\n",
    "                ptmp = pd.DataFrame(tmp)\n",
    "                ptmp = ptmp.apply(lambda x: abnormal_condition(x, exps[key]['extract_exps'][keyword]['cond']), axis=1)\n",
    "                abnormal = ptmp.loc[(ptmp[an] == True), keyword].values\n",
    "                res.append({'file_name': file_name, 'product_name': table[content['assigned_name']],'assigned_name': content['assigned_name'], 'cmd': key, 'keywords': keyword, 'abnormal':abnormal})\n",
    "    data = pd.DataFrame(res).groupby(['file_name', 'product_name', 'assigned_name', 'cmd', 'keywords'])['abnormal'].apply(lambda x: [i for j in x for i in j]).reset_index(name='merged_abnormal')\n",
    "result = result.append(data).reset_index(drop=True)\n",
    "result.to_csv(origin_data_output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab4f2e34-0355-4279-84f2-2468a7e32987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>assigned_name</th>\n",
       "      <th>cmd</th>\n",
       "      <th>keywords</th>\n",
       "      <th>merged_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>dpd</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>dpdStateMachine</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>gainStateMachine</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>linearizationStateMachine</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txDpdPma</td>\n",
       "      <td>[{'file_name': 'DL-NL3798-1-202303301405.log',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txPma</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txPmb</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2054</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txTorPmb</td>\n",
       "      <td>[{'file_name': 'DL-NL3798-1-202303301405.log',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>dpd</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>dpdStateMachine</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>gainStateMachine</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>linearizationStateMachine</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txDpdPma</td>\n",
       "      <td>[{'file_name': 'DL-NL3798-1-202303301405.log',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txPma</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txPmb</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DL-NL3798-1-202303301405.log</td>\n",
       "      <td>AIR3268B42</td>\n",
       "      <td>fru_2055</td>\n",
       "      <td>trx status</td>\n",
       "      <td>txTorPmb</td>\n",
       "      <td>[{'file_name': 'DL-NL3798-1-202303301405.log',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_name product_name assigned_name         cmd  \\\n",
       "0   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "1   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "2   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "3   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "4   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "5   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "6   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "7   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2054  trx status   \n",
       "8   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "9   DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "10  DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "11  DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "12  DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "13  DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "14  DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "15  DL-NL3798-1-202303301405.log   AIR3268B42      fru_2055  trx status   \n",
       "\n",
       "                     keywords  \\\n",
       "0                         dpd   \n",
       "1             dpdStateMachine   \n",
       "2            gainStateMachine   \n",
       "3   linearizationStateMachine   \n",
       "4                    txDpdPma   \n",
       "5                       txPma   \n",
       "6                       txPmb   \n",
       "7                    txTorPmb   \n",
       "8                         dpd   \n",
       "9             dpdStateMachine   \n",
       "10           gainStateMachine   \n",
       "11  linearizationStateMachine   \n",
       "12                   txDpdPma   \n",
       "13                      txPma   \n",
       "14                      txPmb   \n",
       "15                   txTorPmb   \n",
       "\n",
       "                                      merged_abnormal  \n",
       "0                                                  []  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4   [{'file_name': 'DL-NL3798-1-202303301405.log',...  \n",
       "5                                                  []  \n",
       "6                                                  []  \n",
       "7   [{'file_name': 'DL-NL3798-1-202303301405.log',...  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "10                                                 []  \n",
       "11                                                 []  \n",
       "12  [{'file_name': 'DL-NL3798-1-202303301405.log',...  \n",
       "13                                                 []  \n",
       "14                                                 []  \n",
       "15  [{'file_name': 'DL-NL3798-1-202303301405.log',...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc0f4e-8bbf-45cb-91e6-8119127b343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.read_csv('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\OriginData.csv')\n",
    "# result['RP'] = result['RP'].astype(str)\n",
    "\n",
    "# organize the required data.\n",
    "group = ['file_name','product_name','assigned_name','cmd','keywords','merged_abnormal']\n",
    "items = []\n",
    "for p in grouped[group].values:\n",
    "    groups = p[0: -1]\n",
    "    data = p[-1]\n",
    "    items.append({'path': list(groups), 'graph_type': 'ScatterPlot', 'start_timestamp': 0, 'end_timestamp': 100, 'elements': data})\n",
    "\n",
    "start_x = []\n",
    "end_x = []\n",
    "for item in items:\n",
    "    start_x.append(item['start_timestamp'])\n",
    "    end_x.append(item['end_timestamp'])\n",
    "\n",
    "graphs = []\n",
    "# define IndentedTree\n",
    "global_inter = linear_scale([min(start_x), max(end_x)], [0, pixel_width])\n",
    "tree = IndentedTree('', 0, pixel_width, pixel_width, items, global_inter)\n",
    "graphs.append({'id': tree.id, 'type': 'IndentedTree', 'elements': convert_dict_format(tree.to_dict(sort=False, with_data=True))})\n",
    "\n",
    "nodes = tree.get_all_nodes_to_list()\n",
    "for node in nodes:\n",
    "    if node['elements'] is not None:\n",
    "        sp = ScatterPlot(node['id'],node['sx'],node['ex'],node['ex'] - node['sx'],node['elements'],global_inter)\n",
    "        node['type'] = 'ScatterPlot'\n",
    "        graphs.append(node)\n",
    "\n",
    "graphs.append({\n",
    "    'type': 'Brush',\n",
    "    'width': pixel_width,\n",
    "    'height': tree.height\n",
    "})\n",
    "await self.on_draw('', graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ed5acb0-5710-4c24-b284-d0076dc96592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "grouped = pd.DataFrame(res).groupby(['assigned_name', 'cmd', 'keywords'])['value'].apply(lambda x: [i for j in x for i in j]).reset_index(name='merged_value')\n",
    "\n",
    "# 打印结果\n",
    "print(len(grouped['merged_value'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9c664-20ad-45f9-98c2-3aa4dd8df147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = 'D:/projects/ericsson_flow/new_files/6419ConfigSimple.ecfg'\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    tmp = json.load(f)\n",
    "\n",
    "nodes = []\n",
    "for chart in tmp['chart']:\n",
    "    node = {'id': '', 'type': 'TidyTree', 'elements': chart['key_value_tree']}\n",
    "    chart['key_value_tree'] = [node]\n",
    "    nodes.append(chart)\n",
    "tmp['chart'] = nodes\n",
    "json_object = json.dumps(tmp)\n",
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419ConfigSimple1.ecfg\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "# tmp['chart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97df23-a07d-42f4-8507-357790450fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419ConfigSimple1.ecfg\", 'r') as f:\n",
    "    tmp = json.load(f)\n",
    "tmp['chart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57353a-8dbc-4280-8d82-246869089788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson_toolsets_env",
   "language": "python",
   "name": "ericsson_toolsets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
