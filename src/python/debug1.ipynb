{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15f085-259f-4074-bd31-ab7a8720e801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import socketio\n",
    "sio = socketio.AsyncClient()\n",
    "\n",
    "file1 = \"ru_lock_unlock_normal1_simple.log\"\n",
    "file2 = \"ru_lock_unlock_dpd_hw_fault_simple.log\"\n",
    "\n",
    "await sio.connect('http://127.0.0.1:8000', namespaces=['/TextAnalysis/FileContainer', '/TextAnalysis/TextFileCompare'])\n",
    "await sio.emit('new_file', [f'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\{file1}'], namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(0.2)\n",
    "await sio.emit('load_config', 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419config.ecfg', namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(10)\n",
    "await sio.emit('new_file', [f'D:\\\\Projects\\\\ericsson_flow\\\\new_files\\\\{file2}'], namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(0.2)\n",
    "await sio.emit('load_config', 'D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\6419config.ecfg', namespace='/TextAnalysis/FileContainer')\n",
    "await asyncio.sleep(10)\n",
    "await sio.emit('exec', {'first_file_namespace': f'/TextAnalysis/FileContainer/{file1}', 'second_file_namespace': f'/TextAnalysis/FileContainer/{file2}'}, namespace='/TextAnalysis/TextFileCompare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb27fd-377f-4b2f-a56d-b7f99749cbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sio1 = socketio.AsyncClient()\n",
    "await sio1.connect('http://127.0.0.1:8000', namespaces=[\n",
    "'/TextAnalysis/FileContainer',\n",
    "'/TextAnalysis/TextFileCompare',\n",
    "'/TextAnalysis/FileContainer/ru_lock_unlock_normal1_simple.log/TextFileFunction/SearchFunction/txlProcBranch0',\n",
    "'/TextAnalysis/FileContainer/ru_lock_unlock_dpd_hw_fault_simple.log/TextFileFunction/SearchFunction/txlProcBranch0'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b7ebe-2c69-452b-92a6-b819d607f3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = {}\n",
    "model2 = {}\n",
    "\n",
    "def set_data1(model):\n",
    "    model1.update(model)\n",
    "def set_data2(model):\n",
    "    model2.update(model)\n",
    "await sio1.emit('model', namespace='/TextAnalysis/FileContainer/ru_lock_unlock_normal1_simple.log/TextFileFunction/SearchFunction/txlProcBranch0', callback=set_data1)\n",
    "await asyncio.sleep(0.2)\n",
    "await sio1.emit('model', namespace='/TextAnalysis/FileContainer/ru_lock_unlock_dpd_hw_fault_simple.log/TextFileFunction/SearchFunction/txlProcBranch0', callback=set_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5c649-c93d-4e58-9400-7952d83b5b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "string = '       air_mongoose com_ericsson_trithread INFO cpu_id  process txlProcBranch fileAndLine spiMaster cc  msg Warning Slow response to SPI_SEND_REQ for device paCtrlDevice   took ms '\n",
    "re.sub(' '+\"+\", ' ', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514940e7-4ba2-401d-91fe-565b8b3b3003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = 'Power measurement'\n",
    "for item in model1['res_clean_lines']:\n",
    "    if s in item:\n",
    "        print('model1', item)\n",
    "        \n",
    "for item in model2['res_clean_lines']:\n",
    "    if s in item:\n",
    "        print('model2', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f4edf-0413-4bf3-ac33-ac63a293845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t[14:56:47.927884604] (+0.001409563) air6419_mongoose com_ericsson_trithread:INFO: { cpu_id = 2 }, { process = \"WorkerTaskAas\", fileAndLine = \"algAasHelper.cc:659\", msg = \"Missing subbandMappingExt param, using default fullband instead.\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26446a-5c23-406a-9ba8-3ada3a5745ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2['res_clean_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1768f2-5582-488b-882b-3c5bad989fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "        self.b = 2\n",
    "        \n",
    "    def __getattribute__(self, obj):\n",
    "        print(obj)\n",
    "        return object.__getattribute__(self, obj)\n",
    "    \n",
    "c = A()\n",
    "c.a * c.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68ae71-a31a-43eb-b5c8-5858319c55e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from asyncio import get_event_loop\n",
    "from text_analysis import *\n",
    "\n",
    "# loop = get_event_loop()\n",
    "# loop.run_until_complete(TextAnalysisModel('parallel'))\n",
    "\n",
    "web.run_app(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bed893-12aa-40c5-8aa0-685e15d37007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as dp\n",
    "\n",
    "str(dp('221210-12:40:51', yearfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843578f-c129-4057-abfe-4e4633cc13e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if '2022-12-11 01:12:21.105110' > '2022-12-11 01:12:22':\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d155b-32e7-4219-8d01-047fc736d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from parse import parse\n",
    "\n",
    "str1 = '230228-16:19:06+0100 172.21.11.66 23.0b MSRBS_NODE_MODEL_22.Q2_566.28125.116_3317 stopfile=/tmp/11737'\n",
    "str2 = 'BXP_7:     769,dl-1  disabled        false    essFdd150_Id2       B     dl    2162500         BandI      0,       0    469            469     SETUP     SETUP'\n",
    "# exp_extract = '{}MSRBS_NODE_MODEL_{version}_{}'\n",
    "exp_extract = '{bxp}:{:s}{carrierId}{:s}{Enabled}{:s}{RealRelease}{:s}{carrierType}{:s}{rfPort}{:s}dl{:s}{Frequency}{:s}{Band}{:s}{Arfcn_min}{:s}{Arfcn_max}{:s}{Power}{:s}{ReservedPower}{:s}{tr}{:s}{bdconf}'\n",
    "r_extract = parse(exp_extract, str2)\n",
    "print(r_extract.named)\n",
    "# print(r_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc08b0-17cb-4a11-bbc8-14f46f0f8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for index in self.text_file.data['test'].res_lines:\n",
    "    lines.append(self.text_file.lines[index])\n",
    "\n",
    "with open('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\ru_lock_unlock_normal2_simple.log', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(lines))\n",
    "    \n",
    "# jesd|dfe|radiosw|rProxyMedian.cc # (txlProcBranch0|TxBranchCtrl0).*event com_ericsson_trithread:INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da1f0d-de24-450c-b58b-010130d4d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = self.text_file.data['dl'].res_key_value\n",
    "file = pd.DataFrame(pd.Series(data['Band']['value']), columns=['Band'])\n",
    "\n",
    "file['rfPort'] = pd.Series(data['rfPort']['value'])\n",
    "file['rfPort'] = 'Port_' + file['rfPort']\n",
    "file['carrierType'] = pd.Series(data['carrierType']['value'])\n",
    "file['Power'] = pd.Series(data['Power']['value'])\n",
    "\n",
    "result = {\n",
    "            'SiteName': self.text_file.file_name.split('_radio4480')[0],\n",
    "            'Version': self.text_file.data['version'].res_key_value['version']['value'][0],\n",
    "            'RadioQuantity': len(self.text_file.data['device'].res_lines)\n",
    "         }\n",
    "for band,port,carrier,power in file.values:\n",
    "    result[band+'_'+port+'_carrier_config'] = carrier\n",
    "    result[band+'_'+port+'_output_power_config'] = power\n",
    "\n",
    "self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07042a0-ce72-48ff-8dd7-11415ec32f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\KaiHong_4480config_origin_data.csv')\n",
    "data = data.fillna('')\n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "band1.extend(band3)\n",
    "columns = band1\n",
    "total = len(data)\n",
    "res = data.groupby(columns).size().reset_index(name='RadioAmount')\n",
    "for index,item in enumerate(json.loads(res.to_json(orient='records'))):\n",
    "    band1_dbm = []\n",
    "    band3_dbm = []\n",
    "    total_dbm = 0\n",
    "    for key in item.keys():\n",
    "        if ('output_power_BandIII' in key) & (item[key] != ''):\n",
    "            band3_dbm.append(item[key])\n",
    "        elif ('output_power_BandI' in key) & (item[key] != ''):\n",
    "            band1_dbm.append(item[key])\n",
    "    band1_dbm = sum(band1_dbm) if len(band1_dbm) > 0 else 0\n",
    "    band3_dbm = sum(band3_dbm) if len(band3_dbm) > 0 else 0\n",
    "    total_dbm = band1_dbm + band3_dbm\n",
    "    res.loc[index, ['BandI_dBm', 'BandIII_dBm', 'BandI+BandIII_dBm']] = [band1_dbm,band3_dbm,total_dbm]\n",
    "res['Percentage'] = res['RadioAmount'] / total\n",
    "res.to_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\6651_config_Sweden_204_Nodes_config_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaa13e-e71e-4a3c-8078-c27a7cdb7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = self.text_analysis.batch_statistic.table['table'].values\n",
    "data = pd.DataFrame()\n",
    "for index, item in enumerate(items):\n",
    "    print(index)\n",
    "    try:\n",
    "        tmp = pd.DataFrame(item)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue\n",
    "    data = data.append(tmp, ignore_index=True)\n",
    "    \n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "columns.extend(band1)\n",
    "columns.extend(band3)\n",
    "data = data.reindex(columns=columns)\n",
    "data.to_csv('C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\KaiHong_4480config_origin_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532a7d2-c2ec-41ae-806b-0a25c956fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = self.text_file.data['dl'].res_key_value\n",
    "file = pd.DataFrame(pd.Series(data['Band']['value']), columns=['Band'])\n",
    "\n",
    "file['bxp'] = pd.Series(data['bxp']['value'])\n",
    "file['rfPort'] = pd.Series(data['rfPort']['value'])\n",
    "file['rfPort'] = 'Port_' + file['rfPort']\n",
    "file['carrierType'] = pd.Series(data['carrierType']['value'])\n",
    "file['Power'] = pd.Series(data['Power']['value'])\n",
    "\n",
    "result = []\n",
    "for bxp in set(file['bxp'].values):\n",
    "    item = {\n",
    "                'SiteName': self.text_file.file_name.split('.log')[0],\n",
    "                'Bxp': bxp,\n",
    "                'Version': self.text_file.data['version'].res_key_value['version']['value'][0]\n",
    "             }\n",
    "    tmp = file.loc[(file['bxp'] == bxp), :].reset_index(drop=True)\n",
    "    for band,bxp,port,carrier,power in tmp.values:\n",
    "        if band in ['BandI', 'BandIII']:\n",
    "            cc = band+'_'+port+'_carrier_config'\n",
    "            pc = band+'_'+port+'_output_power_config'\n",
    "            dBm = 'output_power_' + band+'_'+port + '_dBm'\n",
    "            if cc in item:\n",
    "                item[cc] = carrier + ' + ' + item[cc] if carrier < item[cc] else item[cc] + ' + ' + carrier\n",
    "                item[pc] = power + ' + ' + item[pc] if carrier < item[cc] else item[pc] + ' + ' + power\n",
    "                item[dBm] = item[dBm] + round(10**(int(power)/100)/1000, 1)\n",
    "            else:\n",
    "                item[cc] = carrier\n",
    "                item[pc] = power\n",
    "                item[dBm] = round(10**(int(power)/100)/1000, 1)\n",
    "    if len(item.keys())> 3:\n",
    "        result.append(item)\n",
    "\n",
    "self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a20888-6166-4e92-a73a-0844aba40c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "sheet_names = pd.read_excel(file_path, sheet_name=None).keys()\n",
    "sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bcf46-dc83-4475-b363-8afa60666fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_excel(file_path, sheet_name='Claro_4480_cc_SW', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf6166-9977-4946-ba30-3b460b7be537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "print('Loading file...')\n",
    "sheet_names = pd.read_excel(file_path, sheet_name=None).keys()\n",
    "for sheet_name in sheet_names:\n",
    "    print(f'Start Handle {sheet_name}...')\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    result = []\n",
    "    x= list(data['SerialNo'].values)\n",
    "    sns = sorted(set(x), key=x.index)\n",
    "    for sn in sns:\n",
    "        radio = data.loc[(data['SerialNo'] == sn)&(data['MaxTxPower_br'].notna()), :].reset_index(drop=True)\n",
    "        if len(radio) == 0:\n",
    "            continue\n",
    "        item = {'SerialNo': sn, 'SwPack': list(radio['SwPack'].values)[0]}\n",
    "        for port,band,power in radio[['rfPortId', 'freqBand', 'MaxTxPower_br']].values:\n",
    "            if band in [1,3]:\n",
    "                item['Band'+str(int(band))+'_Port'+port+'_MaxTxPower_br'] = power\n",
    "\n",
    "        band1_power = []\n",
    "        band3_power = []\n",
    "        for key in item.keys():\n",
    "            if 'Band1' in key:\n",
    "                band1_power.append(item[key])\n",
    "            if 'Band3' in key:\n",
    "                band3_power.append(item[key])\n",
    "\n",
    "        item['Band1_MaxTxPower_br'] = sum(band1_power) if len(band1_power) > 0 else 0\n",
    "        item['Band3_MaxTxPower_br'] = sum(band3_power) if len(band3_power) > 0 else 0\n",
    "        item['Band1+Band3_MaxTxPower_br'] = item['Band1_MaxTxPower_br'] + item['Band3_MaxTxPower_br']\n",
    "        result.append(item)\n",
    "    data = ''\n",
    "    del data\n",
    "    origin_data = pd.DataFrame(result)\n",
    "    origin_data.to_csv(f'{output_path}\\\\{sheet_name}_Origin_Data.csv', index=False)\n",
    "\n",
    "    origin_data = origin_data.fillna('')\n",
    "    total = len(origin_data)\n",
    "    summary = origin_data.groupby(list(origin_data.columns[2:])).size().reset_index(name='RadioAmount')\n",
    "    summary['Percentage'] = summary['RadioAmount'] / total\n",
    "    summary.to_csv(f'{output_path}\\\\{sheet_name}_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe86ef3-05cd-443e-8b7e-df84fcac089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script name: my_script.py\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: March 28, 2023\n",
    "Description: Collect the configuration information for multiple 4480 radios.\n",
    "Process: \n",
    "        1.Extract file returned by 'carrierListHandler print table' command.\n",
    "        2.Extract (version carrierType rfPort dl/ul Band Power)\n",
    "        3.Batch extraction and output to a table. \n",
    "        4.Export origin data based on a single radio.\n",
    "        5.Export summary information based on the configuration information of all radios.\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.dir_path = 'C:\\\\Users\\\\MSI-NB\\\\Downloads\\\\6651_config_Denmark_68_Nodes\\\\6651_config_Denmark_68_Nodes'\n",
    "# Config Location\n",
    "self.config_path = 'D:\\\\projects\\\\ericsson_flow\\\\configs\\\\4480_Configure_Statistic_Config.ecfg'\n",
    "# Output Location\n",
    "self.output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "# Save name\n",
    "self.save_name = '6651_config_Denmark_68_Nodes'\n",
    "\n",
    "###################### Batch handle file, according to config ###############################\n",
    "table = await self.batch_handle(self.dir_path, self.config_path)\n",
    "table = table.drop(['search_atoms', 'chart_atoms', 'statistic_atoms'], axis=1)\n",
    "\n",
    "###################### Export origin data ###############################\n",
    "items = table['table'].values\n",
    "data = pd.DataFrame()\n",
    "for index, item in enumerate(items):\n",
    "    try:\n",
    "        tmp = pd.DataFrame(item)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        continue\n",
    "    data = data.append(tmp, ignore_index=True)\n",
    "    \n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "columns.extend(band1)\n",
    "columns.extend(band3)\n",
    "data = data.reindex(columns=columns)\n",
    "data.to_csv(f'{self.output_path}//{self.save_name}_origin_data.csv', index=False)\n",
    "await self.on_console(msg='Export Origin Data Finish!')\n",
    "\n",
    "###################### Export summary data ###############################\n",
    "data = data.fillna('')\n",
    "columns = ['SiteName', 'Bxp', 'Version']\n",
    "tmpl = sorted(list(set(data.columns).difference(set(columns))))\n",
    "band1 = []\n",
    "band3 = []\n",
    "for c in tmpl:\n",
    "    if 'BandIII_' in c:\n",
    "        band3.append(c)\n",
    "    elif 'BandI_' in c:\n",
    "        band1.append(c)\n",
    "        \n",
    "band1.extend(band3)\n",
    "columns = band1\n",
    "total = len(data)\n",
    "res = data.groupby(columns).size().reset_index(name='RadioAmount')\n",
    "for index,item in enumerate(json.loads(res.to_json(orient='records'))):\n",
    "    band1_dbm = []\n",
    "    band3_dbm = []\n",
    "    total_dbm = 0\n",
    "    for key in item.keys():\n",
    "        if ('output_power_BandIII' in key) & (item[key] != ''):\n",
    "            band3_dbm.append(item[key])\n",
    "        elif ('output_power_BandI' in key) & (item[key] != ''):\n",
    "            band1_dbm.append(item[key])\n",
    "    band1_dbm = sum(band1_dbm) if len(band1_dbm) > 0 else 0\n",
    "    band3_dbm = sum(band3_dbm) if len(band3_dbm) > 0 else 0\n",
    "    total_dbm = band1_dbm + band3_dbm\n",
    "    res.loc[index, ['BandI_dBm', 'BandIII_dBm', 'BandI+BandIII_dBm']] = [band1_dbm,band3_dbm,total_dbm]\n",
    "res['Percentage'] = res['RadioAmount'] / total\n",
    "res.to_csv(f'{self.output_path}//{self.save_name}_summary.csv', index=False)\n",
    "await self.on_console(msg='Export Summary Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848a8a4-f080-49cf-bfbd-22ed2d9a0c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect the configuration information for 4480 radios xslx.\n",
    "\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "CreateTime: 2023.3.20\n",
    "ChangeTime: 2023.3.30\n",
    "Version: 1.1\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "# Files directory Location\n",
    "self.xslx_path = 'D:\\\\projects\\\\ericsson_flow\\\\CC summary V2,0.xlsx'\n",
    "# Output Location\n",
    "self.output_path = 'D:\\\\projects\\\\ericsson_flow\\\\output'\n",
    "\n",
    "print('Loading file...')\n",
    "sheet_names = pd.read_excel(self.xslx_path, sheet_name=None).keys()\n",
    "for sheet_name in sheet_names:\n",
    "    print(f'Start Handle {sheet_name}...')\n",
    "    data = pd.read_excel(self.xslx_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    \n",
    "    ###################### Export origin data ###############################\n",
    "    result = []\n",
    "    x= list(data['SerialNo'].values)\n",
    "    sns = sorted(set(x), key=x.index)\n",
    "    for sn in sns:\n",
    "        radio = data.loc[(data['SerialNo'] == sn)&(data['MaxTxPower_br'].notna()), :].reset_index(drop=True)\n",
    "        if len(radio) == 0:\n",
    "            continue\n",
    "        item = {'SerialNo': sn, 'SwPack': list(radio['SwPack'].values)[0]}\n",
    "        for port,band,power in radio[['rfPortId', 'freqBand', 'MaxTxPower_br']].values:\n",
    "            if band in [1,3]:\n",
    "                item['Band'+str(int(band))+'_Port'+port+'_MaxTxPower_br'] = power\n",
    "\n",
    "        band1_power = []\n",
    "        band3_power = []\n",
    "        for key in item.keys():\n",
    "            if 'Band1' in key:\n",
    "                band1_power.append(item[key])\n",
    "            if 'Band3' in key:\n",
    "                band3_power.append(item[key])\n",
    "\n",
    "        item['Band1_MaxTxPower_br'] = sum(band1_power) if len(band1_power) > 0 else 0\n",
    "        item['Band3_MaxTxPower_br'] = sum(band3_power) if len(band3_power) > 0 else 0\n",
    "        item['Band1+Band3_MaxTxPower_br'] = item['Band1_MaxTxPower_br'] + item['Band3_MaxTxPower_br']\n",
    "        result.append(item)\n",
    "    data = ''\n",
    "    del data\n",
    "    origin_data = pd.DataFrame(result)\n",
    "    origin_data.to_csv(f'{self.output_path}\\\\{sheet_name}_Origin_Data.csv', index=False)\n",
    "    \n",
    "    ###################### Export summary data ###############################\n",
    "    origin_data = origin_data.fillna('')\n",
    "    total = len(origin_data)\n",
    "    summary = origin_data.groupby(list(origin_data.columns[2:])).size().reset_index(name='RadioAmount')\n",
    "    summary['Percentage'] = summary['RadioAmount'] / total\n",
    "    summary.to_csv(f'{self.output_path}\\\\{sheet_name}_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf33fa-32df-4e39-a42b-6d62b3949088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script name: DOT4455_Abnormal_Analyze.escp\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: April 11, 2023\n",
    "Description: Batch analyze DOT4455 abnormal keywords and group them based on RU, RdPort, and Abnormal.\n",
    "\"\"\"\n",
    "\n",
    "###################### User Define ###############################\n",
    "group = ['Root','RU','RP','Abnormal']\n",
    "# Files directory Location\n",
    "self.dir_path = 'D:/projects/ericsson_flow/new_files/low_tx_power_log0331'\n",
    "self.exps = [\n",
    "                {'name': 'DPD errorCode 0x340a', 'exp': '{RU}: OK {} {timestampd} {timestampt} {}: DPD errorCode 0x340a{}'},\n",
    "                {'name': 'Low tx Power', 'exp': '{RU}: OK {} {timestampd} {timestampt} {}: Low tx Power{}'}\n",
    "            ]\n",
    "self.end_marker = '{}Done RdId:{RI}, RdPort:{RP}{}'\n",
    "origin_data_output = 'D:/projects/ericsson_flow/new_files/OriginData.csv'\n",
    "root_name = 'DOT4455'\n",
    "pixel_width = 5000\n",
    "\n",
    "###################### Execution area ###############################\n",
    "await self.on_console(msg='Script running...')\n",
    "# extract keywords and generate origin data\n",
    "result = pd.DataFrame()\n",
    "for file_name in iterate_files_in_directory(self.dir_path):\n",
    "    path = f'{self.dir_path}\\\\{file_name}'\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    rd_port = []\n",
    "    for line in lines:\n",
    "        for exp in self.exps:\n",
    "            r = parse(exp['exp'], line)\n",
    "            if r is not None:\n",
    "                rd_port.append({'IP': file_name, 'RU': r['RU'], 'Abnormal': exp['name'], 'timestamp': convert_datetime_timestamp(r['timestampd'] + ' ' + r['timestampt'])})\n",
    "        if parse(self.end_marker, line) is not None:\n",
    "            tmp = pd.DataFrame(rd_port)\n",
    "            tmp['RP'] = parse(self.end_marker, line)['RP']\n",
    "            result = result.append(tmp).reset_index(drop=True)\n",
    "            rd_port = []\n",
    "    await self.on_console(msg=f'Finish {file_name}.')\n",
    "result['Root'] = root_name\n",
    "result['RP'] = result['RP'].astype(str)\n",
    "result = result.loc[:, ['Root','IP','RU','RP','Abnormal','timestamp']]\n",
    "result.to_csv(origin_data_output, index=False)\n",
    "\n",
    "# result = pd.read_csv('D:\\\\projects\\\\ericsson_flow\\\\new_files\\\\OriginData.csv')\n",
    "# result['RP'] = result['RP'].astype(str)\n",
    "\n",
    "# organize the required data.\n",
    "items = []\n",
    "grouped = result.groupby(group)\\\n",
    "    .apply(lambda x: x[['IP', 'timestamp']].assign(api='that.textAnalysisView.fileContainerView.controlNewFile([\"'+self.dir_path+'/'+x['IP']+'\"])').to_dict('records'))\\\n",
    "    .reset_index(name='data')\n",
    "group.append('data')\n",
    "for p in grouped[group].values:\n",
    "    groups = p[0: -1]\n",
    "    data = p[-1]\n",
    "    items.append({'path': list(groups), 'graph_type': 'ScatterPlot', 'start_x': min(pd.DataFrame(data)['timestamp'].values), 'end_x': max(pd.DataFrame(data)['timestamp'].values), 'elements': data})\n",
    "\n",
    "start_x = []\n",
    "end_x = []\n",
    "for item in items:\n",
    "    start_x.append(item['start_x'])\n",
    "    end_x.append(item['end_x'])\n",
    "\n",
    "graphs = []\n",
    "# define xaxis\n",
    "graphs.append({\n",
    "    'type': 'XAxis',\n",
    "    'width': pixel_width,\n",
    "    'lower_bound': min(start_x),\n",
    "    'upper_bound': max(end_x),\n",
    "    'tick_format_func': 'formatTimestamp'\n",
    "})\n",
    "\n",
    "# define IndentedTree\n",
    "global_inter = linear_scale([min(start_x), max(end_x)], [0, pixel_width])\n",
    "tree = IndentedTree('', 0, pixel_width, pixel_width, items, global_inter)\n",
    "graphs.append({'id': tree.id, 'type': tree.type, 'elements': tree.elements})\n",
    "\n",
    "nodes = tree.get_all_nodes_to_list()\n",
    "for node in nodes:\n",
    "    if node['elements'] is not None:\n",
    "        sp = ScatterPlot(node['id'],node['sx'],node['ex'],node['width'],node['elements'],global_inter,2,'timestamp')\n",
    "        graphs.append(node)\n",
    "\n",
    "graphs.append({\n",
    "    'type': 'Brush',\n",
    "    'width': pixel_width,\n",
    "    'height': tree.height\n",
    "})\n",
    "await self.on_draw('', graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072c659-5eeb-4b0f-bec5-b04c8ce60f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eefed1f-a5d0-4d97-896c-b9b65b738633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LDJ\\AppData\\Local\\Temp\\ipykernel_18468\\1494805047.py:145: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(data).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script name: AIR3268B42_Abnormal_Analyze.escp\n",
    "Author: DengJun Lei(EEEINLD)\n",
    "Date created: April 12, 2023\n",
    "Description: Batch analyze AIR3268B42 abnormal keywords and group them based on file_name,product_name,assigned_name,cmd,keywords, and Abnormal.\n",
    "\"\"\"\n",
    "\n",
    "# from utils import *\n",
    "# from graph import *\n",
    "# import random\n",
    "\n",
    "###################### User Define ###############################\n",
    "group = ['file_name','product_name','assigned_name','cmd','keywords']\n",
    "# Files directory Location\n",
    "dir_path = 'D:/projects/ericsson_flow/new_files/AIR3268B42_log'\n",
    "\n",
    "exps = {\n",
    "    'trx status': {'extract_exps': {\n",
    "                    'timestamp':{'exp':'{}Date: {timestamp},{}', 'cond': \"row['timestamp_abnormal'] = False\"},\n",
    "                    'txPma':{'exp':'{}txPma{}: {txPma},{}', 'cond': \"row['txPma_abnormal'] = False\"},\n",
    "                    'txDpdPma':{'exp':'{}txDpdPma{}: {txDpdPma},{}', 'cond': \"row['txDpdPma_abnormal'] = True if float(row['txPma']['value']) - float(row['txDpdPma']['value']) > 4 else False\"},\n",
    "                    'txPmb':{'exp':'{}txPmb{}: {txPmb},{}', 'cond': \"row['txPmb_abnormal'] = True if float(row['txPma']['value']) - float(row['txPmb']['value']) != 0 else False\"},\n",
    "                    'txTorPmb':{'exp':'{}txTorPmb{}: {txTorPmb},{}', 'cond': \"row['txTorPmb_abnormal'] = True if float(row['txPma']['value']) - float(row['txTorPmb']['value']) > 0.1 else False\"},\n",
    "                    'dpd':{'exp':'{}dpd {}: {dpd},{}', 'cond': \"row['dpd_abnormal'] = True if row['dpd']['value'] in ['off'] else False\"},\n",
    "                    'dpdStateMachine':{'exp':'{}dpdStateMachine{}: {dpdStateMachine},{}', 'cond': \"row['dpdStateMachine_abnormal'] = True if row['dpdStateMachine']['value'] in ['OFF'] else False\"},\n",
    "                    'gainStateMachine':{'exp':'{}gainStateMachine{}: {gainStateMachine},{}', 'cond': \"row['gainStateMachine_abnormal'] = True if row['gainStateMachine']['value'] in ['CtrlGainStateIdle:started', 'ns:stopped'] else False\"},\n",
    "                    'linearizationStateMachine':{'exp':'{}linearizationStateMachine{}: {linearizationStateMachine},{}', 'cond': \"row['linearizationStateMachine_abnormal'] = True if row['linearizationStateMachine']['value'] in ['ns:stopped'] else False\"},\n",
    "                }, 'time_type': 'batch', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} trx status{}', 'end_exp': 'coli>/fruacc/lhsh{}'},\n",
    "    'elog read': {'extract_exps': {\n",
    "                    'LinFault':{'exp':'{}[{timestamp}]{}Lin. fault port{LinFault}', 'cond': \"row['LinFault_abnormal'] = True if row['LinFault'] is not None else False\"},\n",
    "                    'PowerLost':{'exp':'{}[{timestamp}]{}POWER LOST{PowerLost}', 'cond': \"row['PowerLost_abnormal'] = True if row['PowerLost'] is not None else False\"},\n",
    "                    'PsuEnter':{'exp':'{}[{timestamp}]{}PSU enters{PsuEnter}', 'cond': \"row['PsuEnter_abnormal'] = True if row['PsuEnter'] is not None else False\"},\n",
    "                    'JesdLinkFailure':{'exp':'{}[{timestamp}]{}JESD LINK FAILURE{JesdLinkFailure}', 'cond': \"row['JesdLinkFailure_abnormal'] = True if row['JesdLinkFailure'] is not None else False\"},\n",
    "                    'DpdController':{'exp':'{}[{timestamp}]{}#### DPDCONTROLLER{DpdController}', 'cond': \"row['DpdController_abnormal'] = True if row['DpdController'] is not None else False\"},\n",
    "                }, 'time_type': 'embedded', 'start_exp': 'coli>/fruacc/lhsh {assigned_name} elog read{}', 'end_exp': '{}End of log{}'},\n",
    "}\n",
    "\n",
    "map_table_start_mark = ['FRU','LNH','BOARD','ST','FAULT','OPER','MAINT']\n",
    "map_table_end_mark = '---------------------------------------------------------------------'\n",
    "map_table_exp = '{} ;{assigned_name} ;{product_name} {}'\n",
    "origin_data_output = 'D:/projects/ericsson_flow/new_files/AIR3268OriginData.csv'\n",
    "pixel_width = 2000\n",
    "\n",
    "###################### Execution area ###############################\n",
    "# await self.on_console(msg='Script running...')\n",
    "# extract keywords and generate origin data\n",
    "def abnormal_condition(row, code):\n",
    "    exec(code)\n",
    "    return row\n",
    "    \n",
    "result = pd.DataFrame()\n",
    "for file_index, file_name in enumerate(iterate_files_in_directory(dir_path)):\n",
    "    path = f'{dir_path}\\\\{file_name}'\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # find map table\n",
    "    flag = False\n",
    "    table = {}\n",
    "    for line in lines:\n",
    "        if list(set([True if word in line else False  for word in map_table_start_mark]))[0] == True:\n",
    "            flag = True\n",
    "        if flag:\n",
    "            r = parse(map_table_exp, line)\n",
    "            if r is not None:\n",
    "                table[r.named['assigned_name']] = r.named['product_name']\n",
    "        if (map_table_end_mark in line) & flag:\n",
    "            break\n",
    "\n",
    "    # init \n",
    "    search_contents = {}\n",
    "    for key in exps.keys():\n",
    "        search_contents[key] = []\n",
    "    \n",
    "    # find search content\n",
    "    for key in exps.keys():\n",
    "        flag = False\n",
    "        content = {'lines':[]}\n",
    "        for index, line in enumerate(lines):\n",
    "            if flag:\n",
    "                r = parse(exps[key]['end_exp'], line)\n",
    "                if r is not None:\n",
    "                    flag = False\n",
    "                    search_contents[key].append(content)\n",
    "                    content = {'lines':[]}\n",
    "                else:\n",
    "                    content['lines'].append({'global_index':index, 'text':line})\n",
    "                    continue\n",
    "            r = parse(exps[key]['start_exp'], line)\n",
    "            if r is not None:\n",
    "                flag = True\n",
    "                content['assigned_name'] = r['assigned_name']\n",
    "                content['lines'].append({'global_index':index, 'text':line})\n",
    "    \n",
    "    # extract key value\n",
    "    res = []\n",
    "    for key in search_contents.keys():\n",
    "        for cmd_batch, content in enumerate(search_contents[key]):\n",
    "            tmp = {}\n",
    "            for extract_key in exps[key]['extract_exps'].keys():\n",
    "                if extract_key != 'timestamp':\n",
    "                    tmp[extract_key] = []\n",
    "            \n",
    "            if exps[key]['time_type'] == 'embedded':\n",
    "                for line in content['lines']:\n",
    "                    for extract_key in exps[key]['extract_exps'].keys():\n",
    "                        r = parse(exps[key]['extract_exps'][extract_key]['exp'], line['text'])\n",
    "                        if r is not None:\n",
    "                            item = {\n",
    "                                    'file_name':file_name, 'product_name':table[content['assigned_name']], 'assigned_name':content['assigned_name'], \n",
    "                                    'cmd':key, 'keywords':extract_key, 'global_index': line['global_index'], 'value':'',\n",
    "                                    'cmd_batch': cmd_batch, 'timestamp': convert_datetime_timestamp(r.named['timestamp']), 'x': random.randint(0, 100), 'y':random.randint(0, 100)\n",
    "                                    }\n",
    "                            tmp[extract_key].append(item)\n",
    "            elif exps[key]['time_type'] == 'batch':\n",
    "                timestamp = ''\n",
    "                for line in content['lines']:\n",
    "                    for extract_key in exps[key]['extract_exps'].keys():\n",
    "                        r = parse(exps[key]['extract_exps'][extract_key]['exp'], line['text'])\n",
    "                        if r is not None:\n",
    "                            if 'timestamp' in r.named:\n",
    "                                timestamp = convert_datetime_timestamp(r.named['timestamp'])\n",
    "                                break\n",
    "                            item = {\n",
    "                                    'file_name':file_name, 'product_name':table[content['assigned_name']], 'assigned_name':content['assigned_name'], \n",
    "                                    'cmd':key, 'keywords':extract_key, 'global_index': line['global_index'], 'value':r.named[extract_key],\n",
    "                                    'cmd_batch': cmd_batch, 'timestamp': timestamp, 'x': random.randint(0, 100), 'y':random.randint(0, 100)\n",
    "                                    }\n",
    "                            tmp[extract_key].append(item)\n",
    "                \n",
    "            for keyword in tmp.keys():\n",
    "\n",
    "                max_len = max([len(v) for v in tmp.values()])\n",
    "                for k, v in tmp.items():\n",
    "                    if len(v) < max_len:\n",
    "                        v.extend([None] * (max_len - len(v)))\n",
    "        \n",
    "                an = keyword+'_abnormal'\n",
    "                ptmp = pd.DataFrame(tmp)\n",
    "                ptmp = ptmp.apply(lambda x: abnormal_condition(x, exps[key]['extract_exps'][keyword]['cond']), axis=1)\n",
    "                abnormal = ptmp.loc[(ptmp[an] == True), keyword].values\n",
    "                res.append({'file_name': file_name, 'product_name': table[content['assigned_name']],'assigned_name': content['assigned_name'], 'cmd': key, 'keywords': keyword, 'abnormal':abnormal})\n",
    "    data = pd.DataFrame(res).groupby(group)['abnormal'].apply(lambda x: [i for j in x for i in j]).reset_index(name='merged_abnormal')\n",
    "    await self.on_console(msg=f'Finish {file_index} {file_name}.')\n",
    "result = result.append(data).reset_index(drop=True)\n",
    "result.to_csv(origin_data_output, index=False)\n",
    "\n",
    "# draw picture\n",
    "items = []\n",
    "group.append('merged_abnormal')\n",
    "for p in result[group].values:\n",
    "    groups = [i.replace('.','_') for i in p[0: -1]]\n",
    "    data = p[-1]\n",
    "    ts = []\n",
    "    for dot in data:\n",
    "        ts.append(dot['timestamp'])\n",
    "    items.append({'path': list(groups), 'graph_type': 'ScatterPlot', 'start_x': min(ts) if len(ts) > 0 else 0, 'end_x': max(ts) if len(ts) > 0 else 0, 'elements': data})\n",
    "\n",
    "start_x = []\n",
    "end_x = []\n",
    "for item in items:\n",
    "    if (item['start_x'] !=0) & (item['end_x'] !=0):\n",
    "        start_x.append(item['start_x'])\n",
    "        end_x.append(item['end_x'])\n",
    "\n",
    "graphs = []\n",
    "# define xaxis\n",
    "graphs.append({\n",
    "    'type': 'XAxis',\n",
    "    'width': pixel_width,\n",
    "    'lower_bound': min(start_x),\n",
    "    'upper_bound': max(end_x),\n",
    "    'tick_format_func': 'formatTimestamp'\n",
    "})\n",
    "# define IndentedTree\n",
    "global_inter = linear_scale([min(start_x), max(end_x)], [0, pixel_width])\n",
    "tree = IndentedTree('', 0, pixel_width, pixel_width, items, global_inter)\n",
    "graphs.append({'id': tree.id, 'type': tree.type, 'elements': tree.elements})\n",
    "\n",
    "nodes = tree.get_all_nodes_to_list()\n",
    "for node in nodes:\n",
    "    if node['elements'] is not None:\n",
    "        sp = ScatterPlot(node['id'],node['sx'],node['ex'],node['width'],node['elements'],global_inter,2,'x')\n",
    "        for dot in sp.elements:\n",
    "            dot['api'] = f\"\"\"\n",
    "                that.textAnalysisView.fileContainerView.controlNewFile([\"{dir_path}/{dot['file_name']}\"])\n",
    "                setTimeout(function() {{\n",
    "                   that.textAnalysisView.fileContainerView.textFileViews[that.textAnalysisView.fileContainerView.activeTextFileView].textFileOriginalView.controlJump(d)\n",
    "                }}, 500)\n",
    "            \"\"\"\n",
    "        graphs.append(sp.get_vars())\n",
    "\n",
    "graphs.append({\n",
    "    'type': 'Brush',\n",
    "    'width': pixel_width,\n",
    "    'height': tree.height\n",
    "})\n",
    "await self.on_draw('', json.dumps(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa57353a-8dbc-4280-8d82-246869089788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'DL-NL1-1-202303301315.log',\n",
       " 'product_name': 'AIR3268B42',\n",
       " 'assigned_name': 'fru_2053',\n",
       " 'cmd': 'trx status',\n",
       " 'keywords': 'txDpdPma',\n",
       " 'global_index': 15423,\n",
       " 'value': -33.29,\n",
       " 'cmd_batch': 2,\n",
       " 'timestamp': '2023-03-30 07:47:15',\n",
       " 'x': 9,\n",
       " 'y': 52}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptmp = pd.DataFrame(tmp)\n",
    "ptmp.loc[30,'txDpdPma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0a82d7c-a610-4db8-92f5-7ad50dc74f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10895 10896\n",
      "11041 11042\n",
      "11187 11188\n",
      "11333 11334\n",
      "11480 11481\n",
      "11629 11630\n",
      "11775 11776\n",
      "11921 11922\n",
      "12066 12067\n",
      "12212 12213\n",
      "12358 12359\n",
      "12504 12505\n",
      "12650 12797\n",
      "12796 12943\n",
      "12942 13088\n",
      "13087 13234\n",
      "13233 13380\n",
      "13379 13526\n",
      "13525 13672\n",
      "13671 13818\n",
      "13817 13964\n",
      "13963 14110\n",
      "14109 14256\n",
      "14255 14402\n",
      "14401 14548\n",
      "14547 14694\n",
      "14693 14840\n",
      "14839 14986\n",
      "14985 15131\n",
      "15130 15277\n",
      "15276 15423\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxPma\u001b[39m\u001b[38;5;124m'\u001b[39m], tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxDpdPma\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_index\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglobal_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for a, b in zip(tmp['txPma'], tmp['txDpdPma']):\n",
    "    print(a['global_index'], b['global_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b014729-797a-4427-b45f-c31f4e2c017a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson_toolsets_env",
   "language": "python",
   "name": "ericsson_toolsets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
